{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './csvFiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 목록을 랜덤하게 섞습니다.\n",
    "random.seed(42)  # 재현 가능한 결과를 위해 시드 설정\n",
    "random.shuffle(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[300:-100]\n",
    "    df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Time</th>\n",
       "      <th>m_avg_PelvisPosX</th>\n",
       "      <th>m_avg_PelvisPosY</th>\n",
       "      <th>m_avg_PelvisPosZ</th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipPosX</th>\n",
       "      <th>m_avg_L_HipPosY</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristPosX</th>\n",
       "      <th>m_avg_R_WristPosY</th>\n",
       "      <th>m_avg_R_WristPosZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.0</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.26</td>\n",
       "      <td>352.22</td>\n",
       "      <td>350.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.20</td>\n",
       "      <td>359.56</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>352.27</td>\n",
       "      <td>350.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>352.29</td>\n",
       "      <td>350.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>359.53</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>352.28</td>\n",
       "      <td>350.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.24</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.26</td>\n",
       "      <td>352.23</td>\n",
       "      <td>350.85</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.39</td>\n",
       "      <td>359.57</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250226</th>\n",
       "      <td>4599.0</td>\n",
       "      <td>51.25</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.55</td>\n",
       "      <td>179.77</td>\n",
       "      <td>357.66</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.13</td>\n",
       "      <td>198.30</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>47.17</td>\n",
       "      <td>37.40</td>\n",
       "      <td>178.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250227</th>\n",
       "      <td>4600.0</td>\n",
       "      <td>51.26</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.36</td>\n",
       "      <td>179.61</td>\n",
       "      <td>357.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.13</td>\n",
       "      <td>198.37</td>\n",
       "      <td>3.79</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>47.21</td>\n",
       "      <td>37.33</td>\n",
       "      <td>178.62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250228</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>51.27</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.36</td>\n",
       "      <td>179.61</td>\n",
       "      <td>357.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.13</td>\n",
       "      <td>198.42</td>\n",
       "      <td>3.84</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>47.29</td>\n",
       "      <td>37.23</td>\n",
       "      <td>178.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250229</th>\n",
       "      <td>4602.0</td>\n",
       "      <td>51.28</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.36</td>\n",
       "      <td>179.61</td>\n",
       "      <td>357.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.14</td>\n",
       "      <td>198.47</td>\n",
       "      <td>3.87</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>47.36</td>\n",
       "      <td>37.14</td>\n",
       "      <td>178.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250230</th>\n",
       "      <td>4603.0</td>\n",
       "      <td>51.29</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.45</td>\n",
       "      <td>179.67</td>\n",
       "      <td>357.49</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.14</td>\n",
       "      <td>198.51</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>47.44</td>\n",
       "      <td>37.06</td>\n",
       "      <td>178.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250231 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frame   Time  m_avg_PelvisPosX  m_avg_PelvisPosY  m_avg_PelvisPosZ  \\\n",
       "0         301.0   3.45              0.02              0.54              0.69   \n",
       "1         302.0   3.47              0.02              0.54              0.69   \n",
       "2         303.0   3.48              0.02              0.54              0.69   \n",
       "3         304.0   3.49              0.02              0.54              0.69   \n",
       "4         305.0   3.50              0.02              0.54              0.69   \n",
       "...         ...    ...               ...               ...               ...   \n",
       "1250226  4599.0  51.25             -0.67              0.46              0.82   \n",
       "1250227  4600.0  51.26             -0.67              0.46              0.82   \n",
       "1250228  4601.0  51.27             -0.67              0.46              0.82   \n",
       "1250229  4602.0  51.28             -0.67              0.46              0.82   \n",
       "1250230  4603.0  51.29             -0.67              0.46              0.82   \n",
       "\n",
       "         m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  \\\n",
       "0                  358.82              0.68            359.84   \n",
       "1                  358.82              0.68            359.84   \n",
       "2                  358.82              0.68            359.84   \n",
       "3                  358.82              0.68            359.84   \n",
       "4                  358.82              0.68            359.84   \n",
       "...                   ...               ...               ...   \n",
       "1250226             18.55            179.77            357.66   \n",
       "1250227             18.36            179.61            357.62   \n",
       "1250228             18.36            179.61            357.62   \n",
       "1250229             18.36            179.61            357.62   \n",
       "1250230             18.45            179.67            357.49   \n",
       "\n",
       "         m_avg_L_HipPosX  m_avg_L_HipPosY  ...  m_avg_R_ElbowRotX  \\\n",
       "0                  -0.04             0.46  ...               8.26   \n",
       "1                  -0.04             0.46  ...               8.27   \n",
       "2                  -0.04             0.46  ...               8.27   \n",
       "3                  -0.04             0.46  ...               8.27   \n",
       "4                  -0.04             0.46  ...               8.26   \n",
       "...                  ...              ...  ...                ...   \n",
       "1250226            -0.61             0.39  ...              11.13   \n",
       "1250227            -0.61             0.39  ...              11.13   \n",
       "1250228            -0.61             0.39  ...              11.13   \n",
       "1250229            -0.61             0.39  ...              11.14   \n",
       "1250230            -0.61             0.39  ...              11.14   \n",
       "\n",
       "         m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristPosX  \\\n",
       "0                   352.22             350.74               0.73   \n",
       "1                   352.27             350.77               0.73   \n",
       "2                   352.29             350.81               0.73   \n",
       "3                   352.28             350.81               0.73   \n",
       "4                   352.23             350.85               0.73   \n",
       "...                    ...                ...                ...   \n",
       "1250226             198.30               3.76              -1.32   \n",
       "1250227             198.37               3.79              -1.32   \n",
       "1250228             198.42               3.84              -1.32   \n",
       "1250229             198.47               3.87              -1.32   \n",
       "1250230             198.51               3.90              -1.32   \n",
       "\n",
       "         m_avg_R_WristPosY  m_avg_R_WristPosZ  m_avg_R_WristRotX  \\\n",
       "0                     0.94               0.63               0.20   \n",
       "1                     0.94               0.63               0.11   \n",
       "2                     0.94               0.63               0.15   \n",
       "3                     0.94               0.63               0.24   \n",
       "4                     0.94               0.63               0.39   \n",
       "...                    ...                ...                ...   \n",
       "1250226               1.04               0.93              47.17   \n",
       "1250227               1.04               0.92              47.21   \n",
       "1250228               1.04               0.92              47.29   \n",
       "1250229               1.04               0.92              47.36   \n",
       "1250230               1.04               0.93              47.44   \n",
       "\n",
       "         m_avg_R_WristRotY  m_avg_R_WristRotZ  Unnamed: 128  \n",
       "0                   359.56               0.85           NaN  \n",
       "1                   359.54               0.88           NaN  \n",
       "2                   359.53               0.92           NaN  \n",
       "3                   359.54               0.96           NaN  \n",
       "4                   359.57               0.96           NaN  \n",
       "...                    ...                ...           ...  \n",
       "1250226              37.40             178.72           NaN  \n",
       "1250227              37.33             178.62           NaN  \n",
       "1250228              37.23             178.46           NaN  \n",
       "1250229              37.14             178.29           NaN  \n",
       "1250230              37.06             178.13           NaN  \n",
       "\n",
       "[1250231 rows x 129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250231"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_columns = [col for col in combined_df.columns if 'Rot' in col]\n",
    "rotation_df = combined_df[rotation_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -180~180 사이로 정규화\n",
    "normalize_angle = lambda x: (x - 360) if x > 180 else (x + 360) if x < -180 else x\n",
    "rotation_df = rotation_df.apply(lambda col: col.apply(normalize_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.78</td>\n",
       "      <td>-9.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.63</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-6.61</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.72</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.77</td>\n",
       "      <td>-9.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0             -1.18              0.68             -0.16            -0.28   \n",
       "1             -1.18              0.68             -0.16            -0.28   \n",
       "2             -1.18              0.68             -0.16            -0.28   \n",
       "3             -1.18              0.68             -0.16            -0.28   \n",
       "4             -1.18              0.68             -0.16            -0.28   \n",
       "\n",
       "   m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0             0.11            -0.02             -0.93              0.18   \n",
       "1             0.11            -0.02             -0.93              0.18   \n",
       "2             0.11            -0.02             -0.93              0.18   \n",
       "3             0.11            -0.02             -0.93              0.18   \n",
       "4             0.11            -0.02             -0.93              0.18   \n",
       "\n",
       "   m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "0             -0.09               0.04  ...                 1.8   \n",
       "1             -0.09               0.04  ...                 1.8   \n",
       "2             -0.09               0.04  ...                 1.8   \n",
       "3             -0.09               0.04  ...                 1.8   \n",
       "4             -0.09               0.04  ...                 1.8   \n",
       "\n",
       "   m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "0                  9.14                 -0.34                 -6.66   \n",
       "1                  9.14                 -0.35                 -6.63   \n",
       "2                  9.13                 -0.37                 -6.61   \n",
       "3                  9.12                 -0.39                 -6.62   \n",
       "4                  9.12                 -0.35                 -6.60   \n",
       "\n",
       "   m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  \\\n",
       "0               8.26              -7.78              -9.26               0.20   \n",
       "1               8.27              -7.73              -9.23               0.11   \n",
       "2               8.27              -7.71              -9.19               0.15   \n",
       "3               8.27              -7.72              -9.19               0.24   \n",
       "4               8.26              -7.77              -9.15               0.39   \n",
       "\n",
       "   m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "0              -0.44               0.85  \n",
       "1              -0.46               0.88  \n",
       "2              -0.47               0.92  \n",
       "3              -0.46               0.96  \n",
       "4              -0.43               0.96  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 프레임과의 차이를 계산하여 변화량 DataFrame을 생성\n",
    "rotation_change_df = rotation_df.diff().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량을 계산하는 함수\n",
    "def calculate_average_change(rotation_df):\n",
    "    rotation_change_df = rotation_df.diff().abs()\n",
    "    # 첫 번째 행의 NaN 값을 0으로 채우기 (또는 다른 합리적인 값으로 채울 수 있음)\n",
    "    rotation_change_df.iloc[0] = rotation_change_df.iloc[0].fillna(0)\n",
    "    # 모든 joint의 변화량에 대한 평균을 계산\n",
    "    average_change = rotation_change_df.mean(axis=1)\n",
    "    return average_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량을 기준으로 데이터를 1, 2, 3단계로 나누는 함수\n",
    "def categorize_average_change(average_change, thresholds):\n",
    "    # 변화량에 따라 범주화\n",
    "    categories = np.digitize(average_change, thresholds)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame에 변화량 범주를 추가하는 함수\n",
    "def add_change_category_to_df(rotation_df, thresholds):\n",
    "    average_change = calculate_average_change(rotation_df)\n",
    "    change_categories = categorize_average_change(average_change, thresholds)\n",
    "    rotation_df['Rot_diff_category'] = change_categories\n",
    "    return rotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 설정 (예: [5, 10])\n",
    "thresholds = [5, 10]\n",
    "combined_df = add_change_category_to_df(rotation_df, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범위를 벗어나는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# -180 ~ 180 범위를 벗어나는 값이 있는지 확인\n",
    "num_values_out_of_range = (combined_df > 180).sum().sum() + (combined_df < -180).sum().sum()\n",
    "\n",
    "# 결과 확인\n",
    "if num_values_out_of_range > 0:\n",
    "    print(f\"범위를 벗어나는 값의 수: {num_values_out_of_range}\")\n",
    "else:\n",
    "    print(\"범위를 벗어나는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot_diff_category\n",
      "0    1161534\n",
      "1      59415\n",
      "2      29282\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = combined_df['Rot_diff_category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Rot_diff_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.78</td>\n",
       "      <td>-9.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.63</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-6.61</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.72</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.77</td>\n",
       "      <td>-9.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0             -1.18              0.68             -0.16            -0.28   \n",
       "1             -1.18              0.68             -0.16            -0.28   \n",
       "2             -1.18              0.68             -0.16            -0.28   \n",
       "3             -1.18              0.68             -0.16            -0.28   \n",
       "4             -1.18              0.68             -0.16            -0.28   \n",
       "\n",
       "   m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0             0.11            -0.02             -0.93              0.18   \n",
       "1             0.11            -0.02             -0.93              0.18   \n",
       "2             0.11            -0.02             -0.93              0.18   \n",
       "3             0.11            -0.02             -0.93              0.18   \n",
       "4             0.11            -0.02             -0.93              0.18   \n",
       "\n",
       "   m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_ShoulderRotX  \\\n",
       "0             -0.09               0.04  ...                  9.14   \n",
       "1             -0.09               0.04  ...                  9.14   \n",
       "2             -0.09               0.04  ...                  9.13   \n",
       "3             -0.09               0.04  ...                  9.12   \n",
       "4             -0.09               0.04  ...                  9.12   \n",
       "\n",
       "   m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  m_avg_R_ElbowRotX  \\\n",
       "0                 -0.34                 -6.66               8.26   \n",
       "1                 -0.35                 -6.63               8.27   \n",
       "2                 -0.37                 -6.61               8.27   \n",
       "3                 -0.39                 -6.62               8.27   \n",
       "4                 -0.35                 -6.60               8.26   \n",
       "\n",
       "   m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  m_avg_R_WristRotY  \\\n",
       "0              -7.78              -9.26               0.20              -0.44   \n",
       "1              -7.73              -9.23               0.11              -0.46   \n",
       "2              -7.71              -9.19               0.15              -0.47   \n",
       "3              -7.72              -9.19               0.24              -0.46   \n",
       "4              -7.77              -9.15               0.39              -0.43   \n",
       "\n",
       "   m_avg_R_WristRotZ  Rot_diff_category  \n",
       "0               0.85                  0  \n",
       "1               0.88                  0  \n",
       "2               0.92                  0  \n",
       "3               0.96                  0  \n",
       "4               0.96                  0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('./combined_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터를 DataFrame으로 변환\n",
    "combined_df = pd.DataFrame(combined_df, columns=combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined_df.iloc[:897757]\n",
    "test = combined_df.iloc[897757:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_input = 30  # Sequence length\n",
    "n_features = 64  # Number of features\n",
    "output_units = (21 * 3) + 1  # Output shape\n",
    "head_size = 256  # Size of attention head\n",
    "num_heads = 8  # Number of attention heads\n",
    "ff_dim = 512  # Hidden layer size in feed forward network inside transformer\n",
    "num_blocks = 4  # Number of transformer blocks\n",
    "mlp_units = [512, 256, 128]  # Size of the dense layers of the final classifier\n",
    "dropout_rate = 0.3 \n",
    "\n",
    "# TimeseriesGenerator 생성\n",
    "train_generator = TimeseriesGenerator(X_train.values, X_train.values, length=n_input, batch_size=batch_size)\n",
    "val_generator = TimeseriesGenerator(X_val.values, X_val.values, length=n_input, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 30, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0800e+00,  1.1200e+00,  1.0000e-02, ..., -8.1000e-01,\n",
       "         9.1000e-01,  0.0000e+00],\n",
       "       [-1.0800e+00,  1.1200e+00,  1.0000e-02, ..., -8.3000e-01,\n",
       "         9.0000e-01,  0.0000e+00],\n",
       "       [-1.0800e+00,  1.1200e+00,  1.0000e-02, ..., -8.7000e-01,\n",
       "         8.7000e-01,  0.0000e+00],\n",
       "       ...,\n",
       "       [-5.7600e+00, -1.1000e+00, -3.8900e+00, ..., -1.3011e+02,\n",
       "         4.3780e+01,  0.0000e+00],\n",
       "       [-5.7800e+00, -1.1600e+00, -3.8700e+00, ..., -1.3085e+02,\n",
       "         4.4590e+01,  0.0000e+00],\n",
       "       [-5.7800e+00, -1.1600e+00, -3.8700e+00, ..., -1.3135e+02,\n",
       "         4.5340e+01,  0.0000e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.initializers import HeNormal\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-Head Attention\n",
    "    attention_out = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    attention_out = layers.Dropout(dropout)(attention_out)\n",
    "    attention_out = layers.LayerNormalization(epsilon=1e-6)(inputs + attention_out)\n",
    "\n",
    "    # Feed Forward\n",
    "    ff_out = layers.Dense(ff_dim, activation=\"relu\", kernel_initializer=HeNormal())(attention_out)\n",
    "    ff_out = layers.Dropout(dropout)(ff_out)\n",
    "    ff_out = layers.Dense(inputs.shape[-1])(ff_out)\n",
    "    ff_out = layers.LayerNormalization(epsilon=1e-6)(attention_out + ff_out)\n",
    "    return ff_out\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_blocks, output_units, dropout=0, mlp_units=[]):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = transformer_block(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    for units in mlp_units:\n",
    "        x = layers.Dense(units, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(output_units, activation=\"linear\")(x)  # Sigmoid activation for output layer\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Building the model\n",
    "model = build_transformer_model(\n",
    "    input_shape=(n_input, n_features),\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_blocks=num_blocks,\n",
    "    dropout=dropout_rate,\n",
    "    mlp_units=mlp_units,\n",
    "    output_units=output_units\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  # patience를 7에서 15로 증가\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.00001)  # patience를 4에서 7로 증가, min_lr를 더 낮춤\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "csv_logger = CSVLogger('training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(Loss):\n",
    "    # def __init__(self, weighted_columns_indices, weight_for_weighted_columns, weights_for_rot_diff_category, **kwargs):\n",
    "    def __init__(self, weighted_columns_indices, weight_for_weighted_columns, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weighted_columns_indices = tf.constant(weighted_columns_indices, dtype=tf.int32)\n",
    "        self.weight_for_weighted_columns = weight_for_weighted_columns\n",
    "        # self.weights_for_rot_diff_category = tf.constant(weights_for_rot_diff_category, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # y_pred의 마지막 feature를 rot_diff_category로 분리\n",
    "        y_pred_values = y_pred[:, :-1]\n",
    "        rot_diff_pred = y_pred[:, -1]\n",
    "\n",
    "        # 런타임에 형태 확인\n",
    "        # tf.print(\"y_true shape:\", tf.shape(y_true))\n",
    "        # tf.print(\"y_pred_values shape:\", tf.shape(y_pred_values))\n",
    "\n",
    "        # MSE 계산\n",
    "        mse = tf.reduce_mean(tf.square(y_true[:, :-1] - y_pred_values), axis=-1)\n",
    "\n",
    "        # 특정 joint rotation에 대한 가중치 적용\n",
    "        weighted_mse = tf.gather(y_pred_values, self.weighted_columns_indices, axis=1)\n",
    "        weighted_mse = tf.square(weighted_mse) * self.weight_for_weighted_columns\n",
    "        mse += tf.reduce_mean(weighted_mse, axis=-1)\n",
    "\n",
    "        # rot_diff_category에 따른 가중치 적용\n",
    "        # for category in range(len(self.weights_for_rot_diff_category)):\n",
    "        #     category_mask = tf.cast(tf.equal(rot_diff_pred, category), tf.float32)\n",
    "        #     category_mask = tf.expand_dims(category_mask, -1)  \n",
    "        #     weighted_mse = tf.square(y_true[:, :-1] - y_pred_values) * category_mask\n",
    "        #     mse += self.weights_for_rot_diff_category[category] * tf.reduce_mean(weighted_mse, axis=-1)\n",
    "\n",
    "        return mse\n",
    "\n",
    "# 가중치를 적용할 열 인덱스와 가중치 값\n",
    "weighted_columns_indices = [42, 43, 44, 48, 49, 50, 60, 61, 62]  # 예시 인덱스\n",
    "weight_for_weighted_columns = 2.0\n",
    "# weights_for_rot_diff_category = [1.0, 1.5, 2.0]  # 1단계, 2단계, 3단계에 대한 가중치\n",
    "\n",
    "# CustomLoss 인스턴스 생성\n",
    "custom_loss_instance = CustomLoss(\n",
    "    weighted_columns_indices=weighted_columns_indices,\n",
    "    weight_for_weighted_columns=weight_for_weighted_columns,\n",
    "    # weights_for_rot_diff_category=weights_for_rot_diff_category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss=custom_loss_instance)\n",
    "# model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 30, 64)      530496      ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 30, 64)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 30, 64)      0           ['input_1[0][0]',                \n",
      " da)                                                              'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 30, 64)      128         ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30, 512)      33280       ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 30, 512)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30, 64)       32832       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 30, 64)      0           ['layer_normalization[0][0]',    \n",
      " mbda)                                                            'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 30, 64)      530496      ['layer_normalization_1[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 30, 64)       0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 30, 512)      33280       ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 30, 512)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 30, 64)       32832       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 30, 64)      530496      ['layer_normalization_3[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 30, 64)       0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30, 512)      33280       ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 30, 512)      0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30, 64)       32832       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 30, 64)      530496      ['layer_normalization_5[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 30, 64)       0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30, 512)      33280       ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 30, 512)      0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 30, 64)       32832       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_7[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30, 512)      33280       ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 30, 512)      0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 30, 512)     1024        ['dropout_8[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30, 256)      131328      ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 30, 256)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 30, 256)     512         ['dropout_9[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 30, 128)      32896       ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 30, 128)      0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 30, 128)     256         ['dropout_10[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_10[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           8256        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,595,008\n",
      "Trainable params: 2,595,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Current device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# 사용 가능한 GPU 목록을 출력합니다.\n",
    "print(\"Available GPUs:\", tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "# 현재 장치를 출력합니다.\n",
    "print(\"Current device:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5611/5611 [==============================] - 179s 31ms/step - loss: 3590.8811 - val_loss: 3299.9722 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 2943.7317 - val_loss: 2867.0986 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "5611/5611 [==============================] - 171s 30ms/step - loss: 2631.5383 - val_loss: 2693.6155 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2473.1699 - val_loss: 2641.8591 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2367.5496 - val_loss: 2583.1538 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2290.6519 - val_loss: 2541.2759 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2234.3271 - val_loss: 2489.6631 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2189.2725 - val_loss: 2547.4214 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2155.3308 - val_loss: 2515.9675 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2122.7446 - val_loss: 2418.2988 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2091.1067 - val_loss: 2384.7202 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2058.4165 - val_loss: 2371.2759 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2027.4392 - val_loss: 2333.0059 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 2001.2913 - val_loss: 2358.1658 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1974.5371 - val_loss: 2314.3708 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1947.6580 - val_loss: 2299.2217 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1923.0272 - val_loss: 2281.5354 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 1899.0121 - val_loss: 2275.6826 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1873.4495 - val_loss: 2224.8687 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1848.6316 - val_loss: 2235.7964 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1821.9746 - val_loss: 2173.1802 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1792.2587 - val_loss: 2154.8062 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1759.0181 - val_loss: 2135.9802 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1728.1520 - val_loss: 2148.8665 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 1700.2389 - val_loss: 2132.2861 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 1676.4762 - val_loss: 2128.9548 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 1655.4236 - val_loss: 2167.6230 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1634.2786 - val_loss: 2082.4070 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1617.7303 - val_loss: 2100.2737 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1600.7866 - val_loss: 2130.6299 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1586.8606 - val_loss: 2114.3218 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 1570.3748 - val_loss: 2032.8942 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "5611/5611 [==============================] - 173s 31ms/step - loss: 1558.2317 - val_loss: 2125.1057 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "5611/5611 [==============================] - 171s 30ms/step - loss: 1544.4781 - val_loss: 2105.3147 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "5611/5611 [==============================] - 171s 30ms/step - loss: 1533.3284 - val_loss: 2050.7598 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "5611/5611 [==============================] - 171s 30ms/step - loss: 1519.5437 - val_loss: 2074.0693 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1509.4363 - val_loss: 2056.3474 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1496.1370 - val_loss: 2085.3157 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1485.2686 - val_loss: 2037.7832 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1440.5123 - val_loss: 2016.9265 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1431.6235 - val_loss: 2015.5116 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1426.5399 - val_loss: 2000.9515 - lr: 2.0000e-05\n",
      "Epoch 43/50\n",
      "5611/5611 [==============================] - 175s 31ms/step - loss: 1422.1708 - val_loss: 2004.0280 - lr: 2.0000e-05\n",
      "Epoch 44/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1418.2452 - val_loss: 2018.3951 - lr: 2.0000e-05\n",
      "Epoch 45/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1414.2128 - val_loss: 2015.2672 - lr: 2.0000e-05\n",
      "Epoch 46/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1409.8450 - val_loss: 2008.8868 - lr: 2.0000e-05\n",
      "Epoch 47/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1405.9260 - val_loss: 1996.3434 - lr: 2.0000e-05\n",
      "Epoch 48/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1402.3646 - val_loss: 2011.0209 - lr: 2.0000e-05\n",
      "Epoch 49/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1397.9648 - val_loss: 2008.1047 - lr: 2.0000e-05\n",
      "Epoch 50/50\n",
      "5611/5611 [==============================] - 172s 31ms/step - loss: 1394.3557 - val_loss: 1991.0082 - lr: 2.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211d56f54c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=50, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint, csv_logger]\n",
    "    # callbacks=[reduce_lr, model_checkpoint, csv_logger]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model_Transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2185c2fc790>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPG0lEQVR4nO3deXhU1eHG8e9kJYRkQoBsEPZFkUU2IYigIFtBQG3FjaK1WBdoKdAFbau2KqhVf7aodWm1tQpaKxYVIsiqQNgju7KvCcGQTBZCEpL7++MkE8JmJpnkZpL38zz3mZk7Z2bOXJF5OavDsiwLERERER/jZ3cFRERERCpDIUZERER8kkKMiIiI+CSFGBEREfFJCjEiIiLikxRiRERExCcpxIiIiIhPUogRERERnxRgdwWqS3FxMcePHycsLAyHw2F3dURERKQCLMsiOzubuLg4/Pwu39ZSZ0PM8ePHiY+Pt7saIiIiUglHjhyhRYsWly1TZ0NMWFgYYC5CeHi4zbURERGRisjKyiI+Pt79O345dTbElHYhhYeHK8SIiIj4mIoMBdHAXhEREfFJCjEiIiLikxRiRERExCcpxIiIiIhPUogRERERn6QQIyIiIj5JIUZERER8kkKMiIiI+CSFGBEREfFJCjEiIiLikxRiRERExCcpxIiIiIhPUojx0I4dMGMGPPOM3TURERGp3xRiPHTkCDz/PMyda3dNRERE6jeFGA/FxJjb1FR76yEiIlLfKcR4qDTEnDwJRUX21kVERKQ+U4jxULNm4OcHxcUmyIiIiIg9FGI85O9vggzAiRP21kVERKQ+U4iphOhoc6txMSIiIvZRiKkEDe4VERGxn0JMJSjEiIiI2E8hphIUYkREROynEFMJpSFGA3tFRETs41GIefXVV+nWrRvh4eGEh4eTkJDAokWL3M/fc889OByOcke/fv3KvUd+fj5TpkyhadOmhIaGMmbMGI4ePVquTEZGBhMmTMDpdOJ0OpkwYQKZmZmV/5ZepoG9IiIi9vMoxLRo0YLZs2ezceNGNm7cyODBgxk7diw7duxwlxkxYgQpKSnuY+HCheXeY+rUqcyfP5958+bx1VdfkZOTw+jRoyk6Z+W4O++8k+TkZBITE0lMTCQ5OZkJEyZU8at6j7qTRERE7OewLMuqyhtERkby3HPPcd9993HPPfeQmZnJxx9/fNGyLpeLZs2a8c477zB+/HgAjh8/Tnx8PAsXLmT48OHs2rWLzp07k5SURN++fQFISkoiISGB3bt306lTpwrVKysrC6fTicvlIjw8vCpf8QI7d8JVV0HjxnDqlFffWkREpF7z5Pe70mNiioqKmDdvHrm5uSQkJLjPr1ixgqioKDp27MikSZNIS0tzP7dp0yYKCwsZNmyY+1xcXBxdunRhzZo1AKxduxan0+kOMAD9+vXD6XS6y1xMfn4+WVlZ5Y7qUtoSk5EB+fnV9jEiIiJyGR6HmG3bttGoUSOCg4N54IEHmD9/Pp07dwZg5MiRvPvuuyxbtoznn3+eDRs2MHjwYPJLfulTU1MJCgqicePG5d4zOjqa1JK+mdTUVKKioi743KioKHeZi5k1a5Z7DI3T6SQ+Pt7Tr1ZhjRtDYKC5f05GExERkRrkcYjp1KkTycnJJCUl8eCDDzJx4kR27twJwPjx4xk1ahRdunThpptuYtGiRXz77bd89tlnl31Py7JwOBzux+fev1SZ882cOROXy+U+jhw54ulXqzCHQ4N7RURE7OZxiAkKCqJ9+/b07t2bWbNm0b17d1566aWLlo2NjaVVq1bs2bMHgJiYGAoKCsjIyChXLi0tjeiSVBATE8OJi8xdPnnypLvMxQQHB7tnTZUe1UmDe0VEROxV5XViLMtydxedLz09nSNHjhAbGwtAr169CAwMZMmSJe4yKSkpbN++nf79+wOQkJCAy+Vi/fr17jLr1q3D5XK5y9QGCjEiIiL2CvCk8COPPMLIkSOJj48nOzubefPmsWLFChITE8nJyeHxxx/n1ltvJTY2loMHD/LII4/QtGlTbr75ZgCcTif33Xcf06dPp0mTJkRGRjJjxgy6du3KjTfeCMCVV17JiBEjmDRpEq+99hoA999/P6NHj67wzKSaoBAjIiJiL49CzIkTJ5gwYQIpKSk4nU66detGYmIiQ4cOJS8vj23btvGvf/2LzMxMYmNjueGGG3j//fcJCwtzv8eLL75IQEAAt912G3l5eQwZMoS3334bf39/d5l3332Xn//85+5ZTGPGjGHOnDle+sreoVV7RURE7FXldWJqq+pcJwZgzhyYMgVuvRU+/NDrby8iIlIv1cg6MfWdupNERETspRBTSQoxIiIi9lKIqSSFGBEREXspxFRSaYjJzYWcHHvrIiIiUh8pxFRSo0bQsKG5rxlKIiIiNU8hpgrUpSQiImIfhZgqUIgRERGxj0JMFSjEiIiI2Echpgq0aq+IiIh9FGKqoHRTbbXEiIiI1DyFmCpQd5KIiIh9FGKqQCFGRETEPgoxVaAQIyIiYh+FmCo4d2Bv3dwLXEREpPZSiKmCqChzW1AAmZm2VkVERKTeUYipggYNICLC3FeXkoiISM1SiKkijYsRERGxh0JMFSnEiIiI2EMhpooUYkREROyhEFNFpav2ausBERGRmqUQU0VqiREREbGHQkwVKcSIiIjYQyGmMs7mwuljgEKMiIiIXRRiPHX4Q/igEay5E1CIERERsYtCjKcaxpvb7H1A2cDekyehqMimOomIiNRDCjGeCmtvbvOOwdk8mjUDhwOKi+G77+ytmoiISH2iEOOpoEgIjDD3c/YTEADNmpmH6lISERGpOQoxnnI4IKyduZ+zF9C4GBERETsoxFRGo5IupZJxMQoxIiIiNU8hpjLOa4nRqr0iIiI1TyGmMtwtMepOEhERsYtCTGW4W2LUnSQiImIXhZjKKG2JyT0ExYUKMSIiIjZQiKmMkFjwDwGrCHIPKcSIiIjYQCGmMhwOaFTSpZS91x1iNLBXRESk5ijEVFZY2eDe0tlJp05Bfr59VRIREalPFGIqq1HZ4N7GjSEw0DxMS7OvSiIiIvWJQkxlndMS4+dXtlaMxsWIiIjUDIWYymqkadYiIiJ2UoiprNKWmJz9YBVrcK+IiEgNU4iprIbx4BcIxflw+pi6k0RERGqYQkxl+QVAaGtzP2evupNERERqmEJMVZyzh5JCjIiISM1SiKmKc/ZQUogRERGpWQoxVXGRlhgN7BUREakZCjFVcU5LjAb2ioiI1CyFmKo4tyUm2gIgJ8ccIiIiUr0UYqqiURvAAWdzaBR4koYNzWl1KYmIiFQ/hZiq8A8268UADk2zFhERqVEKMVUVpsG9IiIidlCIqapGGtwrIiJiB4WYqrpIS4xCjIiISPVTiKmqRlrwTkRExA4KMVXl3s1aLTEiIiI1SSGmqkpbYvLTaRGdCWhgr4iISE1QiKmqwEbQwIzojW+8D1BLjIiISE1QiPGGki6lmIZ7ARNiLMvOComIiNR9CjHeUNKlFBFgWmIKCiAz08b6iIiI1AMKMd5QsodS4Jm9RESYU+pSEhERqV4KMd4QduE0aw3uFRERqV4KMd5wzm7WWrVXRESkZijEeEPpWjF5x2nZ/DSgECMiIlLdFGK8ITgSAiMA6NxyP6AQIyIiUt0UYrylpDWmQ0zZNGsRERGpPgox3lIyzbqlFrwTERGpEQox3lLSEhNdsuCdZieJiIhUL49CzKuvvkq3bt0IDw8nPDychIQEFi1a5H7esiwef/xx4uLiCAkJ4frrr2fHjh3l3iM/P58pU6bQtGlTQkNDGTNmDEePHi1XJiMjgwkTJuB0OnE6nUyYMIHM2r56XOmCd4FqiREREakJHoWYFi1aMHv2bDZu3MjGjRsZPHgwY8eOdQeVZ599lhdeeIE5c+awYcMGYmJiGDp0KNnZ2e73mDp1KvPnz2fevHl89dVX5OTkMHr0aIqKitxl7rzzTpKTk0lMTCQxMZHk5GQmTJjgpa9cTUpaYhoWmZaYtDQ45yuJiIiIt1lV1LhxY+vNN9+0iouLrZiYGGv27Nnu586cOWM5nU7rb3/7m2VZlpWZmWkFBgZa8+bNc5c5duyY5efnZyUmJlqWZVk7d+60ACspKcldZu3atRZg7d69u8L1crlcFmC5XK6qfsWKOX3cst7FKn7PzwoKyLfAslJTa+ajRURE6gpPfr8rPSamqKiIefPmkZubS0JCAgcOHCA1NZVhw4a5ywQHBzNo0CDWrFkDwKZNmygsLCxXJi4uji5durjLrF27FqfTSd++fd1l+vXrh9PpdJe5mPz8fLKyssodNapBDPg3xGEV06PjIUBdSiIiItXJ4xCzbds2GjVqRHBwMA888ADz58+nc+fOpJb8YkeXLllbIjo62v1camoqQUFBNG7c+LJloqKiLvjcqKgod5mLmTVrlnsMjdPpJD4+3tOvVjUOh3v7gZ4dNLhXRESkunkcYjp16kRycjJJSUk8+OCDTJw4kZ07d7qfdzgc5cpblnXBufOdX+Zi5b/vfWbOnInL5XIfR44cqehX8p6Swb2dW2pwr4iISHXzOMQEBQXRvn17evfuzaxZs+jevTsvvfQSMSU7H57fWpKWluZunYmJiaGgoICMjIzLljlxkSaMkydPXtDKc67g4GD3rKnSo8ZpwTsREZEaU+V1YizLIj8/nzZt2hATE8OSJUvczxUUFLBy5Ur69+8PQK9evQgMDCxXJiUlhe3bt7vLJCQk4HK5WL9+vbvMunXrcLlc7jK1VklLTLwWvBMREal2AZ4UfuSRRxg5ciTx8fFkZ2czb948VqxYQWJiIg6Hg6lTp/L000/ToUMHOnTowNNPP03Dhg258847AXA6ndx3331Mnz6dJk2aEBkZyYwZM+jatSs33ngjAFdeeSUjRoxg0qRJvPbaawDcf//9jB49mk6dOnn563tZ6YJ3oWqJERERqW4ehZgTJ04wYcIEUlJScDqddOvWjcTERIYOHQrAr3/9a/Ly8njooYfIyMigb9++LF68mLCwMPd7vPjiiwQEBHDbbbeRl5fHkCFDePvtt/H393eXeffdd/n5z3/unsU0ZswY5syZ443vW70amRAT4b8fP0cRJ074f88LREREpLIclmVZdleiOmRlZeF0OnG5XDU3Pqa4CD4IgeJCWv78EGHRLTlvwWIRERG5DE9+v7V3kjf5+UNoGwDaR+9Vd5KIiEg1UojxtpLBve2i93HqFOTk2FwfERGROkohxttKBvde3c4M7v36azsrIyIiUncpxHhbSUtMaYjZssXOyoiIiNRdCjHeVtIS0zbKrBWjECMiIlI9FGK8rSTENGuwF7DYvNne6oiIiNRVCjHeFtoacBBALlHhaezYAQUFdldKRESk7lGI8Tb/YAhtCZjdrAsL0VoxIiIi1UAhpjqUDO4d2NOMi1GXkoiIiPcpxFSHknExvTtphpKIiEh1UYipDiUtMR1iFGJERESqi0JMdXDvZm26k5KToajIxvqIiIjUQQox1aFkN+sGZ/cSEmJx+jTs2WNznUREROoYhZjqENYe/IJwFJzilsHbAHUpiYiIeJtCTHUIaAhxPwDg7uvmAZqhJCIi4m0KMdWl1R0A9G8+D7DUEiMiIuJlCjHVpfloCAgl3O8AfduvY8sWsCy7KyUiIlJ3KMRUl4CG0HwsAHddO5dTp+DwYZvrJCIiUocoxFSn1qZL6fb+H+DnKFKXkoiIiBcpxFSnmGEQ1JhmjVIZdOVKhRgREREvUoipTv5BEH8rAHf0n6sZSiIiIl6kEFPdSmYp3drnv2zfWmBzZUREROoOhZjqFjWI4uBYIhtlcFWTxaSl2V0hERGRukEhprr5+ePX+jYA7kiYq3ExIiIiXqIQUxNKupTG9vof25JP21wZERGRukEhpiY0uYbMs21o1CCXgNRP7K6NiIhInaAQUxMcDk6F3Q5A50bzbK6MiIhI3aAQU0MiupsupUHtF5KVnmlvZUREROoAhZgaEtm2K9+kXkVwYAGp6+fbXR0RERGfpxBTgzakmS6l4BNzba6JiIiI71OIqUGl42LiA5fCGS0YIyIiUhUKMTWoVZf2rN/XBz9HMRz+j93VERER8WkKMTWoRw+Yu8YM8C0+oC4lERGRqlCIqUHx8bDk29soLnbgl74acg/bXSURERGfpRBTgxwOiG3bnFW7B5oTh963t0IiIiI+TCGmhvXoAXPXmi4lDqlLSUREpLIUYmpYz57w4fofcrYoADK2QNY3dldJRETEJynE1LAePeBUThO+2DHMnDio1hgREZHKUIipYR06QGgovLvarBnD4XlgWfZWSkRExAcpxNQwPz+4+mr4eOM4zloNTHfStscVZERERDykEGODHj0g50wYnx97zJzY/kdY+2Moyre3YiIiIj5EIcYGPXqY2z8v+i1c8wY4/OHgv2H5MMg/ZW/lREREfIRCjA169jS3yclgtfspXL8IAsMhbRUsToDsvbbWT0RExBcoxNigc2cIDITMTDh4EIgdCkPXQMOWkP0tLO4HJ1fbXEsREZHaTSHGBkFB0KWLub95c8nJiKtg+DqI7A356bB0MBycZ1sdRUREajuFGJuUjovZsuWckyExcONKaDEOigtgzR2w/SnNXBIREbkIhRiblI6LKRdiAAIawoAP4Yrp5vHW38G6n0BRQY3WT0REpLZTiLFJaUuMuzvpXH7+0PPP0OcVcPjB/rfhqx9pCraIiMg5FGJs0q2b2dU6NRVSUi5RqMODMHAB+AXDsQWw6mYoOlOj9RQREamtFGJs0qgRdO1q7n/22WUKNh8F138K/iGQsghWjoGzp2ukjiIiIrWZQoyN7rrL3L711vcUjLnRrCUTEAqpS2DFKCjMqfb6iYiI1GYKMTaaMAH8/WHNGti9+3sKRw+CGz6HgDBIWwErRkJhVk1UU0REpFZSiLFRbCyMGGHuv/12BV7Q7FoYvAQCnXDyK1g2HAoyq7GGIiIitZdCjM1+8hNz+69/wdmzFXhB074wZCkENYb0JFg2VPstiYhIvaQQY7PRo6FpUzNDafHiCr4oshcMWQ7BTeHURlg2BM58V631FBERqW0UYmwWFFQ2wPcf//DghY27w5AV0CAaMpJh6Q2Ql+r9CoqIiNRSCjG1wL33mtsFC+A7TxpUIq4yQSYkFlzbYWE3OLqgGmooIiJS+yjE1ALdu5ttCAoL4b33PHyx8wq4cRVEdIX8k7BqLKybBIXZ1VJXERGR2kIhppYobY353jVjLiasPQxfD1fOAByw701YdDWcXOPFGoqIiNQuCjG1xJ13mvExyckX2RSyIvwbQI/nYMgyaNgScvbDF9fB149q80gREamTFGJqichIGDvW3K9Ua0yp6OvhB1uhzY/BKoYdT8PifuDa6Y1qioiI1BoKMbVI6Zox774L+VXZsDrICQn/hAH/gaBIyNgCib3gm7+YYFMVRfmwdiJ8eiXsfROKC6v2fiIiIpWkEFOLDB0KzZvDqVPwySdeeMOWP4RR2yF2hNn9etMvzAaSlR30ezYPVo2DA/+CrN2wfhJ8dhUcnFf1cCQiIuIhhZhaxN8ffvxjc79KXUrnComF6xdC75fNuJnjn8GSAXD6qGfvU5gDK0dBSiL4N4Qrfw3BzSB7D6y5Axb1gKOfgGV5qeIiIiKXpxBTy9xzj7lNTIRjx7z0pg4HdHwIhqw0i+NlboXP+8KpzRV7fYELlg+DE8vNBpQ3fA49noEx+6Hbk2Yvp8ytsGoMLO5vyomIiFQzj0LMrFmz6NOnD2FhYURFRTFu3Di++eabcmXuueceHA5HuaNfv37lyuTn5zNlyhSaNm1KaGgoY8aM4ejR8i0DGRkZTJgwAafTidPpZMKECWRmZlbuW/qQjh1hwAAoLoZ33vHymze9BoavA+dVkHccvhhoWk8uJz/dbGvw3VqzX9OQpRA1wDwX2Ai6PGrCTOffgn+I2c9p6WBYeiN8t87LX0BERKSMRyFm5cqVPPzwwyQlJbFkyRLOnj3LsGHDyM3NLVduxIgRpKSkuI+FCxeWe37q1KnMnz+fefPm8dVXX5GTk8Po0aMpKipyl7nzzjtJTk4mMTGRxMREkpOTmTBhQhW+qu84d80Yr/fOhLaCoashZiiczYUvx5kBvxeTlwpfXA+nNpmuoyHLoUmfC8sFR8LVs0yY6TgF/ALhxFIzK+rQB17+AiIiIobDsir/M3ny5EmioqJYuXIlAwcOBExLTGZmJh9//PFFX+NyuWjWrBnvvPMO48ePB+D48ePEx8ezcOFChg8fzq5du+jcuTNJSUn07dsXgKSkJBISEti9ezedOnX63rplZWXhdDpxuVyEh4dX9ivaIjsbYmLg9GlYvRr696+GDykuhA0Pw743zOOOk6Hni+AXYB6fPgpLh0D2txASB4O/AOeVFXvvnIOQ/Gs4/B9oEAWjd5tWHBERke/hye93lcbEuFwuACIjI8udX7FiBVFRUXTs2JFJkyaRlpbmfm7Tpk0UFhYybNgw97m4uDi6dOnCmjVmhdm1a9fidDrdAQagX79+OJ1Od5nz5efnk5WVVe7wVWFh8KMfmfsebQrpCb9AuOY1uPpZ8/jbOWbmUWEO5ByAJQNNgGnY0mxrUNEAA9CoNST8G8KvhDNpkPxIdXwDERGp5yodYizLYtq0aQwYMIAuXbq4z48cOZJ3332XZcuW8fzzz7NhwwYGDx5MfsnCJ6mpqQQFBdG4cfl/mUdHR5OamuouExUVdcFnRkVFucucb9asWe7xM06nk/j4+Mp+tVqhdM2Y99+H83rrvMfhgM6/ggEflp+5tOQ6yD0AjdrD0C8hrJ3n7+0fBH1eNff3vqbxMSIi4nWVDjGTJ09m69atzJ07t9z58ePHM2rUKLp06cJNN93EokWL+Pbbb/nss88u+36WZeFwONyPz71/qTLnmjlzJi6Xy30cOXKkEt+q9rjuOmjXDnJy4L//reYPa3mr2Q27QRRkfg15x8DZGYaugtCWlX/f6EFm5WAs2PAAFJ/1UoVFREQqGWKmTJnCggULWL58OS1atLhs2djYWFq1asWePXsAiImJoaCggIyMjHLl0tLSiI6Odpc5ceLEBe918uRJd5nzBQcHEx4eXu7wZQ5H2XRrr60ZczlN+8KwddDsWoi+wYSakNiqv2+P58x4mIxk02UlIiLiJR6FGMuymDx5Mh999BHLli2jTZs23/ua9PR0jhw5Qmys+UHs1asXgYGBLFmyxF0mJSWF7du3079kBGtCQgIul4v169e7y6xbtw6Xy+UuUx9MnGjCzIoVsH9/DXxgo9Yw9CuziWSDZt55zwZRcPUz5v7W33u+yJ6IiMgleBRiHn74Yf7973/z3nvvERYWRmpqKqmpqeTl5QGQk5PDjBkzWLt2LQcPHmTFihXcdNNNNG3alJtvvhkAp9PJfffdx/Tp01m6dClbtmzh7rvvpmvXrtx4440AXHnllYwYMYJJkyaRlJREUlISkyZNYvTo0RWamVRXxMebrQgAZs+2ty5V0u4+aJoAZ3Ng0y/tro2IiNQVlgeAix5vvfWWZVmWdfr0aWvYsGFWs2bNrMDAQKtly5bWxIkTrcOHD5d7n7y8PGvy5MlWZGSkFRISYo0ePfqCMunp6dZdd91lhYWFWWFhYdZdd91lZWRkVLiuLpfLAiyXy+XJV6x1vvzSssCy/PwsKznZ7tpUwalky3rP37LexbKOfmZ3bUREpJby5Pe7SuvE1Ga+vE7M+caPhw8+gBtugKVLTReTT9o8A3Y/D6FtzMaUAQ3trpGIiNQyNbZOjNSMZ56B4GBYvhwWLLC7NlXQ9XFo2MJM397xtN21ERERH6cQ4wNat4Zp08z9GTOgoMDW6lReYCPoVbLFwa5nwbXL3vqIiIhPU4jxETNnQnQ07N0Lc3x5pnKLcRA3qmTbg4eqYXMoERGpLxRifERYGDxd0gPzxz/CyZP21qfSHA7o/Vez43XaCjj4b7trJCIiPkohxodMnAg9eoDLBY89ZndtqqBRG+jyB3N/83TIP2VvfURExCcpxPgQf3948UVz/7XXYPt2e+tTJVdMM1sb5J+ELwbC8US7ayQiIj5GIcbHDBoEt9wCxcXwy1/68JAS/yDo+xYERYJrB6wYCcuGQ+Y2u2smIiI+QiHGBz37LAQFwRdfwPfsq1m7Nb0Gxuw1rTJ+gZC6GBZdDesmQd7FdysXEREppRDjg9q1g6lTzf3p06Gw0NbqVE1QY+j5PIzaBfE/BKsY9r0Jn7SHbX+Cs6ftrqGIiNRSCjE+6tFHISoKvv0WXnnF7tp4QVg7uO4/MHQ1NOkHZ3Nh2x/gkw6w/20TbkRERM6hbQd82BtvwP33Q0SEWT+mSRO7a+QllgWHP4Dk30LuQXMuKNJsIll6NLnGLJ4nIiJ1iie/3woxPqyoCHr2hK1bYfJk+Otf7a6RlxWdgW/nwPanoDCz/HMOP3B2hWb9y4JNo3Y+vLGUiIiAQgxQP0IMwLJlMGSImX69dSt07mx3japBUQFkJMN3a8uO04cvLBd+JVzzN4gaWONVFBER71CIof6EGIBx4+B//4M+feDLL81mkXXe6eMlgWaNuT21CYpLNpVqNwl6PAtBEbZWUUREPKddrOuZl16CyEjYsAF+/nO7a1NDGsZBy1vNzKZha+CWE9D+fvPcvjfg0yvh8IcVX0inuAiOfQrLR8KHkbD7RR9ehEdEpH5QiKkDWrWC994zw0Fefx3+8Q+7a2SDoAi45jW4cSWEd4IzqfDVj2DVODh99NKvy0+Hnc+aWVArb4KURCjIgM3TYOVoOJNWU99AREQ8pBBTRwwfbjaGBHjoIdi82d762CZqIIxMhi6/NwvoHVsAn3aGb+aY1pZS6Rsh6V6Y3xySfwO5B8yaNVdMhx7Pg38DOL4QFnaH1KW2fR0REbk0jYmpQ4qLYexY+PRTaN0aNm6sQ9OuKyNzB6yfZMbMgFl/pu2Pzboz6evLyjXuCR0fhla3Q0DDktduh9W3my0RcEDn30C3P5pgJCIi1UYDe6mfIQYgMxN694Z9+0zrzGefmZlL9ZZVDHv+ZtacOZtddt4vCFr+CDpOhiZ9Lz41++xp06209zXzuMk1cO1caNS2ZuouIlIPaWBvPRYRAf/9L4SEwOefwxNP2F0jmzn8oONDMHqn2dYgrCN0fwrGHYH+/4am/S69tkxAQzNle8CHEBhhWm8W9YCD82r0K4iIyMWpJaaO+ve/YcIEc/+TT2D0aHvr4/NyD8OaO+HkavO47b3Q7U/QsLm99RIRqWPUEiPcfbdZxbf0/t699tbH54W2hCEroMsfTOvO/rfg4xbwSUdYdz8cnGvWrhERkRqjlpg6rKAArr8e1q6Fbt3MbcOGdteqDjix0sxoOrXhwo0pwzpC9A0QdT1EXw8hMXbUUETEZ2lgLwoxpY4dM/srpaWZFpl//UvbC3lNgQtOfgknVsCJ5ZCxBTjvfydnF2g+CuJGm/E3fgF21FRExGcoxKAQc64VK+DGG82GkS++CFOn2l2jOqogE9JWmVCTthwyvqZcqAlqDLEjIG4UxI2A4Po8/11E5OIUYlCIOd/zz8OMGWX3p02ztz71Qn46pHwOxz6DlEVmJeBSDj+z83bcKGh2LYTEQUgsBITaV18RkVpAIQaFmPNZFvzmN/Dcc+bx739vpl+ra6mGFJ+F75Lg+GfmyNx28XIBYSbMlB4NSm4jukHsMP0HE5E6TyEGhZiLsSyYPRseecQ8njIF/u//wE9z1Gpe7mETZo4thKydkJcCRXmXf027+6D3K+AfVDN1FBGxgUIMCjGX88or8PDD5v6ECWbDyACNN7WXZUFhlgkzZ1LNbV4KnEkxgefIh2YmVNT1cN1/ITjS7hqLiFQLT36/9dNVDz30EISHwz33wDvvQHY2zJ0LDRrYXbN6zOGAIKc5nFdc+Pyxz8xeTmkrYHE/GPQphHes8WqKiNQm6kiop+6+Gz76CIKD4eOPYdQoyMmxu1ZySc1HwbA10LAlZO8xQebECrtrJSJiK4WYemzMGFi0CBo1gmXLzDTsU6fsrpVcUkRXGL7ebFhZkAHLhsK+f9hdKxER2yjE1HM33ABLl0JkJKxbB4MGQUqK3bWSSwqJhiHLodXtYJ2FdffBll9fuHLw+SzLjLFJ+wqK8mumriIi1UwDewWA7dth2DATYFq3hg8+gD597K6VXJJlwbYnYHvJNuUtxplduQNCTUjJ2mUW28vcWnabf9KUbTYAbkjUmjQiUitpdhIKMZWxf78JMvv2QWAg/PnPZhq2liapxQ7OhaR7oTgfwjqAXzBk7TatNOdz+IEjAIoLIOZGGPQJ+Gs0t4jULgoxKMRUVmYm3HefGfQLcPPNZgp2RISdtZLLOrkWvhwHZ9LKzgVGQOPuENEdGnczt86rIPNrM5bmbI5ZLfi6j7TujIjUKgoxKMRUhWXBnDkwfToUFkKbNvD+++peqtVOHzOL54XEmcDSsMWlm9BOrIQVI6DoDMT/EK6dq40pRaTW8OT3WwN75QIOh+lGWr3aBJgDB+Daa+Gll0zAkVqoYXNofz80Hw2h8ZfvA4weBNd9DH5BZhG9pHu/f2CwiEgtpBAjl9SnD2zeDLfcYlpkpk419zMyvvelUtvFDYcB/zFjZA7+G9Y/oIQqIj5HIUYuKyICPvwQ/vpXCAoyC+P17Anr19tdM6myFmPMjCaHH+x7AzZNVZAREZ+iECPfy+GAyZPLupcOHoT+/U2XU3q63bWTKmk1HvqWLJj37V/g60cUZETEZyjESIX17m26l267DYqKzODf9u3hhRegoMDu2kmltZ0IfV4193fOhh1P2VsfEZEKUogRj0REmJlKX3wB3bubKdnTp0PnzjB/vv4R77M6PAA9XzD3t/4e1j9oVvctLrK3XiIil6EQI5UyZAhs2gR//zvExJgF8m65Ba6/3pwXH3TFL6Hbk+b+3r/BF9fB/Bgze+nIfCj08R1Ccw/B6rtg7UQoLrS7NiLiBVonRqosOxuefdas8HvmjBlD8+Mfw1NPQfPmdtdOPHbsUzg0D459BoWZZef9giFmCDQfA81vgoZxtlXRI8VFsOdlM97nbK45d9Wj0P1Je+slIhelxe5QiLHDkSMwcya8+6553LAhTJsGv/oV6D+BDyouhJNfwdEFcPR/kHug/PORfSB+nNm3KfzK2rk/ReYOWPdTSE8yj51XgWuHmZE1ZCVEDbC3fiJyAYUYFGLstH69CS+rV5vHTZvC738PDzxgpmmLD7IscO2EYwtMqCkNBaXCOpow02IcNO1rQsLFFBeZvZ3S15nju3Wmm6fJNRA7DGKHm6BR1UBUlA87ZsHOp00YCwiDHs9A+59B0k/gwD8htBWM/BqCnFX7LBHxKoUYFGLsZllmoO/MmfDtt+Zc27ami+m228BPo7F8W14qHPsEjn4MqV+YTSVLNYiGFmNNoHF2gVObSkLLekjfAGezL//eIXEm0MQMg5ih0KCpZ3U7uRbW/9SELoC40dDnFbOSMUBhFiy82rQstb4b+r/j2fuLSLVSiEEhprYoLDQbSD7+OKSmmnO9esEzz5jBwVIHFGbB8UQTaI5/Zh5fTkAoRPaGJn1Nq03DlqbbKuVzSFsJRXnnFHZAZE8TaEJbQaATAsMvfhTlwdePwrdzAAuCm0Hvv0LL2y5s2Tm5xgxctoqh/1xofbuXL0qJ00chqAkEhFTP+4vUQQoxKMTUNrm5Zj2ZZ5+FnJJJLsOHw+zZcPXVtlZNvKmoANJWmEBz9GM4c8J0DzXpa7qMmvQFZ+dLbzhZdKYs0KQshsytFf9shz9YJVPC20yEns9DcJNLl9/6B9j+J7Pj9w+2lrXUeEPaKtj6mLkW/g2g2XUlrUtDIaJb9YwfOpNmrlfTaxWaxKcpxKAQU1ulpcGTT8Lf/mZaaRwOuOMO+OMfoV07u2snXmUVm/Eo/sGVf4+8FEhZAidXQf53ppWnMAsKXHC25H7RmbLyoa3hmtdMYPg+xYWwZIDp5oq6HgZ/AX7+la8rmLV1tj0GJ5ZdukyDaIi50QSamKHemeV1Ng8Se0DWN6alK240tPwhxI00j0V8iEIMCjG13b598Lvfwbx55nFAANx3nxkArGnZ4pGiAhNmzuZAwxaXbuW5mKw95sf/bC5c/Qx0/nXl6nByjQkvqV+Yx36B0PY+uGqmqVfKYkhdAidWQNHp8q91XgWdfwNtJlTuswG2/AZ2PQs4gHP+SvcPgbgfQMsfQdwoCGxU+c8QqSEKMSjE+IrNm+HRRyEx0Txu0MDsyfSb30CTy/QEiHjN3jdh/SQTPIatg8geFX/td+tMeEn53Dx2BEC7n8BVj5gxPOcryofv1paFmlObMKHDAUOWQvQNntc/fSMs7mtavgb+zwyMPvwfOPIh5OwvK+ffAGJHmDFCLX/kWdgTqUEKMSjE+JpVq8xMpjVrzOPwcJgxA6ZOhbAwW6smdZ1lwZe3mDE84VfCiI0Q0PDS5QuzTYvL3jcgZZE55/CHtveaRfQata74Z+enm93DD/4bQmJhZDI0iKr464sK4PPekLkNWt0O184t/70ykk2gOfwfyNlb9lzcD2DAB+pqklpJIQaFGF9kWbBwoWmZ+fprc65ZM3jkEbPGTIMG9tZP6rAz38HCrnAmFTo8DH3mlH8+Z79ZwfjYp2awbumUcoc/tPkxdPkdNGpbuc8+mwuJfSBrl1kn5/qFl15n53zb/mhagoKbwqid0KDZxctZlgk6hz+A3S+YmVxN+sH1n15+8LOIDRRiUIjxZcXF8MEHZnzM3pJ/PLZsaQYE33WX1piRanL8c1gxwtwfuACCIkxoOf5p2ZozpRq1M1svdHwYwtpX/bMzt8Pnfcwg5YqOzcncDok9zQDl/u9B6zsq9lkn18DK0VCQAeFXwA2fQ2jLqtW/KgoyzQBu55X21UFqFYUYFGLqgsJCeOsteOIJOH7cnOve3awxM2xY7VzlXnzcxl/At3+58LzD30yTbj7aHGEdvf8HcO/rsP5nZlzN0C+hab9Lly0ugiX9zcyq5jeZsTCe1Me1E5YPN+vYNGwB1ydCxFVV/w6eyDthWoX2vGIGP3eaCj2eNWOTpF5TiEEhpi45fRpeesmsKZNVso7akCFmzZmePe2tm9QxZ/PMINnMbRAUacaONB9tunmCIqr3sy0LVt8Bh98v2RJhCwQ1vnjZXS/Alulmkb9RO6FhJab05R4xQSZrl/mcQZ9Cs/4Ve+3po3D4vyXTuX/g2TTx3MOw6znY92b56fEAUYPg2vchJLri7yd1jkIMCjF10XffmW0LXn7ZtNKAWWPmqaegTRt76yZ1SGEWZO8zi9JVdd2Yynz2oh5mDE78LTDgwwtbWLL3wsJuZlzLNW9A+59W/vPyT5mupe/WmtlL134ALW66eNmiArPVxL6/Q+rnZjZUqcY9TNiLGwVN+lx8TE/2Xtg5Gw78y3SBgVn88KpHwToLayeaLSlCmsN1/zWrOUu9pBCDQkxdduCAWWPmvffM48BAePhhMyC4qYfb7IjUOukbTVdRcSH0fhk6PlT2nFUMS4eYwcXRQ2Dwkqp3a509DV/dZraMcPibYNTu3rLnXbtMcDnwL8g/WXa+2XVmgHP6esqtTdMgCmJHmlATMxROHzGbcR6eVxZ8om8w4SV6cFn9Xbvhy5vNBqF+QWbLiHaT1G9cDynEoBBTH2zebNaT+aJkfbGwMLN79i9/CU5tTCy+bPeLsHka+AXD8CRofLU5v+c12PAA+DeEUduhkZeaIIsLYf39sP9t87jbn8yU731/N600pRrEQNt7oO1PILyDOXcmDY4vMiEo5fPye2c5AkwrS6m4H5jwcqluq8JsSLoHjnxkHre7D3rPMa1EUm8oxKAQU58sWQK//jUkJ5vHjRubx1OmQKiWwRBfZFmwcoyZGRXWEUZsMrOJPrvKdLn0/D+44hfe/8yvZ8LOZ8qfd/ibbqJ2PzXbGFxukbziQrP31bHPTKjJ2g04IP5WswBgRRYStCxTh62PmpabyN6me8nOGVRSoxRiUIipb4qL4aOP4A9/gF27zLmoKLOAntaYEZ905jtYdDXkHYPWE6AgHY4vhKYJcOOX1TdeZ/f/wZYZZt2bdveZdXBCYiv3XjkHTGtMZTbXTFlsBjoXnDLr4Az4oHIrGovPUYhBIaa+KiqCuXPh8cfN/kxg9mJ69FGzN1NQkK3VE/FM2pew9PqysSR+QWZV3+peU6Uwx8w8sns8Ss4Bs5pyRrIZLBw3GlrdYQYfa7XhOsuT328tGyZ1ir8/3H23aY154w2Ij4djx+Chh6BTJ/j73yE/3+5ailRQ1HXQ9Ymyx10fq5lF4QIb2R9gwIz5GbratAZZxXBsAay5A/4bBavvhKMLzKwpqbfUEiN1Wn6+CTNPPQWpqeZcdLTpYnrgAYiJsbd+It+ruAg2Pmy2J+j3j/q7GFzmNjg0Dw7OhdwDZecDI6DlraaFJur6mp8W/32s4opvIyFANXYnzZo1i48++ojdu3cTEhJC//79eeaZZ+jUqZO7jGVZPPHEE7z++utkZGTQt29fXn75Za66qmw1yPz8fGbMmMHcuXPJy8tjyJAhvPLKK7Ro0cJdJiMjg5///OcsWLAAgDFjxvDXv/6ViIgIr18EqftOn4ZXX4UXXzQtM2C6lm6/HX7xCy2aJ+IzLMtM6z40zywMmJdS9lyDaAhtbbrdSg//oPKP/YLMthFRAyGyp/dD4emjphvw5Jfm1rXDfEZgGASEm9vAMAgouQ0MN+dDos0aOQ2bl93W0y6zagsxI0aM4Pbbb6dPnz6cPXuWRx99lG3btrFz505CS6aBPPPMMzz11FO8/fbbdOzYkSeffJJVq1bxzTffEFayHfGDDz7IJ598wttvv02TJk2YPn06p06dYtOmTfj7mxQ9cuRIjh49yuuvvw7A/fffT+vWrfnkk0+8fhGk/igsNAOAX3oJ1p4zc3TAALNj9tixEHCZyRciUosUF8HJVSWB5kMzCNgT/g3NdO9mA02oaXINBIRU/PWWBVnflAWWk19C7kHP6nA5gRHlQ034FWYxwcheJvxU1Nk8SF8HaasgbaVZeDCgIQQ0KglUjUpCVcltQCOzinOza03Qq+GWpBob2Hvy5EmioqJYuXIlAwcOxLIs4uLimDp1Kr/5zW8A0+oSHR3NM888w89+9jNcLhfNmjXjnXfeYfz48QAcP36c+Ph4Fi5cyPDhw9m1axedO3cmKSmJvn3Nqo1JSUkkJCSwe/fuci0/3rgIUj+tX2/CzAcfwNmSpSxatoTJk+GnPzVTtUXERxQVQHqS2VCyuKD8UXTu/TzI/NqEjvNDj1+QCTJRA01rTWG2mdJ+wW2WuZ97qPwCgGB+8Bv3MIsBRl1n3s+yzGtK3+Pc+2ezocBlWpTyjpnj9FHTfXhJjrJA0+QaiOwDjbuDf7B5ujDbbPR5cpUJLunry3Ze91SDKIgZbqbXxw6rkV3PayzE7N27lw4dOrBt2za6dOnC/v37adeuHZs3b6ZHj7L1AMaOHUtERAT//Oc/WbZsGUOGDOHUqVM0PudXonv37owbN44nnniCf/zjH0ybNo3MzMxynxcREcGLL77Ivffey/ny8/PJP2fEZlZWFvHx8Qox8r2OH4dXXoHXXjNbG4BZX+YnPzFdTe3a2Vs/EakGVrHZCDOt5If+5KryXVMV5RdstkhoNtCElqYJpnWjSnUrCT15x+B0SbDJPQKZW00gOX34IvUIhIjugAMyNoNVVP75kFizN1XUIFOuON9svFmYbW7PvV+YbT7zxHLz2M1hQlPcSLMqc5Pe1dJK40mIqXTDuWVZTJs2jQEDBtClSxcAUktGTkZHl9+8Kzo6mkOHDrnLBAUFlQswpWVKX5+amkpUVNQFnxkVFeUuc75Zs2bxxBNPXPQ5kcuJi4MnnzTTsOfOhf/7P9i2Df76V5gzB8aNMysBX3tt7ZiwISJe4PCDiC7m6PiQCQ45+0q6hVaZlYgDzh+/Elb+XIMos5pyaQuI1+rmgCCnOZydL3w+7wSc2gDpJcep9ZCfDqc2lpUJbW1alKIGlbUsefoXWFEBfLcajidCyiIzuDp9nTm2PW7W74n/IVzzalW+bZVUOsRMnjyZrVu38tVXX13wnOO8C2VZ1gXnznd+mYuVv9z7zJw5k2nTprkfl7bEiFRUSIhpfbn3Xli6FF54ARYtgvnzzdGnj9nS4Ic/NPs1iUgd4nBAWHtztLuwtb9WCYk2e1M1H20eW5YZi5O+3rTANBvgnRWO/YPMAoPRN0CPZ0w31/FESEmE1CWQ/x2cOVH1z6mCSrUDTZkyhQULFrB8+fJyM4piSuarnt9akpaW5m6diYmJoaCggIyMjMuWOXHiwgtz8uTJC1p5SgUHBxMeHl7uEKkMhwNuvBEWLoQdO2DSJAgOhg0b4M47oW1beO45OK+3U0TEHg6HWVOn1XhofWf1bdHQsIXZNf26D+HW7+DGldD5t9XzWRXkUYixLIvJkyfz0UcfsWzZMtq0Kb/5WJs2bYiJiWHJkiXucwUFBaxcuZL+/c2GX7169SIwMLBcmZSUFLZv3+4uk5CQgMvlYv369e4y69atw+VyucuI1ITOneH11+HIEfjjH81WBkePmr2ZWrQwY2YOHPj+9xERqVP8Ak03VdNrbK2GRwN7H3roId577z3+97//lZsh5HQ6CQkx09KeeeYZZs2axVtvvUWHDh14+umnWbFixQVTrD/99FPefvttIiMjmTFjBunp6RdMsT5+/DivvfYaYKZYt2rVSlOsxVZnzphxMy+8ANu3m3N+fnDzzTB9OiQk2Fs/ERFf59Hvt+UB4KLHW2+95S5TXFxsPfbYY1ZMTIwVHBxsDRw40Nq2bVu598nLy7MmT55sRUZGWiEhIdbo0aOtw4cPlyuTnp5u3XXXXVZYWJgVFhZm3XXXXVZGRkaF6+pyuSzAcrlcnnxFkQopLrasxYsta/hwyzId0ubo18+yPvjAsgoL7a6hiIhv8uT3W9sOiFTR9u1mJeB//xsKSpZiaN3adDX95CegP34iIhWnDSBFalCXLmZjycOH4Q9/gKZN4eBBM5OpeXOzR9PXX9tdSxGRukchRsRLoqPhiSdMmHntNbjiCsjJMfevvhr694d33jHjakREpOoUYkS8LCQE7r8fdu6E5cvhttvMfkxr18KPf2xaZ2bMgD177K6piIhvU4gRqSYOB1x/Pbz/vpmi/eSTZm+mU6fg+eehY0cYOtRsSFlYaHdtRUR8j0KMSA2IiTHbGuzfDwsWwA9+YELOF1/ArbeacPPoo1pzRkTEEwoxIjXI3x9uugk++wz27YPf/tYsoJeaCk8/bTabHD5crTMiIhWhECNikzZtYNYs09X0n/+YriXLgsWLTetMfDw88ohpvRERkQspxIjYLCjIbCq5eLFpnZk508x0OnHChJx27WDYMNMNVVRkd21FRGoPhRiRWqRtW9OtdOQIfPihCS8AS5bA2LHQoQP8+c9mcLCISH2nECNSCwUGmi6lzz83rTO/+hU0bmwG/v7qV2bzyUmTYOtWu2sqImIfhRiRWq5tW3j2WbN79htvQLdukJcHb74J3bvDoEGm1ebsWbtrKiJSsxRiRHxEw4bw059CcjKsWgU/+pGZ7VR6v00b+NOfICXF7pqKiNQMhRgRH+NwwHXXwQcfmD2afvc7aNbMtNT84Q9mzZnx42HlSjPbSUSkrlKIEfFhLVqY1pcjR8y+TP37m26lDz4wqwV36QJz5oDLZXdNRUS8TyFGpA4IDoa774bVq013089+BqGhZv+mKVPMfk0/+5l5TkSkrlCIEaljuneHv/0Njh0zrTCdO0NuLrz+OvToAQMHwvz5WnNGRHyfQoxIHeV0wsMPw/btZnzM+PFmN+0vv4RbbjEbUP7lL5CdbXdNRUQqRyFGpI5zOEzry7x5ZiDwzJkQGWm2M/jFL8z2Br/6FRw+bHdNRUQ8oxAjUo80b162IvCrr5rWGJfLrALcti3cfjusW2d3LUVEKkYhRqQeatgQHngAdu2CTz+FIUPMGJn334d+/UzLzRdfaIq2iNRuCjEi9ZifH4waZQJLcjLcc4/ZkPLLL82u2gMGmK0PFGZEpDZSiBERwMxqeustM1bm5z+HBg1gzRoYMQISEmDhQoUZEaldFGJEpJzmzeGll0yY+eUvISTEjJMZNQquuQY++URhRkRqB4UYEbmo2Fh44QWzc/aMGWYczcaNMGYM9OoFCxYozIiIvRRiROSyoqPhuedMmPnNb8xKwFu2wNixZgdtzWYSEbsoxIhIhURFwezZZq2Z3/7WjJn58kszm+n2203IERGpSQoxIuKRpk1h1izYswcmTjSL6b3/PlxxBUyfDqdO2V1DEakvFGJEpFJatIC334bNm+HGG6GgwIyhad/e3Obn211DEanrFGJEpEquvhoWL4ZFi6BLF8jIMC0yV15pWmiKi+2uoYjUVQoxIlJlDodZTyY5Gd5808xsOnDAjJXp2VMzmUSkeijEiIjX+PvDffeZ8TJPPAFhYfD112YmU9++kJioMCMi3qMQIyJeFxoKf/iDaY357W/NGjMbNsDIkXDddbB8ud01FJG6QCFGRKpNkyZmJlPp6r/BwbB6NQwebI7Vq+2uoYj4MoUYEal20dFmxtK+ffDQQxAYaFpjBgwwrTNffWV3DUXEFynEiEiNad4cXn7ZjJn56U/NGJrERNPFdO21ZgCwZjOJSEUpxIhIjWvVCt54A3bvNmEmKMjsmD12LHTtatafKSiwu5YiUtspxIiIbdq3N2HmwAH49a8hPBx27oR774V27UwXVHa23bUUkdpKIUZEbBcXB888A4cPm9vYWDh61Cya17IlPPooHD9udy1FpLZRiBGRWsPpNC0yBw6YRfM6dYLMTHj6aRNmxo6FTz+Fs2ftrqmI1AYKMSJS6wQHm0Xzdu6E+fPNwN+iIjPw96aboHVrsw7NoUN211RE7KQQIyK1lp8fjBsHq1aZQDNtmll75tgx+NOfoE0bM0X7o4+gsNDu2opITXNYVt1cBDwrKwun04nL5SI8PNzu6oiIl+Tnw8cfmwHBS5eWnY+OhrvvhjvvhB49zH5OIuJ7PPn9VogREZ+1bx/8/e/w1luQmlp2vmNHE2buuMPcFxHfoRCDQoxIfVJYCAsXwnvvmXEzZ86UPderlwkz48dDixb21VFEKkYhBoUYkfoqOxv+9z8TaBYvNgOCwXQvDRxoWmh++EOIjLS3niJycQoxKMSICJw8Cf/5D8ydW35/psBAGDHCBJqbbjK7botI7aAQg0KMiJR36BDMm2cCzddfl50PDTUzoO68E4YONQFHROyjEINCjIhc2o4dJsy8955ZWK9UkyZw221w++3Qvz8EBNhXR5H6SiEGhRgR+X6WBevWmTDz/vuQllb2XHg4DBkCw4aZo21b++opUp8oxKAQIyKeOXsWli2Dd981WxucOlX++fbtTZgZPhxuuAHCwuypp0hdpxCDQoyIVF5REWzeDJ9/bmY4rV1bfr+mgADT3TR8uFkxuHt3s7qwiFSdQgwKMSLiPVlZsHy5CTSLF8PeveWfj442gWbECDM4uGlTe+opUhcoxKAQIyLVZ/9+SEw0LTVLl0JubtlzDgf06WMCzYgR5r4GCItUnEIMCjEiUjMKCmD1ahNqEhNh69byzzdsCP36wbXXmqNfP3A67amriC9QiEEhRkTsceyY6XJKTIQlSyAjo/zzDgd061YWaq69Flq21IaVIqUUYlCIERH7FRfDzp2mpab02L//wnKtW5fNfBo8GCIiarqmIrWHQgwKMSJSO6WklA81W7aUn/nk5wd9+5aFGo2pkfpGIQaFGBHxDTk5sGpV2XTu3bvLP+90mkX3brgBevc207lDQuypq0hNUIhBIUZEfNPhw2YszeLFFx9T4+8PXbpAr14m1PTuDV27QoMG9tRXxNsUYlCIERHfV1QEmzaVLbi3cWP5rRFKBQSYINO7t1mE79przQrDGiwsvkghBoUYEal7LAuOHjXBZuPGsiM9/cKyzZqZQFMaanr1UmuN+AaFGBRiRKR+sCzTBbVxo9nMcvVqc7+goHy5oCATZPr3h549zdiaTp00aFhqH4UYFGJEpP7KzzetNWvWmFCzZs3Fu6GCg834mquvNqGm9NBifGInhRgUYkRESlkW7NtnwkxSEnz9tVlZOCfn4uXbtIFrrjHdUP37m2CjFhupKQoxKMSIiFxOcbFZeO/rr82RnGxuDx++sGxoqFm7pnR8Tb9+WpBPqo8nv98ebx6/atUqbrrpJuLi4nA4HHz88cflnr/nnntwOBzljn79+pUrk5+fz5QpU2jatCmhoaGMGTOGo0ePliuTkZHBhAkTcDqdOJ1OJkyYQGZmpqfVFRGRi/DzMzOYbr0V/vhHWLAADh0yg4SXLoU//QlGjjRdS7m5sGwZPPmkORcZaWZD3Xsv/PnPsGiRCT9185/EUpt53ECYm5tL9+7duffee7n11lsvWmbEiBG89dZb7sdBQUHlnp86dSqffPIJ8+bNo0mTJkyfPp3Ro0ezadMm/P39Abjzzjs5evQoiYmJANx///1MmDCBTz75xNMqi4hIBUVGmq0PBg82j8/dOqF0jM2+fbB9uznOFRYGnTvDVVeVHd27Q0xMzX8PqR+q1J3kcDiYP38+48aNc5+75557yMzMvKCFppTL5aJZs2a88847jB8/HoDjx48THx/PwoULGT58OLt27aJz584kJSXRt29fAJKSkkhISGD37t106tTpe+um7iQRkeqRmmrWrdm6FXbsMMe335bfPuFcrVpBQoLphkpIMAOJz/u3rYibJ7/f1TJUa8WKFURFRREREcGgQYN46qmniIqKAmDTpk0UFhYybNgwd/m4uDi6dOnCmjVrGD58OGvXrsXpdLoDDEC/fv1wOp2sWbPmoiEmPz+f/Px89+OsrKzq+GoiIvVeTAzcfLM5ShUUwJ49ZaGm9PjmG9NNdegQzJtnygYHm+nepcGmb19o0UKL84nnvB5iRo4cyY9+9CNatWrFgQMH+P3vf8/gwYPZtGkTwcHBpKamEhQUROPGjcu9Ljo6mtTUVABSU1PdoedcUVFR7jLnmzVrFk888YS3v46IiFRAUFBZF9K5srJgwwbTcpOUZI70dNM1tWZNWbnISOjWzRzdu5vbq67SPlFyeV4PMaVdRABdunShd+/etGrVis8++4xbbrnlkq+zLAvHOTHccZFIfn6Zc82cOZNp06a5H2dlZREfH1+ZryAiIl4SHm42sBwyxDy2LNi7tyzUrF0L27bBqVOwYoU5Svn5QceOJtD07AmTJpmwI1Kq2mf+x8bG0qpVK/bs2QNATEwMBQUFZGRklGuNSUtLo3///u4yJ06cuOC9Tp48SXR09EU/Jzg4mODg4Gr4BiIi4i0OB3ToYI4f/9icO3MGdu0yY2y2bi2b9v3dd2ZX79274YMP4OWXTZdUyU+FiOdTrD2Vnp7OkSNHiI2NBaBXr14EBgayZMkSd5mUlBS2b9/uDjEJCQm4XC7Wr1/vLrNu3TpcLpe7jIiI1A0NGkCPHjBxIjz/PHzxhVlhOCUFPv8cnnvOTAc/cgQGDoRnnzWzpkQ8np2Uk5PD3r17AejRowcvvPACN9xwA5GRkURGRvL4449z6623Ehsby8GDB3nkkUc4fPgwu3btIiwsDIAHH3yQTz/9lLfffpvIyEhmzJhBenp6uSnWI0eO5Pjx47z22muAmWLdqlWrCk+x1uwkEZG6IzsbfvYzmDvXPB45Ev75T7PRpdQtHv1+Wx5avny5BVxwTJw40Tp9+rQ1bNgwq1mzZlZgYKDVsmVLa+LEidbhw4fLvUdeXp41efJkKzIy0goJCbFGjx59QZn09HTrrrvussLCwqywsDDrrrvusjIyMipcT5fLZQGWy+Xy9CuKiEgtVFxsWW+8YVkNGlgWWFZcnGWtXGl3rcTbPPn91rYDIiLiU7Ztg9tuM2Nl/PzgiSdg5kwoacgXH1et2w6IiIjYqWtX2LjRjKEpLobf/x6GDzeL8En9ohAjIiI+JzQU3n7bHA0bmv2err4afvc7eOcdWLfOTNuWuk3dSSIi4tN27oTx4y/cywmgSROz1kzp0aEDtGxpBgRHRZkwpJWCaxdPfr8VYkRExOedPm1aZbZuNfs4ffstHDv2/a9r0MCEmaiosmDTrJk5IiNNCGrSpOx+ZKTZNkGqj0IMCjEiIvVdbq5ZHbg01JQeKSlmHZq8vMq9b2hoWaBp3BgiIsxt6XH+43OPwEBvfsO6yfYNIEVEROwWGmr2Yere/cLnLMuEnJMnTaApvS09vvvOjKlJTy+7zcgwA4lzc81x+HDl6tS4cVkAKj0u1epTetuwYdWvR12kECMiIvWOwwGNGpmjTZuKvaa4GFyu8uEmIwMyM81t6XH+44wM8zooC0BHj3pW3wYNTJgpbeU5t7Xn/PtOZ9lR+jigjv7a19GvJSIi4l1+fmVhoV07z15bVGSCTEZGWfgpPU6dKjvObfkpvX/2rNlf6vhxc1RGw4blg835rT4Xux8RAWFh5nvXVgoxIiIi1czf3wSDyEjPApBlmS0X0tPLt/Bc7H7prctVduTmmvc5fdocKSme1dvhMDuRn9+yU3q/a1ezHYRdFGJERERqqdIQUdn5KWfPlg8157YGnd/qc/7jggITokpfdzEjRijEiIiISDUICCjrIvLUmTNlASYz8+L327b1do09oxAjIiIiF2jQwBzR0XbX5NJq8XAdERERkUtTiBERERGfpBAjIiIiPkkhRkRERHySQoyIiIj4JIUYERER8UkKMSIiIuKTFGJERETEJynEiIiIiE9SiBERERGfpBAjIiIiPkkhRkRERHySQoyIiIj4pDq7i7VlWQBkZWXZXBMRERGpqNLf7dLf8cupsyEmOzsbgPj4eJtrIiIiIp7Kzs7G6XRetozDqkjU8UHFxcUcP36csLAwHA6HV987KyuL+Ph4jhw5Qnh4uFffWy6k612zdL1rlq53zdL1rlmVud6WZZGdnU1cXBx+fpcf9VJnW2L8/Pxo0aJFtX5GeHi4/ieoQbreNUvXu2bpetcsXe+a5en1/r4WmFIa2CsiIiI+SSFGREREfJJCTCUEBwfz2GOPERwcbHdV6gVd75ql612zdL1rlq53zaru611nB/aKiIhI3aaWGBEREfFJCjEiIiLikxRiRERExCcpxIiIiIhPUojx0CuvvEKbNm1o0KABvXr14ssvv7S7SnXCqlWruOmmm4iLi8PhcPDxxx+Xe96yLB5//HHi4uIICQnh+uuvZ8eOHfZUtg6YNWsWffr0ISwsjKioKMaNG8c333xTroyuufe8+uqrdOvWzb3gV0JCAosWLXI/r2tdvWbNmoXD4WDq1Knuc7rm3vP444/jcDjKHTExMe7nq/NaK8R44P3332fq1Kk8+uijbNmyheuuu46RI0dy+PBhu6vm83Jzc+nevTtz5sy56PPPPvssL7zwAnPmzGHDhg3ExMQwdOhQ9x5Z4pmVK1fy8MMPk5SUxJIlSzh79izDhg0jNzfXXUbX3HtatGjB7Nmz2bhxIxs3bmTw4MGMHTvW/Re5rnX12bBhA6+//jrdunUrd17X3LuuuuoqUlJS3Me2bdvcz1Xrtbakwq655hrrgQceKHfuiiuusH7729/aVKO6CbDmz5/vflxcXGzFxMRYs2fPdp87c+aM5XQ6rb/97W821LDuSUtLswBr5cqVlmXpmteExo0bW2+++aaudTXKzs62OnToYC1ZssQaNGiQ9Ytf/MKyLP359rbHHnvM6t69+0Wfq+5rrZaYCiooKGDTpk0MGzas3Plhw4axZs0am2pVPxw4cIDU1NRy1z44OJhBgwbp2nuJy+UCIDIyEtA1r05FRUXMmzeP3NxcEhISdK2r0cMPP8yoUaO48cYby53XNfe+PXv2EBcXR5s2bbj99tvZv38/UP3Xus5uAOlt3333HUVFRURHR5c7Hx0dTWpqqk21qh9Kr+/Frv2hQ4fsqFKdYlkW06ZNY8CAAXTp0gXQNa8O27ZtIyEhgTNnztCoUSPmz59P586d3X+R61p717x589i8eTMbNmy44Dn9+fauvn378q9//YuOHTty4sQJnnzySfr378+OHTuq/VorxHjI4XCUe2xZ1gXnpHro2lePyZMns3XrVr766qsLntM1955OnTqRnJxMZmYm//3vf5k4cSIrV650P69r7T1HjhzhF7/4BYsXL6ZBgwaXLKdr7h0jR4503+/atSsJCQm0a9eOf/7zn/Tr1w+ovmut7qQKatq0Kf7+/he0uqSlpV2QMMW7Ske569p735QpU1iwYAHLly+nRYsW7vO65t4XFBRE+/bt6d27N7NmzaJ79+689NJLutbVYNOmTaSlpdGrVy8CAgIICAhg5cqV/OUvfyEgIMB9XXXNq0doaChdu3Zlz5491f7nWyGmgoKCgujVqxdLliwpd37JkiX079/fplrVD23atCEmJqbctS8oKGDlypW69pVkWRaTJ0/mo48+YtmyZbRp06bc87rm1c+yLPLz83Wtq8GQIUPYtm0bycnJ7qN3797cddddJCcn07ZtW13zapSfn8+uXbuIjY2t/j/fVR4aXI/MmzfPCgwMtP7+979bO3futKZOnWqFhoZaBw8etLtqPi87O9vasmWLtWXLFguwXnjhBWvLli3WoUOHLMuyrNmzZ1tOp9P66KOPrG3btll33HGHFRsba2VlZdlcc9/04IMPWk6n01qxYoWVkpLiPk6fPu0uo2vuPTNnzrRWrVplHThwwNq6dav1yCOPWH5+ftbixYsty9K1rgnnzk6yLF1zb5o+fbq1YsUKa//+/VZSUpI1evRoKywszP3bWJ3XWiHGQy+//LLVqlUrKygoyOrZs6d7SqpUzfLlyy3ggmPixImWZZlpeo899pgVExNjBQcHWwMHDrS2bdtmb6V92MWuNWC99dZb7jK65t7zk5/8xP33RrNmzawhQ4a4A4xl6VrXhPNDjK6594wfP96KjY21AgMDrbi4OOuWW26xduzY4X6+Oq+1w7Isq+rtOSIiIiI1S2NiRERExCcpxIiIiIhPUogRERERn6QQIyIiIj5JIUZERER8kkKMiIiI+CSFGBEREfFJCjEiIiLikxRiRERExCcpxIiIiIhPUogRERERn6QQIyIiIj7p/wGYEv6gzgE+EwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myloss = model.history.history['loss']\n",
    "myval_loss = model.history.history['val_loss']\n",
    "plt.plot(range(len(myloss)),myloss, label='Training Loss', color='blue')\n",
    "plt.plot(range(len(myval_loss)), myval_loss, label='Validation Loss', color = 'orange')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./B01_TransformData_FinalAvatar_20230922_171230.csv').iloc[300:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Time</th>\n",
       "      <th>m_avg_PelvisPosX</th>\n",
       "      <th>m_avg_PelvisPosY</th>\n",
       "      <th>m_avg_PelvisPosZ</th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipPosX</th>\n",
       "      <th>m_avg_L_HipPosY</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristPosX</th>\n",
       "      <th>m_avg_R_WristPosY</th>\n",
       "      <th>m_avg_R_WristPosZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301</td>\n",
       "      <td>3.516298</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>0.309281</td>\n",
       "      <td>1.707612</td>\n",
       "      <td>357.083</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>0.110527</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>...</td>\n",
       "      <td>351.9312</td>\n",
       "      <td>358.1726</td>\n",
       "      <td>282.4885</td>\n",
       "      <td>0.484731</td>\n",
       "      <td>0.254242</td>\n",
       "      <td>1.712456</td>\n",
       "      <td>339.4850</td>\n",
       "      <td>296.8258</td>\n",
       "      <td>305.4126</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>302</td>\n",
       "      <td>3.527282</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>0.309281</td>\n",
       "      <td>1.707612</td>\n",
       "      <td>357.083</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>0.110527</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>...</td>\n",
       "      <td>350.7178</td>\n",
       "      <td>357.2758</td>\n",
       "      <td>281.4112</td>\n",
       "      <td>0.473791</td>\n",
       "      <td>0.253382</td>\n",
       "      <td>1.724783</td>\n",
       "      <td>337.8150</td>\n",
       "      <td>292.9910</td>\n",
       "      <td>307.2033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>3.538654</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>0.309281</td>\n",
       "      <td>1.707612</td>\n",
       "      <td>357.083</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>0.110527</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>...</td>\n",
       "      <td>349.4878</td>\n",
       "      <td>356.3683</td>\n",
       "      <td>280.3726</td>\n",
       "      <td>0.462770</td>\n",
       "      <td>0.253029</td>\n",
       "      <td>1.736980</td>\n",
       "      <td>336.0336</td>\n",
       "      <td>289.2522</td>\n",
       "      <td>308.9090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>304</td>\n",
       "      <td>3.549650</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.316027</td>\n",
       "      <td>1.705714</td>\n",
       "      <td>357.288</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>0.112322</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>...</td>\n",
       "      <td>348.2825</td>\n",
       "      <td>355.5042</td>\n",
       "      <td>279.3825</td>\n",
       "      <td>0.452501</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>1.747534</td>\n",
       "      <td>334.1286</td>\n",
       "      <td>285.3405</td>\n",
       "      <td>310.8063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>3.561161</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.316027</td>\n",
       "      <td>1.705714</td>\n",
       "      <td>357.288</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>0.112322</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>...</td>\n",
       "      <td>346.9774</td>\n",
       "      <td>354.4922</td>\n",
       "      <td>278.4650</td>\n",
       "      <td>0.441532</td>\n",
       "      <td>0.259532</td>\n",
       "      <td>1.759929</td>\n",
       "      <td>332.4753</td>\n",
       "      <td>281.4930</td>\n",
       "      <td>312.3235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame      Time  m_avg_PelvisPosX  m_avg_PelvisPosY  m_avg_PelvisPosZ  \\\n",
       "300    301  3.516298          0.167637          0.309281          1.707612   \n",
       "301    302  3.527282          0.167637          0.309281          1.707612   \n",
       "302    303  3.538654          0.167637          0.309281          1.707612   \n",
       "303    304  3.549650          0.169145          0.316027          1.705714   \n",
       "304    305  3.561161          0.169145          0.316027          1.705714   \n",
       "\n",
       "     m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipPosX  \\\n",
       "300           357.083          356.5699          359.1780         0.110527   \n",
       "301           357.083          356.5699          359.1780         0.110527   \n",
       "302           357.083          356.5699          359.1780         0.110527   \n",
       "303           357.288          355.9712          359.2451         0.112322   \n",
       "304           357.288          355.9712          359.2451         0.112322   \n",
       "\n",
       "     m_avg_L_HipPosY  ...  m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  \\\n",
       "300         0.229474  ...           351.9312           358.1726   \n",
       "301         0.229474  ...           350.7178           357.2758   \n",
       "302         0.229474  ...           349.4878           356.3683   \n",
       "303         0.236200  ...           348.2825           355.5042   \n",
       "304         0.236200  ...           346.9774           354.4922   \n",
       "\n",
       "     m_avg_R_ElbowRotZ  m_avg_R_WristPosX  m_avg_R_WristPosY  \\\n",
       "300           282.4885           0.484731           0.254242   \n",
       "301           281.4112           0.473791           0.253382   \n",
       "302           280.3726           0.462770           0.253029   \n",
       "303           279.3825           0.452501           0.258765   \n",
       "304           278.4650           0.441532           0.259532   \n",
       "\n",
       "     m_avg_R_WristPosZ  m_avg_R_WristRotX  m_avg_R_WristRotY  \\\n",
       "300           1.712456           339.4850           296.8258   \n",
       "301           1.724783           337.8150           292.9910   \n",
       "302           1.736980           336.0336           289.2522   \n",
       "303           1.747534           334.1286           285.3405   \n",
       "304           1.759929           332.4753           281.4930   \n",
       "\n",
       "     m_avg_R_WristRotZ  Unnamed: 128  \n",
       "300           305.4126           NaN  \n",
       "301           307.2033           NaN  \n",
       "302           308.9090           NaN  \n",
       "303           310.8063           NaN  \n",
       "304           312.3235           NaN  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rotation_columns = [col for col in test_df.columns if 'Rot' in col]\n",
    "test_rotation_df = test_df[test_rotation_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>357.083000</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>3.120952</td>\n",
       "      <td>2.614980</td>\n",
       "      <td>1.605597</td>\n",
       "      <td>357.2850</td>\n",
       "      <td>2.783687</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>354.665700</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0468</td>\n",
       "      <td>346.61580</td>\n",
       "      <td>356.47380</td>\n",
       "      <td>287.389800</td>\n",
       "      <td>351.93120</td>\n",
       "      <td>358.17260</td>\n",
       "      <td>282.488500</td>\n",
       "      <td>339.4850</td>\n",
       "      <td>296.8258</td>\n",
       "      <td>305.41260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>357.083000</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>3.120952</td>\n",
       "      <td>2.614980</td>\n",
       "      <td>1.605597</td>\n",
       "      <td>357.2850</td>\n",
       "      <td>2.783687</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>354.665700</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0468</td>\n",
       "      <td>345.37230</td>\n",
       "      <td>355.67140</td>\n",
       "      <td>286.328600</td>\n",
       "      <td>350.71780</td>\n",
       "      <td>357.27580</td>\n",
       "      <td>281.411200</td>\n",
       "      <td>337.8150</td>\n",
       "      <td>292.9910</td>\n",
       "      <td>307.20330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>357.083000</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>3.120952</td>\n",
       "      <td>2.614980</td>\n",
       "      <td>1.605597</td>\n",
       "      <td>357.2850</td>\n",
       "      <td>2.783687</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>354.665700</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0468</td>\n",
       "      <td>344.11480</td>\n",
       "      <td>354.85520</td>\n",
       "      <td>285.303200</td>\n",
       "      <td>349.48780</td>\n",
       "      <td>356.36830</td>\n",
       "      <td>280.372600</td>\n",
       "      <td>336.0336</td>\n",
       "      <td>289.2522</td>\n",
       "      <td>308.90900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>357.288000</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>1.685574</td>\n",
       "      <td>5.019152</td>\n",
       "      <td>2.186052</td>\n",
       "      <td>356.7885</td>\n",
       "      <td>5.105362</td>\n",
       "      <td>1.477256</td>\n",
       "      <td>4.062734</td>\n",
       "      <td>...</td>\n",
       "      <td>349.6448</td>\n",
       "      <td>342.88500</td>\n",
       "      <td>354.07880</td>\n",
       "      <td>284.322500</td>\n",
       "      <td>348.28250</td>\n",
       "      <td>355.50420</td>\n",
       "      <td>279.382500</td>\n",
       "      <td>334.1286</td>\n",
       "      <td>285.3405</td>\n",
       "      <td>310.80630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>357.288000</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>1.685574</td>\n",
       "      <td>5.019152</td>\n",
       "      <td>2.186052</td>\n",
       "      <td>356.7885</td>\n",
       "      <td>5.105362</td>\n",
       "      <td>1.477256</td>\n",
       "      <td>4.062734</td>\n",
       "      <td>...</td>\n",
       "      <td>349.6448</td>\n",
       "      <td>341.55870</td>\n",
       "      <td>353.14730</td>\n",
       "      <td>283.414800</td>\n",
       "      <td>346.97740</td>\n",
       "      <td>354.49220</td>\n",
       "      <td>278.465000</td>\n",
       "      <td>332.4753</td>\n",
       "      <td>281.4930</td>\n",
       "      <td>312.32350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>0.638496</td>\n",
       "      <td>355.0141</td>\n",
       "      <td>356.6961</td>\n",
       "      <td>357.393600</td>\n",
       "      <td>4.837928</td>\n",
       "      <td>3.512594</td>\n",
       "      <td>349.2009</td>\n",
       "      <td>4.826385</td>\n",
       "      <td>2.328943</td>\n",
       "      <td>349.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>353.4269</td>\n",
       "      <td>10.94913</td>\n",
       "      <td>21.90927</td>\n",
       "      <td>6.278744</td>\n",
       "      <td>10.26911</td>\n",
       "      <td>27.53492</td>\n",
       "      <td>2.730536</td>\n",
       "      <td>355.6536</td>\n",
       "      <td>355.0251</td>\n",
       "      <td>20.78619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0.638496</td>\n",
       "      <td>355.0141</td>\n",
       "      <td>356.6961</td>\n",
       "      <td>357.393600</td>\n",
       "      <td>4.837928</td>\n",
       "      <td>3.512594</td>\n",
       "      <td>349.2009</td>\n",
       "      <td>4.826385</td>\n",
       "      <td>2.328943</td>\n",
       "      <td>349.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>353.4269</td>\n",
       "      <td>10.96714</td>\n",
       "      <td>21.80633</td>\n",
       "      <td>6.167922</td>\n",
       "      <td>10.29771</td>\n",
       "      <td>27.43369</td>\n",
       "      <td>2.622310</td>\n",
       "      <td>355.6207</td>\n",
       "      <td>354.8966</td>\n",
       "      <td>20.48832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>0.638496</td>\n",
       "      <td>355.0141</td>\n",
       "      <td>356.6961</td>\n",
       "      <td>357.393600</td>\n",
       "      <td>4.837928</td>\n",
       "      <td>3.512594</td>\n",
       "      <td>349.2009</td>\n",
       "      <td>4.826385</td>\n",
       "      <td>2.328943</td>\n",
       "      <td>349.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>353.4269</td>\n",
       "      <td>10.97428</td>\n",
       "      <td>21.70186</td>\n",
       "      <td>6.112121</td>\n",
       "      <td>10.31019</td>\n",
       "      <td>27.33001</td>\n",
       "      <td>2.567600</td>\n",
       "      <td>355.6002</td>\n",
       "      <td>354.7376</td>\n",
       "      <td>20.17733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>0.646919</td>\n",
       "      <td>355.0108</td>\n",
       "      <td>356.7127</td>\n",
       "      <td>357.546200</td>\n",
       "      <td>5.342571</td>\n",
       "      <td>3.862668</td>\n",
       "      <td>349.4238</td>\n",
       "      <td>5.280097</td>\n",
       "      <td>2.694932</td>\n",
       "      <td>349.240000</td>\n",
       "      <td>...</td>\n",
       "      <td>353.2370</td>\n",
       "      <td>10.99195</td>\n",
       "      <td>21.59484</td>\n",
       "      <td>6.029818</td>\n",
       "      <td>10.33570</td>\n",
       "      <td>27.22439</td>\n",
       "      <td>2.487622</td>\n",
       "      <td>355.6598</td>\n",
       "      <td>354.5097</td>\n",
       "      <td>19.92392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>0.646919</td>\n",
       "      <td>355.0108</td>\n",
       "      <td>356.7127</td>\n",
       "      <td>357.546200</td>\n",
       "      <td>5.342571</td>\n",
       "      <td>3.862668</td>\n",
       "      <td>349.4238</td>\n",
       "      <td>5.280097</td>\n",
       "      <td>2.694932</td>\n",
       "      <td>349.240000</td>\n",
       "      <td>...</td>\n",
       "      <td>353.2370</td>\n",
       "      <td>10.99784</td>\n",
       "      <td>21.51480</td>\n",
       "      <td>5.988278</td>\n",
       "      <td>10.34555</td>\n",
       "      <td>27.14502</td>\n",
       "      <td>2.446991</td>\n",
       "      <td>355.7557</td>\n",
       "      <td>354.3958</td>\n",
       "      <td>19.77342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4376 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "300         357.083000          356.5699          359.1780         3.120952   \n",
       "301         357.083000          356.5699          359.1780         3.120952   \n",
       "302         357.083000          356.5699          359.1780         3.120952   \n",
       "303         357.288000          355.9712          359.2451         1.685574   \n",
       "304         357.288000          355.9712          359.2451         1.685574   \n",
       "...                ...               ...               ...              ...   \n",
       "4671          0.638496          355.0141          356.6961       357.393600   \n",
       "4672          0.638496          355.0141          356.6961       357.393600   \n",
       "4673          0.638496          355.0141          356.6961       357.393600   \n",
       "4674          0.646919          355.0108          356.7127       357.546200   \n",
       "4675          0.646919          355.0108          356.7127       357.546200   \n",
       "\n",
       "      m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "300          2.614980         1.605597          357.2850          2.783687   \n",
       "301          2.614980         1.605597          357.2850          2.783687   \n",
       "302          2.614980         1.605597          357.2850          2.783687   \n",
       "303          5.019152         2.186052          356.7885          5.105362   \n",
       "304          5.019152         2.186052          356.7885          5.105362   \n",
       "...               ...              ...               ...               ...   \n",
       "4671         4.837928         3.512594          349.2009          4.826385   \n",
       "4672         4.837928         3.512594          349.2009          4.826385   \n",
       "4673         4.837928         3.512594          349.2009          4.826385   \n",
       "4674         5.342571         3.862668          349.4238          5.280097   \n",
       "4675         5.342571         3.862668          349.4238          5.280097   \n",
       "\n",
       "      m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "300           0.762435         354.665700  ...            350.0468   \n",
       "301           0.762435         354.665700  ...            350.0468   \n",
       "302           0.762435         354.665700  ...            350.0468   \n",
       "303           1.477256           4.062734  ...            349.6448   \n",
       "304           1.477256           4.062734  ...            349.6448   \n",
       "...                ...                ...  ...                 ...   \n",
       "4671          2.328943         349.104800  ...            353.4269   \n",
       "4672          2.328943         349.104800  ...            353.4269   \n",
       "4673          2.328943         349.104800  ...            353.4269   \n",
       "4674          2.694932         349.240000  ...            353.2370   \n",
       "4675          2.694932         349.240000  ...            353.2370   \n",
       "\n",
       "      m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "300              346.61580             356.47380            287.389800   \n",
       "301              345.37230             355.67140            286.328600   \n",
       "302              344.11480             354.85520            285.303200   \n",
       "303              342.88500             354.07880            284.322500   \n",
       "304              341.55870             353.14730            283.414800   \n",
       "...                    ...                   ...                   ...   \n",
       "4671              10.94913              21.90927              6.278744   \n",
       "4672              10.96714              21.80633              6.167922   \n",
       "4673              10.97428              21.70186              6.112121   \n",
       "4674              10.99195              21.59484              6.029818   \n",
       "4675              10.99784              21.51480              5.988278   \n",
       "\n",
       "      m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  \\\n",
       "300           351.93120          358.17260         282.488500   \n",
       "301           350.71780          357.27580         281.411200   \n",
       "302           349.48780          356.36830         280.372600   \n",
       "303           348.28250          355.50420         279.382500   \n",
       "304           346.97740          354.49220         278.465000   \n",
       "...                 ...                ...                ...   \n",
       "4671           10.26911           27.53492           2.730536   \n",
       "4672           10.29771           27.43369           2.622310   \n",
       "4673           10.31019           27.33001           2.567600   \n",
       "4674           10.33570           27.22439           2.487622   \n",
       "4675           10.34555           27.14502           2.446991   \n",
       "\n",
       "      m_avg_R_WristRotX  m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "300            339.4850           296.8258          305.41260  \n",
       "301            337.8150           292.9910          307.20330  \n",
       "302            336.0336           289.2522          308.90900  \n",
       "303            334.1286           285.3405          310.80630  \n",
       "304            332.4753           281.4930          312.32350  \n",
       "...                 ...                ...                ...  \n",
       "4671           355.6536           355.0251           20.78619  \n",
       "4672           355.6207           354.8966           20.48832  \n",
       "4673           355.6002           354.7376           20.17733  \n",
       "4674           355.6598           354.5097           19.92392  \n",
       "4675           355.7557           354.3958           19.77342  \n",
       "\n",
       "[4376 rows x 63 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_32852\\1565179903.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_df[test_rotation_columns] = test_df[test_rotation_columns].applymap(normalize_angle)\n"
     ]
    }
   ],
   "source": [
    "#-180~180 사이로 정규화\n",
    "def normalize_angle(x):\n",
    "    x = np.where(x > 180, x - 360, x)\n",
    "    x = np.where(x < -180, x + 360, x)\n",
    "    return x\n",
    "test_df[test_rotation_columns] = test_df[test_rotation_columns].applymap(normalize_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_rotation_columns].map(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>-13.38</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>-72.61</td>\n",
       "      <td>-8.07</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>-77.51</td>\n",
       "      <td>-20.51</td>\n",
       "      <td>-63.17</td>\n",
       "      <td>-54.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>-14.63</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>-73.67</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-78.59</td>\n",
       "      <td>-22.19</td>\n",
       "      <td>-67.01</td>\n",
       "      <td>-52.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>-15.89</td>\n",
       "      <td>-5.14</td>\n",
       "      <td>-74.70</td>\n",
       "      <td>-10.51</td>\n",
       "      <td>-3.63</td>\n",
       "      <td>-79.63</td>\n",
       "      <td>-23.97</td>\n",
       "      <td>-70.75</td>\n",
       "      <td>-51.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.69</td>\n",
       "      <td>5.02</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-3.21</td>\n",
       "      <td>5.11</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.06</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-17.12</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>-75.68</td>\n",
       "      <td>-11.72</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-80.62</td>\n",
       "      <td>-25.87</td>\n",
       "      <td>-74.66</td>\n",
       "      <td>-49.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.69</td>\n",
       "      <td>5.02</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-3.21</td>\n",
       "      <td>5.11</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.06</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-18.44</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>-76.59</td>\n",
       "      <td>-13.02</td>\n",
       "      <td>-5.51</td>\n",
       "      <td>-81.54</td>\n",
       "      <td>-27.52</td>\n",
       "      <td>-78.51</td>\n",
       "      <td>-47.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>10.95</td>\n",
       "      <td>21.91</td>\n",
       "      <td>6.28</td>\n",
       "      <td>10.27</td>\n",
       "      <td>27.53</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-4.35</td>\n",
       "      <td>-4.97</td>\n",
       "      <td>20.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>10.97</td>\n",
       "      <td>21.81</td>\n",
       "      <td>6.17</td>\n",
       "      <td>10.30</td>\n",
       "      <td>27.43</td>\n",
       "      <td>2.62</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>20.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>10.97</td>\n",
       "      <td>21.70</td>\n",
       "      <td>6.11</td>\n",
       "      <td>10.31</td>\n",
       "      <td>27.33</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-4.40</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>20.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-10.58</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-10.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.76</td>\n",
       "      <td>10.99</td>\n",
       "      <td>21.59</td>\n",
       "      <td>6.03</td>\n",
       "      <td>10.34</td>\n",
       "      <td>27.22</td>\n",
       "      <td>2.49</td>\n",
       "      <td>-4.34</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>19.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-10.58</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-10.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.76</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.51</td>\n",
       "      <td>5.99</td>\n",
       "      <td>10.35</td>\n",
       "      <td>27.15</td>\n",
       "      <td>2.45</td>\n",
       "      <td>-4.24</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>19.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4376 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "300              -2.92             -3.43             -0.82             3.12   \n",
       "301              -2.92             -3.43             -0.82             3.12   \n",
       "302              -2.92             -3.43             -0.82             3.12   \n",
       "303              -2.71             -4.03             -0.75             1.69   \n",
       "304              -2.71             -4.03             -0.75             1.69   \n",
       "...                ...               ...               ...              ...   \n",
       "4671              0.64             -4.99             -3.30            -2.61   \n",
       "4672              0.64             -4.99             -3.30            -2.61   \n",
       "4673              0.64             -4.99             -3.30            -2.61   \n",
       "4674              0.65             -4.99             -3.29            -2.45   \n",
       "4675              0.65             -4.99             -3.29            -2.45   \n",
       "\n",
       "      m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "300              2.61             1.61             -2.71              2.78   \n",
       "301              2.61             1.61             -2.71              2.78   \n",
       "302              2.61             1.61             -2.71              2.78   \n",
       "303              5.02             2.19             -3.21              5.11   \n",
       "304              5.02             2.19             -3.21              5.11   \n",
       "...               ...              ...               ...               ...   \n",
       "4671             4.84             3.51            -10.80              4.83   \n",
       "4672             4.84             3.51            -10.80              4.83   \n",
       "4673             4.84             3.51            -10.80              4.83   \n",
       "4674             5.34             3.86            -10.58              5.28   \n",
       "4675             5.34             3.86            -10.58              5.28   \n",
       "\n",
       "      m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "300               0.76              -5.33  ...               -9.95   \n",
       "301               0.76              -5.33  ...               -9.95   \n",
       "302               0.76              -5.33  ...               -9.95   \n",
       "303               1.48               4.06  ...              -10.36   \n",
       "304               1.48               4.06  ...              -10.36   \n",
       "...                ...                ...  ...                 ...   \n",
       "4671              2.33             -10.90  ...               -6.57   \n",
       "4672              2.33             -10.90  ...               -6.57   \n",
       "4673              2.33             -10.90  ...               -6.57   \n",
       "4674              2.69             -10.76  ...               -6.76   \n",
       "4675              2.69             -10.76  ...               -6.76   \n",
       "\n",
       "      m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "300                 -13.38                 -3.53                -72.61   \n",
       "301                 -14.63                 -4.33                -73.67   \n",
       "302                 -15.89                 -5.14                -74.70   \n",
       "303                 -17.12                 -5.92                -75.68   \n",
       "304                 -18.44                 -6.85                -76.59   \n",
       "...                    ...                   ...                   ...   \n",
       "4671                 10.95                 21.91                  6.28   \n",
       "4672                 10.97                 21.81                  6.17   \n",
       "4673                 10.97                 21.70                  6.11   \n",
       "4674                 10.99                 21.59                  6.03   \n",
       "4675                 11.00                 21.51                  5.99   \n",
       "\n",
       "      m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  \\\n",
       "300               -8.07              -1.83             -77.51   \n",
       "301               -9.28              -2.72             -78.59   \n",
       "302              -10.51              -3.63             -79.63   \n",
       "303              -11.72              -4.50             -80.62   \n",
       "304              -13.02              -5.51             -81.54   \n",
       "...                 ...                ...                ...   \n",
       "4671              10.27              27.53               2.73   \n",
       "4672              10.30              27.43               2.62   \n",
       "4673              10.31              27.33               2.57   \n",
       "4674              10.34              27.22               2.49   \n",
       "4675              10.35              27.15               2.45   \n",
       "\n",
       "      m_avg_R_WristRotX  m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "300              -20.51             -63.17             -54.59  \n",
       "301              -22.19             -67.01             -52.80  \n",
       "302              -23.97             -70.75             -51.09  \n",
       "303              -25.87             -74.66             -49.19  \n",
       "304              -27.52             -78.51             -47.68  \n",
       "...                 ...                ...                ...  \n",
       "4671              -4.35              -4.97              20.79  \n",
       "4672              -4.38              -5.10              20.49  \n",
       "4673              -4.40              -5.26              20.18  \n",
       "4674              -4.34              -5.49              19.92  \n",
       "4675              -4.24              -5.60              19.77  \n",
       "\n",
       "[4376 rows x 63 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범위를 벗어나는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# -180 ~ 180 범위를 벗어나는 값이 있는지 확인\n",
    "num_values_out_of_range = (test_df > 180).sum().sum() + (test_df < -180).sum().sum()\n",
    "\n",
    "# 결과 확인\n",
    "if num_values_out_of_range > 0:\n",
    "    print(f\"범위를 벗어나는 값의 수: {num_values_out_of_range}\")\n",
    "else:\n",
    "    print(\"범위를 벗어나는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량 계산 및 범주화\n",
    "def calculate_average_change(test_df):\n",
    "    rotation_change_df = test_df.diff().abs()\n",
    "    rotation_change_df.iloc[0] = rotation_change_df.iloc[0].fillna(0)\n",
    "    average_change = rotation_change_df.mean(axis=1)\n",
    "    return average_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_average_change(average_change, thresholds):\n",
    "    categories = np.digitize(average_change, thresholds)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 변화량 범주 추가\n",
    "def add_change_category_to_df(test_df, thresholds):\n",
    "    average_change = calculate_average_change(test_df)\n",
    "    change_categories = categorize_average_change(average_change, thresholds)\n",
    "    test_df['Rot_diff_category'] = change_categories\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [5, 10]\n",
    "test_df = add_change_category_to_df(test_df, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4376, 64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 새로운 CSV 파일로 저장합니다.\n",
    "test_df.to_csv('./test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측 값을 넣을 빈 리스트\n",
    "test_predictions = []\n",
    "\n",
    "# 훈련 데이터셋에서 마지막 입력 개수의 값을 가져온 후\n",
    "current_batch = test_df[-n_input:].to_numpy().reshape((1, n_input, n_features))\n",
    "\n",
    "# 예측 과정 반복\n",
    "for i in range(1):\n",
    "    # 현재 배치에서 다음 포인트를 예측\n",
    "    current_pred = model.predict(current_batch)[0]  # 마지막 시퀀스 포인트 예측\n",
    "    current_pred = np.array([normalize_angle(y) for y in current_pred])  # 예측값 정규화\n",
    "\n",
    "    # 예측된 마지막 프레임을 리스트에 추가\n",
    "    test_predictions.append(current_pred)\n",
    "\n",
    "    # 새로운 배치 생성: 마지막 시퀀스 제외하고 예측값 추가\n",
    "    current_batch = np.roll(current_batch, -1, axis=1)\n",
    "    current_batch[0, -1, :] = current_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ -20.95533562,  -48.23683548,   -5.23702288,   -8.89239502,\n",
       "           0.58830166,    3.82934499,  -33.51722717,    4.84730148,\n",
       "           1.47978234,   -4.90590858,  -36.25572205,   10.79829884,\n",
       "          -1.77947927,  -17.94521713,  -35.06932831,  -13.87597466,\n",
       "        -119.71685028,   -6.43951416,  -32.50345612, -125.93174744,\n",
       "           3.78405547,   -2.70930004,  -33.99137878,   -3.58870053,\n",
       "           6.37698555,  -18.78131294,   29.8668766 ,  -16.59572983,\n",
       "         -50.81312943,   -8.64706993,    5.217556  ,  -77.51423645,\n",
       "         -10.97056866,   -0.59990865,  -77.63083649,   -8.13341713,\n",
       "           9.51380539,  -20.71405029,  -75.55464935,   -3.80976701,\n",
       "          60.49837875, -118.60435486,    1.46905863,    5.41288233,\n",
       "          -2.33314061,   -7.69117785,  -79.61810303,  -10.47632027,\n",
       "           1.53362429,    0.4647716 ,   -0.74583608,   -6.3459816 ,\n",
       "         -67.48480988,   -8.39581776,    4.89433193,  -15.4468956 ,\n",
       "          49.28728485,   -0.44891894,  141.10342407,   62.69007874,\n",
       "           0.79845166,   -2.91039419,    5.01415873,    6.14635944])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_array = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions 리스트의 각 항목을 (64,) 모양의 배열로 변환합니다.\n",
    "# test_predictions_flat = [pred.flatten() for pred in test_predictions]\n",
    "\n",
    "# 변환된 리스트를 데이터프레임으로 변환합니다.\n",
    "test_predictions = pd.DataFrame(test_predictions_array)\n",
    "\n",
    "# test_predictions 데이터프레임을 CSV 파일로 저장합니다.\n",
    "test_predictions.to_csv('./test_predictions.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-20.955336</td>\n",
       "      <td>-48.236835</td>\n",
       "      <td>-5.237023</td>\n",
       "      <td>-8.892395</td>\n",
       "      <td>0.588302</td>\n",
       "      <td>3.829345</td>\n",
       "      <td>-33.517227</td>\n",
       "      <td>4.847301</td>\n",
       "      <td>1.479782</td>\n",
       "      <td>-4.905909</td>\n",
       "      <td>...</td>\n",
       "      <td>4.894332</td>\n",
       "      <td>-15.446896</td>\n",
       "      <td>49.287285</td>\n",
       "      <td>-0.448919</td>\n",
       "      <td>141.103424</td>\n",
       "      <td>62.690079</td>\n",
       "      <td>0.798452</td>\n",
       "      <td>-2.910394</td>\n",
       "      <td>5.014159</td>\n",
       "      <td>6.146359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2         3         4         5          6   \\\n",
       "0 -20.955336 -48.236835 -5.237023 -8.892395  0.588302  3.829345 -33.517227   \n",
       "\n",
       "         7         8         9   ...        54         55         56  \\\n",
       "0  4.847301  1.479782 -4.905909  ...  4.894332 -15.446896  49.287285   \n",
       "\n",
       "         57          58         59        60        61        62        63  \n",
       "0 -0.448919  141.103424  62.690079  0.798452 -2.910394  5.014159  6.146359  \n",
       "\n",
       "[1 rows x 64 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    'm_avg_PelvisRotX', 'm_avg_PelvisRotY', 'm_avg_PelvisRotZ',\n",
    "    'm_avg_L_HipRotX', 'm_avg_L_HipRotY', 'm_avg_L_HipRotZ',\n",
    "    'm_avg_L_KneeRotX', 'm_avg_L_KneeRotY', 'm_avg_L_KneeRotZ',\n",
    "    'm_avg_L_AnkleRotX', 'm_avg_L_AnkleRotY', 'm_avg_L_AnkleRotZ',\n",
    "    'm_avg_L_FootRotX', 'm_avg_L_FootRotY', 'm_avg_L_FootRotZ',\n",
    "    'm_avg_R_HipRotX', 'm_avg_R_HipRotY', 'm_avg_R_HipRotZ',\n",
    "    'm_avg_R_KneeRotX', 'm_avg_R_KneeRotY', 'm_avg_R_KneeRotZ',\n",
    "    'm_avg_R_AnkleRotX', 'm_avg_R_AnkleRotY', 'm_avg_R_AnkleRotZ',\n",
    "    'm_avg_R_FootRotX', 'm_avg_R_FootRotY', 'm_avg_R_FootRotZ',\n",
    "    'm_avg_Spine1RotX', 'm_avg_Spine1RotY', 'm_avg_Spine1RotZ',\n",
    "    'm_avg_Spine2RotX', 'm_avg_Spine2RotY', 'm_avg_Spine2RotZ',\n",
    "    'm_avg_L_CollarRotX', 'm_avg_L_CollarRotY', 'm_avg_L_CollarRotZ',\n",
    "    'm_avg_L_ShoulderRotX', 'm_avg_L_ShoulderRotY', 'm_avg_L_ShoulderRotZ',\n",
    "    'm_avg_L_ElbowRotX', 'm_avg_L_ElbowRotY', 'm_avg_L_ElbowRotZ',\n",
    "    'm_avg_L_WristRotX', 'm_avg_L_WristRotY', 'm_avg_L_WristRotZ',\n",
    "    'm_avg_NeckRotX', 'm_avg_NeckRotY', 'm_avg_NeckRotZ',\n",
    "    'm_avg_HeadRotX', 'm_avg_HeadRotY', 'm_avg_HeadRotZ',\n",
    "    'm_avg_R_CollarRotX', 'm_avg_R_CollarRotY', 'm_avg_R_CollarRotZ',\n",
    "    'm_avg_R_ShoulderRotX', 'm_avg_R_ShoulderRotY', 'm_avg_R_ShoulderRotZ',\n",
    "    'm_avg_R_ElbowRotX', 'm_avg_R_ElbowRotY', 'm_avg_R_ElbowRotZ',\n",
    "    'm_avg_R_WristRotX', 'm_avg_R_WristRotY', 'm_avg_R_WristRotZ',\n",
    "    'Rot_diff_category'\n",
    "]\n",
    "# input 데이터(test_df)의 마지막 5 프레임과 \n",
    "last_inputs_df = test_df.iloc[-30:][column_order].reset_index(drop=True)\n",
    "test_predictions_df = pd.DataFrame(test_predictions_array, columns=column_order)\n",
    "\n",
    "test_combined_df = pd.concat([last_inputs_df, test_predictions_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Rot_diff_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.290000</td>\n",
       "      <td>-2.860000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>-2.880000</td>\n",
       "      <td>9.890000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>-19.270000</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>-23.310000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>25.170000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>9.240000</td>\n",
       "      <td>30.740000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>-1.590000</td>\n",
       "      <td>-1.080000</td>\n",
       "      <td>28.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.840000</td>\n",
       "      <td>-133.450000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-10.590000</td>\n",
       "      <td>-83.650000</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>-38.960000</td>\n",
       "      <td>-92.770000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-37.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.190000</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>9.190000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>5.990000</td>\n",
       "      <td>-1.950000</td>\n",
       "      <td>-1.220000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.840000</td>\n",
       "      <td>-133.450000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-10.590000</td>\n",
       "      <td>-83.650000</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>-38.960000</td>\n",
       "      <td>-92.770000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-37.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>25.230000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>30.790000</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>-1.390000</td>\n",
       "      <td>28.470000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.840000</td>\n",
       "      <td>-133.450000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-10.590000</td>\n",
       "      <td>-83.650000</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>-38.960000</td>\n",
       "      <td>-92.770000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-37.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>25.190000</td>\n",
       "      <td>9.740000</td>\n",
       "      <td>9.210000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>28.440000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.070000</td>\n",
       "      <td>-4.730000</td>\n",
       "      <td>-2.910000</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>-20.960000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-21.270000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>25.120000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>9.240000</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>6.060000</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>-1.710000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.070000</td>\n",
       "      <td>-4.730000</td>\n",
       "      <td>-2.910000</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>-20.960000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-21.270000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.270000</td>\n",
       "      <td>25.040000</td>\n",
       "      <td>9.660000</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>6.020000</td>\n",
       "      <td>-3.260000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.070000</td>\n",
       "      <td>-4.730000</td>\n",
       "      <td>-2.910000</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>-20.960000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-21.270000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>24.950000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>9.310000</td>\n",
       "      <td>30.510000</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>-3.590000</td>\n",
       "      <td>-2.080000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>-4.650000</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-17.180000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-13.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>24.770000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>30.330000</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>-3.910000</td>\n",
       "      <td>-2.330000</td>\n",
       "      <td>28.320000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>-4.650000</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-17.180000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-13.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>24.610000</td>\n",
       "      <td>9.230000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>30.180000</td>\n",
       "      <td>5.610000</td>\n",
       "      <td>-4.220000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>-4.650000</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-17.180000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-13.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.440000</td>\n",
       "      <td>24.460000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>30.030000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>-4.470000</td>\n",
       "      <td>-2.940000</td>\n",
       "      <td>27.070000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>-14.320000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-11.220000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.510000</td>\n",
       "      <td>24.260000</td>\n",
       "      <td>8.810000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>29.840000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>-4.780000</td>\n",
       "      <td>-3.220000</td>\n",
       "      <td>26.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>-14.320000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-11.220000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.560000</td>\n",
       "      <td>24.080000</td>\n",
       "      <td>8.630000</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>-5.040000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>25.640000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>-14.320000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-11.220000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.610000</td>\n",
       "      <td>23.890000</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>29.480000</td>\n",
       "      <td>4.790000</td>\n",
       "      <td>-5.260000</td>\n",
       "      <td>-3.680000</td>\n",
       "      <td>25.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.590000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.260000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>-9.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>8.160000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>-5.220000</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.590000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.260000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>-9.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>23.520000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>9.860000</td>\n",
       "      <td>29.110000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>-5.230000</td>\n",
       "      <td>-3.910000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.590000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.260000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>-9.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>23.330000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>28.930000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>-5.030000</td>\n",
       "      <td>-4.060000</td>\n",
       "      <td>23.690000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.280000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-12.880000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>-9.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.770000</td>\n",
       "      <td>23.140000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>9.970000</td>\n",
       "      <td>28.740000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>-4.810000</td>\n",
       "      <td>-4.180000</td>\n",
       "      <td>23.170000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.280000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-12.880000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>-9.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.960000</td>\n",
       "      <td>7.330000</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>28.570000</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>-4.670000</td>\n",
       "      <td>-4.340000</td>\n",
       "      <td>22.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.280000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-12.880000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>-9.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830000</td>\n",
       "      <td>22.780000</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>10.070000</td>\n",
       "      <td>28.390000</td>\n",
       "      <td>3.590000</td>\n",
       "      <td>-4.520000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>22.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.290000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>-12.850000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>-9.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.860000</td>\n",
       "      <td>22.620000</td>\n",
       "      <td>6.990000</td>\n",
       "      <td>10.110000</td>\n",
       "      <td>28.230000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>-4.450000</td>\n",
       "      <td>-4.620000</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.290000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>-12.850000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>-9.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.880000</td>\n",
       "      <td>22.460000</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>10.150000</td>\n",
       "      <td>28.080000</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>-4.400000</td>\n",
       "      <td>-4.690000</td>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.290000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>-12.850000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>-9.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>22.330000</td>\n",
       "      <td>6.710000</td>\n",
       "      <td>10.180000</td>\n",
       "      <td>27.940000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>-4.330000</td>\n",
       "      <td>-4.750000</td>\n",
       "      <td>21.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>-11.410000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>-10.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.910000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>27.820000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>-4.290000</td>\n",
       "      <td>-4.810000</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>-11.410000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>-10.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>6.460000</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>27.730000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>-4.300000</td>\n",
       "      <td>-4.870000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>-11.410000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>-10.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.940000</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>27.640000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-4.320000</td>\n",
       "      <td>-4.910000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>-10.800000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>-10.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>10.270000</td>\n",
       "      <td>27.530000</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>-4.350000</td>\n",
       "      <td>-4.970000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>-10.800000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>-10.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>21.810000</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>27.430000</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>-4.380000</td>\n",
       "      <td>-5.100000</td>\n",
       "      <td>20.490000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>-10.800000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>-10.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>10.310000</td>\n",
       "      <td>27.330000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>-4.400000</td>\n",
       "      <td>-5.260000</td>\n",
       "      <td>20.180000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.290000</td>\n",
       "      <td>-2.450000</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>-10.580000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>-10.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>21.590000</td>\n",
       "      <td>6.030000</td>\n",
       "      <td>10.340000</td>\n",
       "      <td>27.220000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>-4.340000</td>\n",
       "      <td>-5.490000</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.290000</td>\n",
       "      <td>-2.450000</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>-10.580000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>-10.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.510000</td>\n",
       "      <td>5.990000</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>27.150000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>-4.240000</td>\n",
       "      <td>-5.600000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-20.955336</td>\n",
       "      <td>-48.236835</td>\n",
       "      <td>-5.237023</td>\n",
       "      <td>-8.892395</td>\n",
       "      <td>0.588302</td>\n",
       "      <td>3.829345</td>\n",
       "      <td>-33.517227</td>\n",
       "      <td>4.847301</td>\n",
       "      <td>1.479782</td>\n",
       "      <td>-4.905909</td>\n",
       "      <td>...</td>\n",
       "      <td>4.894332</td>\n",
       "      <td>-15.446896</td>\n",
       "      <td>49.287285</td>\n",
       "      <td>-0.448919</td>\n",
       "      <td>141.103424</td>\n",
       "      <td>62.690079</td>\n",
       "      <td>0.798452</td>\n",
       "      <td>-2.910394</td>\n",
       "      <td>5.014159</td>\n",
       "      <td>6.146359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0           1.290000         -2.860000         -1.520000        -2.880000   \n",
       "1         -10.840000       -133.450000         -3.480000       -10.590000   \n",
       "2         -10.840000       -133.450000         -3.480000       -10.590000   \n",
       "3         -10.840000       -133.450000         -3.480000       -10.590000   \n",
       "4           1.070000         -4.730000         -2.910000        -1.370000   \n",
       "5           1.070000         -4.730000         -2.910000        -1.370000   \n",
       "6           1.070000         -4.730000         -2.910000        -1.370000   \n",
       "7           0.830000         -4.650000         -3.010000        -1.520000   \n",
       "8           0.830000         -4.650000         -3.010000        -1.520000   \n",
       "9           0.830000         -4.650000         -3.010000        -1.520000   \n",
       "10          0.770000         -4.600000         -2.790000        -1.870000   \n",
       "11          0.770000         -4.600000         -2.790000        -1.870000   \n",
       "12          0.770000         -4.600000         -2.790000        -1.870000   \n",
       "13          0.720000         -4.590000         -2.690000        -2.260000   \n",
       "14          0.720000         -4.590000         -2.690000        -2.260000   \n",
       "15          0.720000         -4.590000         -2.690000        -2.260000   \n",
       "16          0.720000         -4.600000         -2.690000        -2.280000   \n",
       "17          0.720000         -4.600000         -2.690000        -2.280000   \n",
       "18          0.720000         -4.600000         -2.690000        -2.280000   \n",
       "19          0.710000         -4.610000         -2.690000        -2.290000   \n",
       "20          0.710000         -4.610000         -2.690000        -2.290000   \n",
       "21          0.710000         -4.610000         -2.690000        -2.290000   \n",
       "22          0.670000         -5.080000         -3.150000        -2.550000   \n",
       "23          0.670000         -5.080000         -3.150000        -2.550000   \n",
       "24          0.670000         -5.080000         -3.150000        -2.550000   \n",
       "25          0.640000         -4.990000         -3.300000        -2.610000   \n",
       "26          0.640000         -4.990000         -3.300000        -2.610000   \n",
       "27          0.640000         -4.990000         -3.300000        -2.610000   \n",
       "28          0.650000         -4.990000         -3.290000        -2.450000   \n",
       "29          0.650000         -4.990000         -3.290000        -2.450000   \n",
       "30        -20.955336        -48.236835         -5.237023        -8.892395   \n",
       "\n",
       "    m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0          9.890000         4.190000        -19.270000          9.840000   \n",
       "1        -83.650000        19.510000        -38.960000        -92.770000   \n",
       "2        -83.650000        19.510000        -38.960000        -92.770000   \n",
       "3        -83.650000        19.510000        -38.960000        -92.770000   \n",
       "4          2.790000         3.020000        -20.960000          3.240000   \n",
       "5          2.790000         3.020000        -20.960000          3.240000   \n",
       "6          2.790000         3.020000        -20.960000          3.240000   \n",
       "7          3.960000         2.810000        -17.180000          4.290000   \n",
       "8          3.960000         2.810000        -17.180000          4.290000   \n",
       "9          3.960000         2.810000        -17.180000          4.290000   \n",
       "10         4.040000         2.920000        -14.320000          4.220000   \n",
       "11         4.040000         2.920000        -14.320000          4.220000   \n",
       "12         4.040000         2.920000        -14.320000          4.220000   \n",
       "13         4.020000         2.960000        -13.000000          4.140000   \n",
       "14         4.020000         2.960000        -13.000000          4.140000   \n",
       "15         4.020000         2.960000        -13.000000          4.140000   \n",
       "16         4.010000         2.960000        -12.880000          4.130000   \n",
       "17         4.010000         2.960000        -12.880000          4.130000   \n",
       "18         4.010000         2.960000        -12.880000          4.130000   \n",
       "19         4.030000         2.970000        -12.850000          4.150000   \n",
       "20         4.030000         2.970000        -12.850000          4.150000   \n",
       "21         4.030000         2.970000        -12.850000          4.150000   \n",
       "22         4.250000         3.190000        -11.410000          4.290000   \n",
       "23         4.250000         3.190000        -11.410000          4.290000   \n",
       "24         4.250000         3.190000        -11.410000          4.290000   \n",
       "25         4.840000         3.510000        -10.800000          4.830000   \n",
       "26         4.840000         3.510000        -10.800000          4.830000   \n",
       "27         4.840000         3.510000        -10.800000          4.830000   \n",
       "28         5.340000         3.860000        -10.580000          5.280000   \n",
       "29         5.340000         3.860000        -10.580000          5.280000   \n",
       "30         0.588302         3.829345        -33.517227          4.847301   \n",
       "\n",
       "    m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_ShoulderRotX  \\\n",
       "0           1.820000         -23.310000  ...             10.220000   \n",
       "1          19.100000         -37.730000  ...             10.190000   \n",
       "2          19.100000         -37.730000  ...             10.210000   \n",
       "3          19.100000         -37.730000  ...             10.220000   \n",
       "4           0.080000         -21.270000  ...             10.250000   \n",
       "5           0.080000         -21.270000  ...             10.270000   \n",
       "6           0.080000         -21.270000  ...             10.300000   \n",
       "7           0.480000         -13.930000  ...             10.350000   \n",
       "8           0.480000         -13.930000  ...             10.400000   \n",
       "9           0.480000         -13.930000  ...             10.440000   \n",
       "10          1.090000         -11.220000  ...             10.510000   \n",
       "11          1.090000         -11.220000  ...             10.560000   \n",
       "12          1.090000         -11.220000  ...             10.610000   \n",
       "13          1.390000          -9.720000  ...             10.660000   \n",
       "14          1.390000          -9.720000  ...             10.700000   \n",
       "15          1.390000          -9.720000  ...             10.740000   \n",
       "16          1.410000          -9.580000  ...             10.770000   \n",
       "17          1.410000          -9.580000  ...             10.800000   \n",
       "18          1.410000          -9.580000  ...             10.830000   \n",
       "19          1.420000          -9.550000  ...             10.860000   \n",
       "20          1.420000          -9.550000  ...             10.880000   \n",
       "21          1.420000          -9.550000  ...             10.900000   \n",
       "22          1.910000         -10.600000  ...             10.910000   \n",
       "23          1.910000         -10.600000  ...             10.930000   \n",
       "24          1.910000         -10.600000  ...             10.940000   \n",
       "25          2.330000         -10.900000  ...             10.950000   \n",
       "26          2.330000         -10.900000  ...             10.970000   \n",
       "27          2.330000         -10.900000  ...             10.970000   \n",
       "28          2.690000         -10.760000  ...             10.990000   \n",
       "29          2.690000         -10.760000  ...             11.000000   \n",
       "30          1.479782          -4.905909  ...              4.894332   \n",
       "\n",
       "    m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  m_avg_R_ElbowRotX  \\\n",
       "0              25.170000              9.440000           9.240000   \n",
       "1              25.240000              9.640000           9.190000   \n",
       "2              25.230000              9.700000           9.200000   \n",
       "3              25.190000              9.740000           9.210000   \n",
       "4              25.120000              9.710000           9.240000   \n",
       "5              25.040000              9.660000           9.270000   \n",
       "6              24.950000              9.570000           9.310000   \n",
       "7              24.770000              9.400000           9.370000   \n",
       "8              24.610000              9.230000           9.440000   \n",
       "9              24.460000              9.050000           9.500000   \n",
       "10             24.260000              8.810000           9.590000   \n",
       "11             24.080000              8.630000           9.650000   \n",
       "12             23.890000              8.380000           9.730000   \n",
       "13             23.700000              8.160000           9.800000   \n",
       "14             23.520000              7.930000           9.860000   \n",
       "15             23.330000              7.720000           9.920000   \n",
       "16             23.140000              7.520000           9.970000   \n",
       "17             22.960000              7.330000          10.020000   \n",
       "18             22.780000              7.150000          10.070000   \n",
       "19             22.620000              6.990000          10.110000   \n",
       "20             22.460000              6.840000          10.150000   \n",
       "21             22.330000              6.710000          10.180000   \n",
       "22             22.200000              6.580000          10.200000   \n",
       "23             22.100000              6.460000          10.230000   \n",
       "24             22.020000              6.360000          10.250000   \n",
       "25             21.910000              6.280000          10.270000   \n",
       "26             21.810000              6.170000          10.300000   \n",
       "27             21.700000              6.110000          10.310000   \n",
       "28             21.590000              6.030000          10.340000   \n",
       "29             21.510000              5.990000          10.350000   \n",
       "30            -15.446896             49.287285          -0.448919   \n",
       "\n",
       "    m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  \\\n",
       "0           30.740000           5.800000          -1.590000   \n",
       "1           30.800000           5.990000          -1.950000   \n",
       "2           30.790000           6.050000          -2.250000   \n",
       "3           30.750000           6.090000          -2.550000   \n",
       "4           30.680000           6.060000          -2.900000   \n",
       "5           30.600000           6.020000          -3.260000   \n",
       "6           30.510000           5.940000          -3.590000   \n",
       "7           30.330000           5.770000          -3.910000   \n",
       "8           30.180000           5.610000          -4.220000   \n",
       "9           30.030000           5.430000          -4.470000   \n",
       "10          29.840000           5.200000          -4.780000   \n",
       "11          29.670000           5.020000          -5.040000   \n",
       "12          29.480000           4.790000          -5.260000   \n",
       "13          29.300000           4.570000          -5.220000   \n",
       "14          29.110000           4.350000          -5.230000   \n",
       "15          28.930000           4.140000          -5.030000   \n",
       "16          28.740000           3.940000          -4.810000   \n",
       "17          28.570000           3.760000          -4.670000   \n",
       "18          28.390000           3.590000          -4.520000   \n",
       "19          28.230000           3.430000          -4.450000   \n",
       "20          28.080000           3.280000          -4.400000   \n",
       "21          27.940000           3.150000          -4.330000   \n",
       "22          27.820000           3.030000          -4.290000   \n",
       "23          27.730000           2.910000          -4.300000   \n",
       "24          27.640000           2.810000          -4.320000   \n",
       "25          27.530000           2.730000          -4.350000   \n",
       "26          27.430000           2.620000          -4.380000   \n",
       "27          27.330000           2.570000          -4.400000   \n",
       "28          27.220000           2.490000          -4.340000   \n",
       "29          27.150000           2.450000          -4.240000   \n",
       "30         141.103424          62.690079           0.798452   \n",
       "\n",
       "    m_avg_R_WristRotY  m_avg_R_WristRotZ  Rot_diff_category  \n",
       "0           -1.080000          28.350000           0.000000  \n",
       "1           -1.220000          28.450000           2.000000  \n",
       "2           -1.390000          28.470000           0.000000  \n",
       "3           -1.550000          28.440000           0.000000  \n",
       "4           -1.710000          28.450000           2.000000  \n",
       "5           -1.870000          28.500000           0.000000  \n",
       "6           -2.080000          28.500000           0.000000  \n",
       "7           -2.330000          28.320000           0.000000  \n",
       "8           -2.600000          27.990000           0.000000  \n",
       "9           -2.940000          27.070000           0.000000  \n",
       "10          -3.220000          26.340000           0.000000  \n",
       "11          -3.480000          25.640000           0.000000  \n",
       "12          -3.680000          25.050000           0.000000  \n",
       "13          -3.750000          24.580000           0.000000  \n",
       "14          -3.910000          24.100000           0.000000  \n",
       "15          -4.060000          23.690000           0.000000  \n",
       "16          -4.180000          23.170000           0.000000  \n",
       "17          -4.340000          22.580000           0.000000  \n",
       "18          -4.500000          22.040000           0.000000  \n",
       "19          -4.620000          21.660000           0.000000  \n",
       "20          -4.690000          21.350000           0.000000  \n",
       "21          -4.750000          21.050000           0.000000  \n",
       "22          -4.810000          20.760000           0.000000  \n",
       "23          -4.870000          20.830000           0.000000  \n",
       "24          -4.910000          20.900000           0.000000  \n",
       "25          -4.970000          20.790000           0.000000  \n",
       "26          -5.100000          20.490000           0.000000  \n",
       "27          -5.260000          20.180000           0.000000  \n",
       "28          -5.490000          19.920000           0.000000  \n",
       "29          -5.600000          19.770000           0.000000  \n",
       "30          -2.910394           5.014159           6.146359  \n",
       "\n",
       "[31 rows x 64 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined_df.to_csv('./test_combined_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 10개로 output 1개 예측 되는지 확인\n",
    "# 차원 수 확인\n",
    "# transformer모델 고도화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihsens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
