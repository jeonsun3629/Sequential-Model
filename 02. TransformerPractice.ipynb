{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './csvFiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 목록을 랜덤하게 섞습니다.\n",
    "random.seed(42)  # 재현 가능한 결과를 위해 시드 설정\n",
    "random.shuffle(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\914781413.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[300:-100]\n",
    "    df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Time</th>\n",
       "      <th>m_avg_PelvisPosX</th>\n",
       "      <th>m_avg_PelvisPosY</th>\n",
       "      <th>m_avg_PelvisPosZ</th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipPosX</th>\n",
       "      <th>m_avg_L_HipPosY</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristPosX</th>\n",
       "      <th>m_avg_R_WristPosY</th>\n",
       "      <th>m_avg_R_WristPosZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282506</th>\n",
       "      <td>6609.0</td>\n",
       "      <td>73.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.14</td>\n",
       "      <td>358.24</td>\n",
       "      <td>358.39</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7.21</td>\n",
       "      <td>346.10</td>\n",
       "      <td>349.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.21</td>\n",
       "      <td>357.14</td>\n",
       "      <td>3.21</td>\n",
       "      <td>347.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282507</th>\n",
       "      <td>6610.0</td>\n",
       "      <td>73.53</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.14</td>\n",
       "      <td>358.24</td>\n",
       "      <td>358.39</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7.22</td>\n",
       "      <td>346.23</td>\n",
       "      <td>349.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.21</td>\n",
       "      <td>356.62</td>\n",
       "      <td>3.42</td>\n",
       "      <td>347.09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282508</th>\n",
       "      <td>6611.0</td>\n",
       "      <td>73.54</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.14</td>\n",
       "      <td>358.56</td>\n",
       "      <td>359.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7.23</td>\n",
       "      <td>346.34</td>\n",
       "      <td>349.94</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.21</td>\n",
       "      <td>355.43</td>\n",
       "      <td>3.78</td>\n",
       "      <td>346.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282509</th>\n",
       "      <td>6612.0</td>\n",
       "      <td>73.55</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.14</td>\n",
       "      <td>358.56</td>\n",
       "      <td>359.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7.24</td>\n",
       "      <td>346.51</td>\n",
       "      <td>349.97</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>354.11</td>\n",
       "      <td>4.22</td>\n",
       "      <td>345.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282510</th>\n",
       "      <td>6613.0</td>\n",
       "      <td>73.56</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.14</td>\n",
       "      <td>358.56</td>\n",
       "      <td>359.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7.26</td>\n",
       "      <td>346.68</td>\n",
       "      <td>349.98</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>352.74</td>\n",
       "      <td>4.69</td>\n",
       "      <td>345.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282511 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frame   Time  m_avg_PelvisPosX  m_avg_PelvisPosY  m_avg_PelvisPosZ  \\\n",
       "0         281.0   3.21              0.34              0.28              0.54   \n",
       "1         282.0   3.22              0.34              0.28              0.54   \n",
       "2         283.0   3.23              0.34              0.28              0.54   \n",
       "3         284.0   3.24              0.34              0.28              0.54   \n",
       "4         285.0   3.25              0.34              0.28              0.54   \n",
       "...         ...    ...               ...               ...               ...   \n",
       "1282506  6609.0  73.51              0.06              0.48              1.14   \n",
       "1282507  6610.0  73.53              0.06              0.48              1.14   \n",
       "1282508  6611.0  73.54              0.06              0.48              1.14   \n",
       "1282509  6612.0  73.55              0.06              0.48              1.14   \n",
       "1282510  6613.0  73.56              0.06              0.48              1.14   \n",
       "\n",
       "         m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  \\\n",
       "0                    0.00            180.00              0.00   \n",
       "1                    0.00            180.00              0.00   \n",
       "2                    0.00            180.00              0.00   \n",
       "3                    0.00            180.00              0.00   \n",
       "4                    0.00            180.00              0.00   \n",
       "...                   ...               ...               ...   \n",
       "1282506            358.24            358.39              0.71   \n",
       "1282507            358.24            358.39              0.71   \n",
       "1282508            358.56            359.12              0.70   \n",
       "1282509            358.56            359.12              0.70   \n",
       "1282510            358.56            359.12              0.70   \n",
       "\n",
       "         m_avg_L_HipPosX  m_avg_L_HipPosY  ...  m_avg_R_ElbowRotX  \\\n",
       "0                    0.4             0.20  ...               0.00   \n",
       "1                    0.4             0.20  ...               0.00   \n",
       "2                    0.4             0.20  ...               0.00   \n",
       "3                    0.4             0.20  ...               0.00   \n",
       "4                    0.4             0.20  ...               0.00   \n",
       "...                  ...              ...  ...                ...   \n",
       "1282506              0.0             0.39  ...               7.21   \n",
       "1282507              0.0             0.39  ...               7.22   \n",
       "1282508              0.0             0.39  ...               7.23   \n",
       "1282509              0.0             0.39  ...               7.24   \n",
       "1282510              0.0             0.39  ...               7.26   \n",
       "\n",
       "         m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristPosX  \\\n",
       "0                   180.00               0.00              -0.39   \n",
       "1                   180.00               0.00              -0.39   \n",
       "2                   180.00               0.00              -0.39   \n",
       "3                   180.00               0.00              -0.39   \n",
       "4                   180.00               0.00              -0.39   \n",
       "...                    ...                ...                ...   \n",
       "1282506             346.10             349.96               0.76   \n",
       "1282507             346.23             349.95               0.76   \n",
       "1282508             346.34             349.94               0.76   \n",
       "1282509             346.51             349.97               0.76   \n",
       "1282510             346.68             349.98               0.76   \n",
       "\n",
       "         m_avg_R_WristPosY  m_avg_R_WristPosZ  m_avg_R_WristRotX  \\\n",
       "0                     0.76               0.62               0.00   \n",
       "1                     0.76               0.62               0.00   \n",
       "2                     0.76               0.62               0.00   \n",
       "3                     0.76               0.62               0.00   \n",
       "4                     0.76               0.62               0.00   \n",
       "...                    ...                ...                ...   \n",
       "1282506               0.90               1.21             357.14   \n",
       "1282507               0.90               1.21             356.62   \n",
       "1282508               0.90               1.21             355.43   \n",
       "1282509               0.90               1.20             354.11   \n",
       "1282510               0.90               1.20             352.74   \n",
       "\n",
       "         m_avg_R_WristRotY  m_avg_R_WristRotZ  Unnamed: 128  \n",
       "0                   180.00               0.00           NaN  \n",
       "1                   180.00               0.00           NaN  \n",
       "2                   180.00               0.00           NaN  \n",
       "3                   180.00               0.00           NaN  \n",
       "4                   180.00               0.00           NaN  \n",
       "...                    ...                ...           ...  \n",
       "1282506               3.21             347.35           NaN  \n",
       "1282507               3.42             347.09           NaN  \n",
       "1282508               3.78             346.54           NaN  \n",
       "1282509               4.22             345.88           NaN  \n",
       "1282510               4.69             345.13           NaN  \n",
       "\n",
       "[1282511 rows x 129 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282511"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_columns = [col for col in combined_df.columns if 'Rot' in col]\n",
    "rotation_df = combined_df[rotation_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -180~180 사이로 정규화\n",
    "normalize_angle = lambda x: (x - 360) if x > 180 else (x + 360) if x < -180 else x\n",
    "rotation_df = rotation_df.apply(lambda col: col.apply(normalize_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0               0.0             180.0               0.0              0.0   \n",
       "1               0.0             180.0               0.0              0.0   \n",
       "2               0.0             180.0               0.0              0.0   \n",
       "3               0.0             180.0               0.0              0.0   \n",
       "4               0.0             180.0               0.0              0.0   \n",
       "\n",
       "   m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0            180.0              0.0               0.0             180.0   \n",
       "1            180.0              0.0               0.0             180.0   \n",
       "2            180.0              0.0               0.0             180.0   \n",
       "3            180.0              0.0               0.0             180.0   \n",
       "4            180.0              0.0               0.0             180.0   \n",
       "\n",
       "   m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "0               0.0                0.0  ...                 0.0   \n",
       "1               0.0                0.0  ...                 0.0   \n",
       "2               0.0                0.0  ...                 0.0   \n",
       "3               0.0                0.0  ...                 0.0   \n",
       "4               0.0                0.0  ...                 0.0   \n",
       "\n",
       "   m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "0                   0.0                 180.0                   0.0   \n",
       "1                   0.0                 180.0                   0.0   \n",
       "2                   0.0                 180.0                   0.0   \n",
       "3                   0.0                 180.0                   0.0   \n",
       "4                   0.0                 180.0                   0.0   \n",
       "\n",
       "   m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  \\\n",
       "0                0.0              180.0                0.0                0.0   \n",
       "1                0.0              180.0                0.0                0.0   \n",
       "2                0.0              180.0                0.0                0.0   \n",
       "3                0.0              180.0                0.0                0.0   \n",
       "4                0.0              180.0                0.0                0.0   \n",
       "\n",
       "   m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "0              180.0                0.0  \n",
       "1              180.0                0.0  \n",
       "2              180.0                0.0  \n",
       "3              180.0                0.0  \n",
       "4              180.0                0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 프레임과의 차이를 계산하여 변화량 DataFrame을 생성\n",
    "rotation_change_df = rotation_df.diff().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량을 계산하는 함수\n",
    "def calculate_average_change(rotation_df):\n",
    "    rotation_change_df = rotation_df.diff().abs()\n",
    "    # 첫 번째 행의 NaN 값을 0으로 채우기 (또는 다른 합리적인 값으로 채울 수 있음)\n",
    "    rotation_change_df.iloc[0] = rotation_change_df.iloc[0].fillna(0)\n",
    "    # 모든 joint의 변화량에 대한 평균을 계산\n",
    "    average_change = rotation_change_df.mean(axis=1)\n",
    "    return average_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량을 기준으로 데이터를 1, 2, 3단계로 나누는 함수\n",
    "def categorize_average_change(average_change, thresholds):\n",
    "    # 변화량에 따라 범주화\n",
    "    categories = np.digitize(average_change, thresholds)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame에 변화량 범주를 추가하는 함수\n",
    "def add_change_category_to_df(rotation_df, thresholds):\n",
    "    average_change = calculate_average_change(rotation_df)\n",
    "    change_categories = categorize_average_change(average_change, thresholds)\n",
    "    rotation_df['Rot_diff_category'] = change_categories\n",
    "    return rotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 설정 (예: [5, 10])\n",
    "thresholds = [5, 10]\n",
    "combined_df = add_change_category_to_df(rotation_df, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범위를 벗어나는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# -180 ~ 180 범위를 벗어나는 값이 있는지 확인\n",
    "num_values_out_of_range = (combined_df > 180).sum().sum() + (combined_df < -180).sum().sum()\n",
    "\n",
    "# 결과 확인\n",
    "if num_values_out_of_range > 0:\n",
    "    print(f\"범위를 벗어나는 값의 수: {num_values_out_of_range}\")\n",
    "else:\n",
    "    print(\"범위를 벗어나는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot_diff_category\n",
      "0    1191073\n",
      "1      60982\n",
      "2      30456\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = combined_df['Rot_diff_category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Rot_diff_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0               0.0             180.0               0.0              0.0   \n",
       "1               0.0             180.0               0.0              0.0   \n",
       "2               0.0             180.0               0.0              0.0   \n",
       "3               0.0             180.0               0.0              0.0   \n",
       "4               0.0             180.0               0.0              0.0   \n",
       "\n",
       "   m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0            180.0              0.0               0.0             180.0   \n",
       "1            180.0              0.0               0.0             180.0   \n",
       "2            180.0              0.0               0.0             180.0   \n",
       "3            180.0              0.0               0.0             180.0   \n",
       "4            180.0              0.0               0.0             180.0   \n",
       "\n",
       "   m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_ShoulderRotX  \\\n",
       "0               0.0                0.0  ...                   0.0   \n",
       "1               0.0                0.0  ...                   0.0   \n",
       "2               0.0                0.0  ...                   0.0   \n",
       "3               0.0                0.0  ...                   0.0   \n",
       "4               0.0                0.0  ...                   0.0   \n",
       "\n",
       "   m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  m_avg_R_ElbowRotX  \\\n",
       "0                 180.0                   0.0                0.0   \n",
       "1                 180.0                   0.0                0.0   \n",
       "2                 180.0                   0.0                0.0   \n",
       "3                 180.0                   0.0                0.0   \n",
       "4                 180.0                   0.0                0.0   \n",
       "\n",
       "   m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  m_avg_R_WristRotY  \\\n",
       "0              180.0                0.0                0.0              180.0   \n",
       "1              180.0                0.0                0.0              180.0   \n",
       "2              180.0                0.0                0.0              180.0   \n",
       "3              180.0                0.0                0.0              180.0   \n",
       "4              180.0                0.0                0.0              180.0   \n",
       "\n",
       "   m_avg_R_WristRotZ  Rot_diff_category  \n",
       "0                0.0                  0  \n",
       "1                0.0                  0  \n",
       "2                0.0                  0  \n",
       "3                0.0                  0  \n",
       "4                0.0                  0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('./combined_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터를 DataFrame으로 변환\n",
    "combined_df = pd.DataFrame(combined_df, columns=combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined_df.iloc[:897757]\n",
    "test = combined_df.iloc[897757:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_input = 30  # Sequence length\n",
    "n_features = 64  # Number of features\n",
    "output_units = (21 * 3) + 1  # Output shape\n",
    "head_size = 256  # Size of attention head\n",
    "num_heads = 8  # Number of attention heads\n",
    "ff_dim = 512  # Hidden layer size in feed forward network inside transformer\n",
    "num_blocks = 4  # Number of transformer blocks\n",
    "mlp_units = [512, 256, 128]  # Size of the dense layers of the final classifier\n",
    "dropout_rate = 0.3 \n",
    "\n",
    "# TimeseriesGenerator 생성\n",
    "train_generator = TimeseriesGenerator(X_train.values, X_train.values, length=n_input, batch_size=batch_size)\n",
    "val_generator = TimeseriesGenerator(X_val.values, X_val.values, length=n_input, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 30, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.  ,  180.  ,    0.  , ...,  180.  ,    0.  ,    0.  ],\n",
       "       [   0.  ,  180.  ,    0.  , ...,  180.  ,    0.  ,    0.  ],\n",
       "       [   0.  ,  180.  ,    0.  , ...,  180.  ,    0.  ,    0.  ],\n",
       "       ...,\n",
       "       [  30.89, -179.93,   -3.13, ...,  -10.73, -178.35,    0.  ],\n",
       "       [  30.89, -179.93,   -3.13, ...,  -10.55, -178.62,    0.  ],\n",
       "       [  30.79, -178.88,   -2.25, ...,  -10.52, -178.78,    0.  ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.initializers import HeNormal\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-Head Attention\n",
    "    attention_out = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    attention_out = layers.Dropout(dropout)(attention_out)\n",
    "    attention_out = layers.LayerNormalization(epsilon=1e-6)(inputs + attention_out)\n",
    "\n",
    "    # Feed Forward\n",
    "    ff_out = layers.Dense(ff_dim, activation=\"relu\", kernel_initializer=HeNormal())(attention_out)\n",
    "    ff_out = layers.Dropout(dropout)(ff_out)\n",
    "    ff_out = layers.Dense(inputs.shape[-1])(ff_out)\n",
    "    ff_out = layers.LayerNormalization(epsilon=1e-6)(attention_out + ff_out)\n",
    "    return ff_out\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_blocks, output_units, dropout=0, mlp_units=[]):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = transformer_block(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    for units in mlp_units:\n",
    "        x = layers.Dense(units, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(output_units, activation=\"linear\")(x)  # Sigmoid activation for output layer\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Building the model\n",
    "model = build_transformer_model(\n",
    "    input_shape=(n_input, n_features),\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_blocks=num_blocks,\n",
    "    dropout=dropout_rate,\n",
    "    mlp_units=mlp_units,\n",
    "    output_units=output_units\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  # patience를 7에서 15로 증가\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.00001)  # patience를 4에서 7로 증가, min_lr를 더 낮춤\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "csv_logger = CSVLogger('training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(Loss):\n",
    "    def __init__(self, weighted_columns_indices, weight_for_weighted_columns, weights_for_rot_diff_category, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weighted_columns_indices = tf.constant(weighted_columns_indices, dtype=tf.int32)\n",
    "        self.weight_for_weighted_columns = weight_for_weighted_columns\n",
    "        self.weights_for_rot_diff_category = tf.constant(weights_for_rot_diff_category, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # y_pred의 마지막 feature를 rot_diff_category로 분리\n",
    "        y_pred_values = y_pred[:, :-1]\n",
    "        rot_diff_pred = y_pred[:, -1]\n",
    "\n",
    "        # 런타임에 형태 확인\n",
    "        # tf.print(\"y_true shape:\", tf.shape(y_true))\n",
    "        # tf.print(\"y_pred_values shape:\", tf.shape(y_pred_values))\n",
    "\n",
    "        # MSE 계산\n",
    "        mse = tf.reduce_mean(tf.square(y_true[:, :-1] - y_pred_values), axis=-1)\n",
    "\n",
    "        # 특정 joint rotation에 대한 가중치 적용\n",
    "        weighted_mse = tf.gather(y_pred_values, self.weighted_columns_indices, axis=1)\n",
    "        weighted_mse = tf.square(weighted_mse) * self.weight_for_weighted_columns\n",
    "        mse += tf.reduce_mean(weighted_mse, axis=-1)\n",
    "\n",
    "        # rot_diff_category에 따른 가중치 적용\n",
    "        for category in range(len(self.weights_for_rot_diff_category)):\n",
    "            category_mask = tf.cast(tf.equal(rot_diff_pred, category), tf.float32)\n",
    "            category_mask = tf.expand_dims(category_mask, -1)  \n",
    "            weighted_mse = tf.square(y_true[:, :-1] - y_pred_values) * category_mask\n",
    "            mse += self.weights_for_rot_diff_category[category] * tf.reduce_mean(weighted_mse, axis=-1)\n",
    "\n",
    "        return mse\n",
    "\n",
    "# 가중치를 적용할 열 인덱스와 가중치 값\n",
    "weighted_columns_indices = [42, 43, 44, 48, 49, 50, 60, 61, 62]  # 예시 인덱스\n",
    "weight_for_weighted_columns = 2.0\n",
    "weights_for_rot_diff_category = [1.0, 1.5, 2.0]  # 1단계, 2단계, 3단계에 대한 가중치\n",
    "\n",
    "# CustomLoss 인스턴스 생성\n",
    "custom_loss_instance = CustomLoss(\n",
    "    weighted_columns_indices=weighted_columns_indices,\n",
    "    weight_for_weighted_columns=weight_for_weighted_columns,\n",
    "    weights_for_rot_diff_category=weights_for_rot_diff_category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss=custom_loss_instance)\n",
    "# model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 30, 64)      530496      ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 30, 64)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 30, 64)      0           ['input_1[0][0]',                \n",
      " da)                                                              'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 30, 64)      128         ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30, 512)      33280       ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 30, 512)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30, 64)       32832       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 30, 64)      0           ['layer_normalization[0][0]',    \n",
      " mbda)                                                            'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 30, 64)      530496      ['layer_normalization_1[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 30, 64)       0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_1[0][0]',  \n",
      " mbda)                                                            'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 30, 512)      33280       ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 30, 512)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 30, 64)       32832       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_2[0][0]',  \n",
      " mbda)                                                            'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 30, 64)      530496      ['layer_normalization_3[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 30, 64)       0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_3[0][0]',  \n",
      " mbda)                                                            'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30, 512)      33280       ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 30, 512)      0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30, 64)       32832       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_4[0][0]',  \n",
      " mbda)                                                            'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 30, 64)      530496      ['layer_normalization_5[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 30, 64)       0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_5[0][0]',  \n",
      " mbda)                                                            'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30, 512)      33280       ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 30, 512)      0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 30, 64)       32832       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 30, 64)      0           ['layer_normalization_6[0][0]',  \n",
      " mbda)                                                            'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 30, 64)      128         ['tf.__operators__.add_7[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30, 512)      33280       ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 30, 512)      0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 30, 512)     1024        ['dropout_8[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30, 256)      131328      ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 30, 256)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 30, 256)     512         ['dropout_9[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 30, 128)      32896       ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 30, 128)      0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 30, 128)     256         ['dropout_10[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_10[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           8256        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,595,008\n",
      "Trainable params: 2,595,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Current device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# 사용 가능한 GPU 목록을 출력합니다.\n",
    "print(\"Available GPUs:\", tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "# 현재 장치를 출력합니다.\n",
    "print(\"Current device:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5611/5611 [==============================] - 195s 34ms/step - loss: 5691.6318 - val_loss: 1704.4625 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 4660.6050 - val_loss: 1506.1758 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 4156.2295 - val_loss: 1439.0974 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "5611/5611 [==============================] - 202s 36ms/step - loss: 3912.5056 - val_loss: 1351.5619 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "5611/5611 [==============================] - 199s 35ms/step - loss: 3736.6506 - val_loss: 1360.5110 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 3584.1318 - val_loss: 1315.6389 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 3450.4883 - val_loss: 1343.3561 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 3326.0273 - val_loss: 1268.9901 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 3226.4331 - val_loss: 1169.1802 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 3149.3809 - val_loss: 1191.6908 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 3087.0576 - val_loss: 1245.7809 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 3021.7957 - val_loss: 1175.2893 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2948.7261 - val_loss: 1195.0939 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2878.4370 - val_loss: 1151.9425 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2818.2107 - val_loss: 1151.2620 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2758.7654 - val_loss: 1153.3892 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2706.1309 - val_loss: 1151.2135 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "5611/5611 [==============================] - 190s 34ms/step - loss: 2663.6150 - val_loss: 1131.9197 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2626.6257 - val_loss: 1140.9772 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "5611/5611 [==============================] - 190s 34ms/step - loss: 2590.0715 - val_loss: 1089.4188 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "5611/5611 [==============================] - 190s 34ms/step - loss: 2554.2402 - val_loss: 1112.8955 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2519.6382 - val_loss: 1135.0229 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2486.8120 - val_loss: 1102.4032 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2442.5513 - val_loss: 1108.2628 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2393.7800 - val_loss: 1089.9661 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2346.9646 - val_loss: 1117.4968 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2302.1946 - val_loss: 1105.2865 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2216.2046 - val_loss: 1072.2791 - lr: 2.0000e-05\n",
      "Epoch 29/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2197.5220 - val_loss: 1074.6669 - lr: 2.0000e-05\n",
      "Epoch 30/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2184.6216 - val_loss: 1091.6362 - lr: 2.0000e-05\n",
      "Epoch 31/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2171.2661 - val_loss: 1085.9088 - lr: 2.0000e-05\n",
      "Epoch 32/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2160.4387 - val_loss: 1094.2968 - lr: 2.0000e-05\n",
      "Epoch 33/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2149.9275 - val_loss: 1086.3027 - lr: 2.0000e-05\n",
      "Epoch 34/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2139.0984 - val_loss: 1071.3573 - lr: 2.0000e-05\n",
      "Epoch 35/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2128.8853 - val_loss: 1086.3182 - lr: 2.0000e-05\n",
      "Epoch 36/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2118.3667 - val_loss: 1087.8765 - lr: 2.0000e-05\n",
      "Epoch 37/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2109.1125 - val_loss: 1103.3684 - lr: 2.0000e-05\n",
      "Epoch 38/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2099.4719 - val_loss: 1099.3372 - lr: 2.0000e-05\n",
      "Epoch 39/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2090.2107 - val_loss: 1092.1970 - lr: 2.0000e-05\n",
      "Epoch 40/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2080.6987 - val_loss: 1104.9205 - lr: 2.0000e-05\n",
      "Epoch 41/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2072.3821 - val_loss: 1102.7183 - lr: 2.0000e-05\n",
      "Epoch 42/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2057.0298 - val_loss: 1100.6050 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2051.9890 - val_loss: 1107.8408 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2047.6525 - val_loss: 1090.8917 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2042.6038 - val_loss: 1093.3546 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2038.8864 - val_loss: 1089.9825 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2034.5004 - val_loss: 1114.2157 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "5611/5611 [==============================] - 191s 34ms/step - loss: 2030.5303 - val_loss: 1099.1827 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2026.2582 - val_loss: 1100.4065 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "5611/5611 [==============================] - 192s 34ms/step - loss: 2022.5248 - val_loss: 1104.3496 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e1da9fadf0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=50, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint, csv_logger]\n",
    "    # callbacks=[reduce_lr, model_checkpoint, csv_logger]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model_Transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2e888c1f730>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myloss = model.history.history['loss']\n",
    "myval_loss = model.history.history['val_loss']\n",
    "plt.plot(range(len(myloss)),myloss, label='Training Loss', color='blue')\n",
    "plt.plot(range(len(myval_loss)), myval_loss, label='Validation Loss', color = 'orange')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./B01_TransformData_FinalAvatar_20230922_171230.csv').iloc[300:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Time</th>\n",
       "      <th>m_avg_PelvisPosX</th>\n",
       "      <th>m_avg_PelvisPosY</th>\n",
       "      <th>m_avg_PelvisPosZ</th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipPosX</th>\n",
       "      <th>m_avg_L_HipPosY</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristPosX</th>\n",
       "      <th>m_avg_R_WristPosY</th>\n",
       "      <th>m_avg_R_WristPosZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>281</td>\n",
       "      <td>3.294551</td>\n",
       "      <td>0.163016</td>\n",
       "      <td>0.314659</td>\n",
       "      <td>1.710794</td>\n",
       "      <td>359.5202</td>\n",
       "      <td>356.6692</td>\n",
       "      <td>0.294904</td>\n",
       "      <td>0.107622</td>\n",
       "      <td>0.234367</td>\n",
       "      <td>...</td>\n",
       "      <td>7.194553</td>\n",
       "      <td>9.402476</td>\n",
       "      <td>310.8916</td>\n",
       "      <td>0.686491</td>\n",
       "      <td>0.386070</td>\n",
       "      <td>1.544025</td>\n",
       "      <td>1.171339</td>\n",
       "      <td>338.1900</td>\n",
       "      <td>324.1107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282</td>\n",
       "      <td>3.305790</td>\n",
       "      <td>0.163016</td>\n",
       "      <td>0.314659</td>\n",
       "      <td>1.710794</td>\n",
       "      <td>359.5202</td>\n",
       "      <td>356.6692</td>\n",
       "      <td>0.294904</td>\n",
       "      <td>0.107622</td>\n",
       "      <td>0.234367</td>\n",
       "      <td>...</td>\n",
       "      <td>6.706309</td>\n",
       "      <td>8.927062</td>\n",
       "      <td>309.3292</td>\n",
       "      <td>0.677366</td>\n",
       "      <td>0.376311</td>\n",
       "      <td>1.550525</td>\n",
       "      <td>0.682866</td>\n",
       "      <td>337.0667</td>\n",
       "      <td>322.3369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>283</td>\n",
       "      <td>3.316313</td>\n",
       "      <td>0.163470</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>1.709881</td>\n",
       "      <td>359.5370</td>\n",
       "      <td>356.6327</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>0.108054</td>\n",
       "      <td>0.233914</td>\n",
       "      <td>...</td>\n",
       "      <td>6.218950</td>\n",
       "      <td>8.483309</td>\n",
       "      <td>307.7678</td>\n",
       "      <td>0.669111</td>\n",
       "      <td>0.363508</td>\n",
       "      <td>1.551836</td>\n",
       "      <td>0.176055</td>\n",
       "      <td>335.8964</td>\n",
       "      <td>320.6281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>284</td>\n",
       "      <td>3.327757</td>\n",
       "      <td>0.163470</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>1.709881</td>\n",
       "      <td>359.5370</td>\n",
       "      <td>356.6327</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>0.108054</td>\n",
       "      <td>0.233914</td>\n",
       "      <td>...</td>\n",
       "      <td>5.701145</td>\n",
       "      <td>8.032418</td>\n",
       "      <td>306.2205</td>\n",
       "      <td>0.659482</td>\n",
       "      <td>0.354410</td>\n",
       "      <td>1.558534</td>\n",
       "      <td>359.852700</td>\n",
       "      <td>334.4614</td>\n",
       "      <td>319.1403</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>285</td>\n",
       "      <td>3.338641</td>\n",
       "      <td>0.163470</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>1.709881</td>\n",
       "      <td>359.5370</td>\n",
       "      <td>356.6327</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>0.108054</td>\n",
       "      <td>0.233914</td>\n",
       "      <td>...</td>\n",
       "      <td>5.132072</td>\n",
       "      <td>7.533837</td>\n",
       "      <td>304.6148</td>\n",
       "      <td>0.649262</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>1.565930</td>\n",
       "      <td>359.508200</td>\n",
       "      <td>332.9257</td>\n",
       "      <td>318.0372</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame      Time  m_avg_PelvisPosX  m_avg_PelvisPosY  m_avg_PelvisPosZ  \\\n",
       "280    281  3.294551          0.163016          0.314659          1.710794   \n",
       "281    282  3.305790          0.163016          0.314659          1.710794   \n",
       "282    283  3.316313          0.163470          0.314176          1.709881   \n",
       "283    284  3.327757          0.163470          0.314176          1.709881   \n",
       "284    285  3.338641          0.163470          0.314176          1.709881   \n",
       "\n",
       "     m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipPosX  \\\n",
       "280          359.5202          356.6692          0.294904         0.107622   \n",
       "281          359.5202          356.6692          0.294904         0.107622   \n",
       "282          359.5370          356.6327          0.269148         0.108054   \n",
       "283          359.5370          356.6327          0.269148         0.108054   \n",
       "284          359.5370          356.6327          0.269148         0.108054   \n",
       "\n",
       "     m_avg_L_HipPosY  ...  m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  \\\n",
       "280         0.234367  ...           7.194553           9.402476   \n",
       "281         0.234367  ...           6.706309           8.927062   \n",
       "282         0.233914  ...           6.218950           8.483309   \n",
       "283         0.233914  ...           5.701145           8.032418   \n",
       "284         0.233914  ...           5.132072           7.533837   \n",
       "\n",
       "     m_avg_R_ElbowRotZ  m_avg_R_WristPosX  m_avg_R_WristPosY  \\\n",
       "280           310.8916           0.686491           0.386070   \n",
       "281           309.3292           0.677366           0.376311   \n",
       "282           307.7678           0.669111           0.363508   \n",
       "283           306.2205           0.659482           0.354410   \n",
       "284           304.6148           0.649262           0.345275   \n",
       "\n",
       "     m_avg_R_WristPosZ  m_avg_R_WristRotX  m_avg_R_WristRotY  \\\n",
       "280           1.544025           1.171339           338.1900   \n",
       "281           1.550525           0.682866           337.0667   \n",
       "282           1.551836           0.176055           335.8964   \n",
       "283           1.558534         359.852700           334.4614   \n",
       "284           1.565930         359.508200           332.9257   \n",
       "\n",
       "     m_avg_R_WristRotZ  Unnamed: 128  \n",
       "280           324.1107           NaN  \n",
       "281           322.3369           NaN  \n",
       "282           320.6281           NaN  \n",
       "283           319.1403           NaN  \n",
       "284           318.0372           NaN  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rotation_columns = [col for col in test_df.columns if 'Rot' in col]\n",
    "test_rotation_df = test_df[test_rotation_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>359.52020</td>\n",
       "      <td>356.6692</td>\n",
       "      <td>0.294904</td>\n",
       "      <td>1.516567</td>\n",
       "      <td>0.428363</td>\n",
       "      <td>0.640516</td>\n",
       "      <td>356.1847</td>\n",
       "      <td>0.669316</td>\n",
       "      <td>359.864400</td>\n",
       "      <td>14.94714</td>\n",
       "      <td>...</td>\n",
       "      <td>353.6632</td>\n",
       "      <td>3.288348</td>\n",
       "      <td>5.412863</td>\n",
       "      <td>315.111500</td>\n",
       "      <td>7.194553</td>\n",
       "      <td>9.402476</td>\n",
       "      <td>310.891600</td>\n",
       "      <td>1.171339</td>\n",
       "      <td>338.1900</td>\n",
       "      <td>324.11070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>359.52020</td>\n",
       "      <td>356.6692</td>\n",
       "      <td>0.294904</td>\n",
       "      <td>1.516567</td>\n",
       "      <td>0.428363</td>\n",
       "      <td>0.640516</td>\n",
       "      <td>356.1847</td>\n",
       "      <td>0.669316</td>\n",
       "      <td>359.864400</td>\n",
       "      <td>14.94714</td>\n",
       "      <td>...</td>\n",
       "      <td>353.6632</td>\n",
       "      <td>2.694828</td>\n",
       "      <td>5.047416</td>\n",
       "      <td>313.595700</td>\n",
       "      <td>6.706309</td>\n",
       "      <td>8.927062</td>\n",
       "      <td>309.329200</td>\n",
       "      <td>0.682866</td>\n",
       "      <td>337.0667</td>\n",
       "      <td>322.33690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>359.53700</td>\n",
       "      <td>356.6327</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>1.754540</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.571299</td>\n",
       "      <td>355.8433</td>\n",
       "      <td>0.286560</td>\n",
       "      <td>359.710200</td>\n",
       "      <td>16.21369</td>\n",
       "      <td>...</td>\n",
       "      <td>352.4646</td>\n",
       "      <td>2.105070</td>\n",
       "      <td>4.715876</td>\n",
       "      <td>312.078900</td>\n",
       "      <td>6.218950</td>\n",
       "      <td>8.483309</td>\n",
       "      <td>307.767800</td>\n",
       "      <td>0.176055</td>\n",
       "      <td>335.8964</td>\n",
       "      <td>320.62810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>359.53700</td>\n",
       "      <td>356.6327</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>1.754540</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.571299</td>\n",
       "      <td>355.8433</td>\n",
       "      <td>0.286560</td>\n",
       "      <td>359.710200</td>\n",
       "      <td>16.21369</td>\n",
       "      <td>...</td>\n",
       "      <td>352.4646</td>\n",
       "      <td>1.488734</td>\n",
       "      <td>4.378508</td>\n",
       "      <td>310.575900</td>\n",
       "      <td>5.701145</td>\n",
       "      <td>8.032418</td>\n",
       "      <td>306.220500</td>\n",
       "      <td>359.852700</td>\n",
       "      <td>334.4614</td>\n",
       "      <td>319.14030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>359.53700</td>\n",
       "      <td>356.6327</td>\n",
       "      <td>0.269148</td>\n",
       "      <td>1.754540</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.571299</td>\n",
       "      <td>355.8433</td>\n",
       "      <td>0.286560</td>\n",
       "      <td>359.710200</td>\n",
       "      <td>16.21369</td>\n",
       "      <td>...</td>\n",
       "      <td>352.4646</td>\n",
       "      <td>0.820618</td>\n",
       "      <td>4.000119</td>\n",
       "      <td>309.015900</td>\n",
       "      <td>5.132072</td>\n",
       "      <td>7.533837</td>\n",
       "      <td>304.614800</td>\n",
       "      <td>359.508200</td>\n",
       "      <td>332.9257</td>\n",
       "      <td>318.03720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>0.37147</td>\n",
       "      <td>356.0375</td>\n",
       "      <td>356.225200</td>\n",
       "      <td>358.418900</td>\n",
       "      <td>5.324970</td>\n",
       "      <td>3.685883</td>\n",
       "      <td>352.3831</td>\n",
       "      <td>5.281562</td>\n",
       "      <td>2.817024</td>\n",
       "      <td>349.62190</td>\n",
       "      <td>...</td>\n",
       "      <td>357.3122</td>\n",
       "      <td>11.771050</td>\n",
       "      <td>23.381450</td>\n",
       "      <td>3.881207</td>\n",
       "      <td>11.318350</td>\n",
       "      <td>29.048820</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>350.620700</td>\n",
       "      <td>354.8369</td>\n",
       "      <td>17.56684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>0.37147</td>\n",
       "      <td>356.0375</td>\n",
       "      <td>356.225200</td>\n",
       "      <td>358.418900</td>\n",
       "      <td>5.324970</td>\n",
       "      <td>3.685883</td>\n",
       "      <td>352.3831</td>\n",
       "      <td>5.281562</td>\n",
       "      <td>2.817024</td>\n",
       "      <td>349.62190</td>\n",
       "      <td>...</td>\n",
       "      <td>357.3122</td>\n",
       "      <td>11.752190</td>\n",
       "      <td>23.405910</td>\n",
       "      <td>3.867805</td>\n",
       "      <td>11.300870</td>\n",
       "      <td>29.073060</td>\n",
       "      <td>0.416407</td>\n",
       "      <td>350.585900</td>\n",
       "      <td>354.8477</td>\n",
       "      <td>17.54634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>0.37147</td>\n",
       "      <td>356.0375</td>\n",
       "      <td>356.225200</td>\n",
       "      <td>358.418900</td>\n",
       "      <td>5.324970</td>\n",
       "      <td>3.685883</td>\n",
       "      <td>352.3831</td>\n",
       "      <td>5.281562</td>\n",
       "      <td>2.817024</td>\n",
       "      <td>349.62190</td>\n",
       "      <td>...</td>\n",
       "      <td>357.3122</td>\n",
       "      <td>11.730220</td>\n",
       "      <td>23.405460</td>\n",
       "      <td>3.867755</td>\n",
       "      <td>11.279010</td>\n",
       "      <td>29.072150</td>\n",
       "      <td>0.414099</td>\n",
       "      <td>350.555500</td>\n",
       "      <td>354.8747</td>\n",
       "      <td>17.46565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>0.37147</td>\n",
       "      <td>356.0375</td>\n",
       "      <td>356.225200</td>\n",
       "      <td>358.418900</td>\n",
       "      <td>5.324970</td>\n",
       "      <td>3.685883</td>\n",
       "      <td>352.3831</td>\n",
       "      <td>5.281562</td>\n",
       "      <td>2.817024</td>\n",
       "      <td>349.62190</td>\n",
       "      <td>...</td>\n",
       "      <td>357.3122</td>\n",
       "      <td>11.714710</td>\n",
       "      <td>23.414680</td>\n",
       "      <td>3.849796</td>\n",
       "      <td>11.265310</td>\n",
       "      <td>29.081210</td>\n",
       "      <td>0.394749</td>\n",
       "      <td>350.536600</td>\n",
       "      <td>354.9038</td>\n",
       "      <td>17.33500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>0.37147</td>\n",
       "      <td>356.0375</td>\n",
       "      <td>356.225200</td>\n",
       "      <td>358.418900</td>\n",
       "      <td>5.324970</td>\n",
       "      <td>3.685883</td>\n",
       "      <td>352.3831</td>\n",
       "      <td>5.281562</td>\n",
       "      <td>2.817024</td>\n",
       "      <td>349.62190</td>\n",
       "      <td>...</td>\n",
       "      <td>357.3122</td>\n",
       "      <td>11.693320</td>\n",
       "      <td>23.432290</td>\n",
       "      <td>3.847221</td>\n",
       "      <td>11.244280</td>\n",
       "      <td>29.098450</td>\n",
       "      <td>0.389981</td>\n",
       "      <td>350.519200</td>\n",
       "      <td>354.9141</td>\n",
       "      <td>17.36400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4496 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "280          359.52020          356.6692          0.294904         1.516567   \n",
       "281          359.52020          356.6692          0.294904         1.516567   \n",
       "282          359.53700          356.6327          0.269148         1.754540   \n",
       "283          359.53700          356.6327          0.269148         1.754540   \n",
       "284          359.53700          356.6327          0.269148         1.754540   \n",
       "...                ...               ...               ...              ...   \n",
       "4771           0.37147          356.0375        356.225200       358.418900   \n",
       "4772           0.37147          356.0375        356.225200       358.418900   \n",
       "4773           0.37147          356.0375        356.225200       358.418900   \n",
       "4774           0.37147          356.0375        356.225200       358.418900   \n",
       "4775           0.37147          356.0375        356.225200       358.418900   \n",
       "\n",
       "      m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "280          0.428363         0.640516          356.1847          0.669316   \n",
       "281          0.428363         0.640516          356.1847          0.669316   \n",
       "282          0.007881         0.571299          355.8433          0.286560   \n",
       "283          0.007881         0.571299          355.8433          0.286560   \n",
       "284          0.007881         0.571299          355.8433          0.286560   \n",
       "...               ...              ...               ...               ...   \n",
       "4771         5.324970         3.685883          352.3831          5.281562   \n",
       "4772         5.324970         3.685883          352.3831          5.281562   \n",
       "4773         5.324970         3.685883          352.3831          5.281562   \n",
       "4774         5.324970         3.685883          352.3831          5.281562   \n",
       "4775         5.324970         3.685883          352.3831          5.281562   \n",
       "\n",
       "      m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "280         359.864400           14.94714  ...            353.6632   \n",
       "281         359.864400           14.94714  ...            353.6632   \n",
       "282         359.710200           16.21369  ...            352.4646   \n",
       "283         359.710200           16.21369  ...            352.4646   \n",
       "284         359.710200           16.21369  ...            352.4646   \n",
       "...                ...                ...  ...                 ...   \n",
       "4771          2.817024          349.62190  ...            357.3122   \n",
       "4772          2.817024          349.62190  ...            357.3122   \n",
       "4773          2.817024          349.62190  ...            357.3122   \n",
       "4774          2.817024          349.62190  ...            357.3122   \n",
       "4775          2.817024          349.62190  ...            357.3122   \n",
       "\n",
       "      m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "280               3.288348              5.412863            315.111500   \n",
       "281               2.694828              5.047416            313.595700   \n",
       "282               2.105070              4.715876            312.078900   \n",
       "283               1.488734              4.378508            310.575900   \n",
       "284               0.820618              4.000119            309.015900   \n",
       "...                    ...                   ...                   ...   \n",
       "4771             11.771050             23.381450              3.881207   \n",
       "4772             11.752190             23.405910              3.867805   \n",
       "4773             11.730220             23.405460              3.867755   \n",
       "4774             11.714710             23.414680              3.849796   \n",
       "4775             11.693320             23.432290              3.847221   \n",
       "\n",
       "      m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  \\\n",
       "280            7.194553           9.402476         310.891600   \n",
       "281            6.706309           8.927062         309.329200   \n",
       "282            6.218950           8.483309         307.767800   \n",
       "283            5.701145           8.032418         306.220500   \n",
       "284            5.132072           7.533837         304.614800   \n",
       "...                 ...                ...                ...   \n",
       "4771          11.318350          29.048820           0.431600   \n",
       "4772          11.300870          29.073060           0.416407   \n",
       "4773          11.279010          29.072150           0.414099   \n",
       "4774          11.265310          29.081210           0.394749   \n",
       "4775          11.244280          29.098450           0.389981   \n",
       "\n",
       "      m_avg_R_WristRotX  m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "280            1.171339           338.1900          324.11070  \n",
       "281            0.682866           337.0667          322.33690  \n",
       "282            0.176055           335.8964          320.62810  \n",
       "283          359.852700           334.4614          319.14030  \n",
       "284          359.508200           332.9257          318.03720  \n",
       "...                 ...                ...                ...  \n",
       "4771         350.620700           354.8369           17.56684  \n",
       "4772         350.585900           354.8477           17.54634  \n",
       "4773         350.555500           354.8747           17.46565  \n",
       "4774         350.536600           354.9038           17.33500  \n",
       "4775         350.519200           354.9141           17.36400  \n",
       "\n",
       "[4496 rows x 63 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_25988\\1565179903.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_df[test_rotation_columns] = test_df[test_rotation_columns].applymap(normalize_angle)\n"
     ]
    }
   ],
   "source": [
    "#-180~180 사이로 정규화\n",
    "def normalize_angle(x):\n",
    "    x = np.where(x > 180, x - 360, x)\n",
    "    x = np.where(x < -180, x + 360, x)\n",
    "    return x\n",
    "test_df[test_rotation_columns] = test_df[test_rotation_columns].applymap(normalize_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_rotation_columns].map(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-0.48</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>14.95</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.34</td>\n",
       "      <td>3.29</td>\n",
       "      <td>5.41</td>\n",
       "      <td>-44.89</td>\n",
       "      <td>7.19</td>\n",
       "      <td>9.40</td>\n",
       "      <td>-49.11</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-21.81</td>\n",
       "      <td>-35.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.48</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>14.95</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.34</td>\n",
       "      <td>2.69</td>\n",
       "      <td>5.05</td>\n",
       "      <td>-46.40</td>\n",
       "      <td>6.71</td>\n",
       "      <td>8.93</td>\n",
       "      <td>-50.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-22.93</td>\n",
       "      <td>-37.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-0.46</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-4.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>16.21</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.54</td>\n",
       "      <td>2.11</td>\n",
       "      <td>4.72</td>\n",
       "      <td>-47.92</td>\n",
       "      <td>6.22</td>\n",
       "      <td>8.48</td>\n",
       "      <td>-52.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-24.10</td>\n",
       "      <td>-39.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.46</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-4.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>16.21</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.54</td>\n",
       "      <td>1.49</td>\n",
       "      <td>4.38</td>\n",
       "      <td>-49.42</td>\n",
       "      <td>5.70</td>\n",
       "      <td>8.03</td>\n",
       "      <td>-53.78</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-25.54</td>\n",
       "      <td>-40.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-0.46</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-4.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>16.21</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.54</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-50.98</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.53</td>\n",
       "      <td>-55.39</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-27.07</td>\n",
       "      <td>-41.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-10.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>11.77</td>\n",
       "      <td>23.38</td>\n",
       "      <td>3.88</td>\n",
       "      <td>11.32</td>\n",
       "      <td>29.05</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-9.38</td>\n",
       "      <td>-5.16</td>\n",
       "      <td>17.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-10.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>11.75</td>\n",
       "      <td>23.41</td>\n",
       "      <td>3.87</td>\n",
       "      <td>11.30</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-9.41</td>\n",
       "      <td>-5.15</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-10.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>11.73</td>\n",
       "      <td>23.41</td>\n",
       "      <td>3.87</td>\n",
       "      <td>11.28</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-9.44</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>17.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-10.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>11.71</td>\n",
       "      <td>23.41</td>\n",
       "      <td>3.85</td>\n",
       "      <td>11.27</td>\n",
       "      <td>29.08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-9.46</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>17.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>0.37</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>5.32</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-10.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>11.69</td>\n",
       "      <td>23.43</td>\n",
       "      <td>3.85</td>\n",
       "      <td>11.24</td>\n",
       "      <td>29.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-9.48</td>\n",
       "      <td>-5.09</td>\n",
       "      <td>17.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4496 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "280              -0.48             -3.33              0.29             1.52   \n",
       "281              -0.48             -3.33              0.29             1.52   \n",
       "282              -0.46             -3.37              0.27             1.75   \n",
       "283              -0.46             -3.37              0.27             1.75   \n",
       "284              -0.46             -3.37              0.27             1.75   \n",
       "...                ...               ...               ...              ...   \n",
       "4771              0.37             -3.96             -3.77            -1.58   \n",
       "4772              0.37             -3.96             -3.77            -1.58   \n",
       "4773              0.37             -3.96             -3.77            -1.58   \n",
       "4774              0.37             -3.96             -3.77            -1.58   \n",
       "4775              0.37             -3.96             -3.77            -1.58   \n",
       "\n",
       "      m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "280              0.43             0.64             -3.82              0.67   \n",
       "281              0.43             0.64             -3.82              0.67   \n",
       "282              0.01             0.57             -4.16              0.29   \n",
       "283              0.01             0.57             -4.16              0.29   \n",
       "284              0.01             0.57             -4.16              0.29   \n",
       "...               ...              ...               ...               ...   \n",
       "4771             5.32             3.69             -7.62              5.28   \n",
       "4772             5.32             3.69             -7.62              5.28   \n",
       "4773             5.32             3.69             -7.62              5.28   \n",
       "4774             5.32             3.69             -7.62              5.28   \n",
       "4775             5.32             3.69             -7.62              5.28   \n",
       "\n",
       "      m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "280              -0.14              14.95  ...               -6.34   \n",
       "281              -0.14              14.95  ...               -6.34   \n",
       "282              -0.29              16.21  ...               -7.54   \n",
       "283              -0.29              16.21  ...               -7.54   \n",
       "284              -0.29              16.21  ...               -7.54   \n",
       "...                ...                ...  ...                 ...   \n",
       "4771              2.82             -10.38  ...               -2.69   \n",
       "4772              2.82             -10.38  ...               -2.69   \n",
       "4773              2.82             -10.38  ...               -2.69   \n",
       "4774              2.82             -10.38  ...               -2.69   \n",
       "4775              2.82             -10.38  ...               -2.69   \n",
       "\n",
       "      m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "280                   3.29                  5.41                -44.89   \n",
       "281                   2.69                  5.05                -46.40   \n",
       "282                   2.11                  4.72                -47.92   \n",
       "283                   1.49                  4.38                -49.42   \n",
       "284                   0.82                  4.00                -50.98   \n",
       "...                    ...                   ...                   ...   \n",
       "4771                 11.77                 23.38                  3.88   \n",
       "4772                 11.75                 23.41                  3.87   \n",
       "4773                 11.73                 23.41                  3.87   \n",
       "4774                 11.71                 23.41                  3.85   \n",
       "4775                 11.69                 23.43                  3.85   \n",
       "\n",
       "      m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  \\\n",
       "280                7.19               9.40             -49.11   \n",
       "281                6.71               8.93             -50.67   \n",
       "282                6.22               8.48             -52.23   \n",
       "283                5.70               8.03             -53.78   \n",
       "284                5.13               7.53             -55.39   \n",
       "...                 ...                ...                ...   \n",
       "4771              11.32              29.05               0.43   \n",
       "4772              11.30              29.07               0.42   \n",
       "4773              11.28              29.07               0.41   \n",
       "4774              11.27              29.08               0.39   \n",
       "4775              11.24              29.10               0.39   \n",
       "\n",
       "      m_avg_R_WristRotX  m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "280                1.17             -21.81             -35.89  \n",
       "281                0.68             -22.93             -37.66  \n",
       "282                0.18             -24.10             -39.37  \n",
       "283               -0.15             -25.54             -40.86  \n",
       "284               -0.49             -27.07             -41.96  \n",
       "...                 ...                ...                ...  \n",
       "4771              -9.38              -5.16              17.57  \n",
       "4772              -9.41              -5.15              17.55  \n",
       "4773              -9.44              -5.13              17.47  \n",
       "4774              -9.46              -5.10              17.34  \n",
       "4775              -9.48              -5.09              17.36  \n",
       "\n",
       "[4496 rows x 63 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범위를 벗어나는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# -180 ~ 180 범위를 벗어나는 값이 있는지 확인\n",
    "num_values_out_of_range = (test_df > 180).sum().sum() + (test_df < -180).sum().sum()\n",
    "\n",
    "# 결과 확인\n",
    "if num_values_out_of_range > 0:\n",
    "    print(f\"범위를 벗어나는 값의 수: {num_values_out_of_range}\")\n",
    "else:\n",
    "    print(\"범위를 벗어나는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량 계산 및 범주화\n",
    "def calculate_average_change(test_df):\n",
    "    rotation_change_df = test_df.diff().abs()\n",
    "    rotation_change_df.iloc[0] = rotation_change_df.iloc[0].fillna(0)\n",
    "    average_change = rotation_change_df.mean(axis=1)\n",
    "    return average_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_average_change(average_change, thresholds):\n",
    "    categories = np.digitize(average_change, thresholds)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 변화량 범주 추가\n",
    "def add_change_category_to_df(test_df, thresholds):\n",
    "    average_change = calculate_average_change(test_df)\n",
    "    change_categories = categorize_average_change(average_change, thresholds)\n",
    "    test_df['Rot_diff_category'] = change_categories\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [5, 10]\n",
    "test_df = add_change_category_to_df(test_df, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4496, 64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 새로운 CSV 파일로 저장합니다.\n",
    "test_df.to_csv('./test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측 값을 넣을 빈 리스트\n",
    "test_predictions = []\n",
    "\n",
    "# 훈련 데이터셋에서 마지막 입력 개수의 값을 가져온 후\n",
    "current_batch = test_df[-n_input:].to_numpy().reshape((1, n_input, n_features))\n",
    "\n",
    "# 예측 과정 반복\n",
    "for i in range(1):\n",
    "    # 현재 배치에서 다음 포인트를 예측\n",
    "    current_pred = model.predict(current_batch)[0]  # 마지막 시퀀스 포인트 예측\n",
    "    # current_pred = np.array([normalize_angle(y) for y in current_pred])  # 예측값 정규화\n",
    "\n",
    "    # 예측된 마지막 프레임을 리스트에 추가\n",
    "    test_predictions.append(current_pred)\n",
    "\n",
    "    # 새로운 배치 생성: 마지막 시퀀스 제외하고 예측값 추가\n",
    "    current_batch = np.roll(current_batch, -1, axis=1)\n",
    "    current_batch[0, -1, :] = current_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-4.66026354e+00, -9.31943893e+00,  8.31496716e-03, -7.79080153e+00,\n",
       "        -4.64568853e+00,  1.20007110e+00, -1.39882212e+01, -6.04199505e+00,\n",
       "         2.24215341e+00, -8.82387733e+00,  1.14583082e+01,  6.64296532e+00,\n",
       "        -4.01321739e-01, -9.83897114e+00, -1.41252165e+01, -1.10838709e+01,\n",
       "         9.45258522e+00, -1.67459750e+00, -1.11818533e+01,  7.96739292e+00,\n",
       "        -1.74772596e+00, -2.46449089e+00,  1.33792210e+01,  9.29884434e-01,\n",
       "         7.96877623e+00,  1.00800695e+01, -1.07498217e+01, -6.19334412e+00,\n",
       "        -4.44937038e+00, -1.34534717e+00,  6.69827557e+00, -5.83558989e+00,\n",
       "        -2.96628952e+00,  4.95357084e+00, -1.30625038e+01,  5.97635460e+00,\n",
       "         1.22067523e+00,  4.46029358e+01,  8.93325329e-01, -1.55129814e+01,\n",
       "         1.59755011e+01, -4.97004356e+01, -1.85632312e+00,  3.42035460e+00,\n",
       "         8.46314251e-01, -1.10454261e+00, -4.13409376e+00, -1.22531664e+00,\n",
       "         6.97090626e-01, -9.77039099e-01,  4.10842150e-02,  6.12399864e+00,\n",
       "         3.13797545e+00, -7.21470690e+00, -6.70061636e+00, -3.88282847e+00,\n",
       "         6.03492260e+00, -1.72434902e+01,  2.53975658e+01,  3.44516525e+01,\n",
       "        -1.12314892e+00, -2.13073921e+00,  7.08183765e+00, -6.79270887e+00],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_array = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions 리스트의 각 항목을 (64,) 모양의 배열로 변환합니다.\n",
    "# test_predictions_flat = [pred.flatten() for pred in test_predictions]\n",
    "\n",
    "# 변환된 리스트를 데이터프레임으로 변환합니다.\n",
    "test_predictions = pd.DataFrame(test_predictions_array)\n",
    "\n",
    "# test_predictions 데이터프레임을 CSV 파일로 저장합니다.\n",
    "test_predictions.to_csv('./test_predictions.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.660264</td>\n",
       "      <td>-9.319439</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>-7.790802</td>\n",
       "      <td>-4.645689</td>\n",
       "      <td>1.200071</td>\n",
       "      <td>-13.988221</td>\n",
       "      <td>-6.041995</td>\n",
       "      <td>2.242153</td>\n",
       "      <td>-8.823877</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.700616</td>\n",
       "      <td>-3.882828</td>\n",
       "      <td>6.034923</td>\n",
       "      <td>-17.24349</td>\n",
       "      <td>25.397566</td>\n",
       "      <td>34.451653</td>\n",
       "      <td>-1.123149</td>\n",
       "      <td>-2.130739</td>\n",
       "      <td>7.081838</td>\n",
       "      <td>-6.792709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5          6   \\\n",
       "0 -4.660264 -9.319439  0.008315 -7.790802 -4.645689  1.200071 -13.988221   \n",
       "\n",
       "         7         8         9   ...        54        55        56        57  \\\n",
       "0 -6.041995  2.242153 -8.823877  ... -6.700616 -3.882828  6.034923 -17.24349   \n",
       "\n",
       "          58         59        60        61        62        63  \n",
       "0  25.397566  34.451653 -1.123149 -2.130739  7.081838 -6.792709  \n",
       "\n",
       "[1 rows x 64 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    'm_avg_PelvisRotX', 'm_avg_PelvisRotY', 'm_avg_PelvisRotZ',\n",
    "    'm_avg_L_HipRotX', 'm_avg_L_HipRotY', 'm_avg_L_HipRotZ',\n",
    "    'm_avg_L_KneeRotX', 'm_avg_L_KneeRotY', 'm_avg_L_KneeRotZ',\n",
    "    'm_avg_L_AnkleRotX', 'm_avg_L_AnkleRotY', 'm_avg_L_AnkleRotZ',\n",
    "    'm_avg_L_FootRotX', 'm_avg_L_FootRotY', 'm_avg_L_FootRotZ',\n",
    "    'm_avg_R_HipRotX', 'm_avg_R_HipRotY', 'm_avg_R_HipRotZ',\n",
    "    'm_avg_R_KneeRotX', 'm_avg_R_KneeRotY', 'm_avg_R_KneeRotZ',\n",
    "    'm_avg_R_AnkleRotX', 'm_avg_R_AnkleRotY', 'm_avg_R_AnkleRotZ',\n",
    "    'm_avg_R_FootRotX', 'm_avg_R_FootRotY', 'm_avg_R_FootRotZ',\n",
    "    'm_avg_Spine1RotX', 'm_avg_Spine1RotY', 'm_avg_Spine1RotZ',\n",
    "    'm_avg_Spine2RotX', 'm_avg_Spine2RotY', 'm_avg_Spine2RotZ',\n",
    "    'm_avg_L_CollarRotX', 'm_avg_L_CollarRotY', 'm_avg_L_CollarRotZ',\n",
    "    'm_avg_L_ShoulderRotX', 'm_avg_L_ShoulderRotY', 'm_avg_L_ShoulderRotZ',\n",
    "    'm_avg_L_ElbowRotX', 'm_avg_L_ElbowRotY', 'm_avg_L_ElbowRotZ',\n",
    "    'm_avg_L_WristRotX', 'm_avg_L_WristRotY', 'm_avg_L_WristRotZ',\n",
    "    'm_avg_NeckRotX', 'm_avg_NeckRotY', 'm_avg_NeckRotZ',\n",
    "    'm_avg_HeadRotX', 'm_avg_HeadRotY', 'm_avg_HeadRotZ',\n",
    "    'm_avg_R_CollarRotX', 'm_avg_R_CollarRotY', 'm_avg_R_CollarRotZ',\n",
    "    'm_avg_R_ShoulderRotX', 'm_avg_R_ShoulderRotY', 'm_avg_R_ShoulderRotZ',\n",
    "    'm_avg_R_ElbowRotX', 'm_avg_R_ElbowRotY', 'm_avg_R_ElbowRotZ',\n",
    "    'm_avg_R_WristRotX', 'm_avg_R_WristRotY', 'm_avg_R_WristRotZ',\n",
    "    'Rot_diff_category'\n",
    "]\n",
    "# input 데이터(test_df)의 마지막 5 프레임과 \n",
    "last_inputs_df = test_df.iloc[-30:][column_order].reset_index(drop=True)\n",
    "test_predictions_df = pd.DataFrame(test_predictions_array, columns=column_order)\n",
    "\n",
    "test_combined_df = pd.concat([last_inputs_df, test_predictions_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Rot_diff_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.940000</td>\n",
       "      <td>22.820000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>11.48000</td>\n",
       "      <td>28.490000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-8.110000</td>\n",
       "      <td>-5.270000</td>\n",
       "      <td>16.450000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>22.840000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>11.49000</td>\n",
       "      <td>28.510000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>-8.150000</td>\n",
       "      <td>-5.250000</td>\n",
       "      <td>16.470000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>22.850000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>11.48000</td>\n",
       "      <td>28.520000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>-8.210000</td>\n",
       "      <td>-5.230000</td>\n",
       "      <td>16.550000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>22.870000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>11.48000</td>\n",
       "      <td>28.540000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-8.310000</td>\n",
       "      <td>-5.240000</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>11.49000</td>\n",
       "      <td>28.570000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>-8.440000</td>\n",
       "      <td>-5.260000</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>22.940000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>11.49000</td>\n",
       "      <td>28.610000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-8.550000</td>\n",
       "      <td>-5.280000</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.960000</td>\n",
       "      <td>22.970000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>28.640000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>-8.650000</td>\n",
       "      <td>-5.310000</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.960000</td>\n",
       "      <td>22.980000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>-8.720000</td>\n",
       "      <td>-5.320000</td>\n",
       "      <td>16.790000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.970000</td>\n",
       "      <td>23.010000</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>11.51000</td>\n",
       "      <td>28.680000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>-8.730000</td>\n",
       "      <td>-5.310000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>23.030000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>11.49000</td>\n",
       "      <td>28.700000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-8.750000</td>\n",
       "      <td>-5.290000</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>11.48000</td>\n",
       "      <td>28.740000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-8.740000</td>\n",
       "      <td>-5.290000</td>\n",
       "      <td>17.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.940000</td>\n",
       "      <td>23.090000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>11.48000</td>\n",
       "      <td>28.760000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>-8.710000</td>\n",
       "      <td>-5.300000</td>\n",
       "      <td>17.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.930000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>11.47000</td>\n",
       "      <td>28.770000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-8.650000</td>\n",
       "      <td>-5.300000</td>\n",
       "      <td>16.970000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920000</td>\n",
       "      <td>23.110000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>11.46000</td>\n",
       "      <td>28.780000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-8.620000</td>\n",
       "      <td>-5.300000</td>\n",
       "      <td>16.920000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.910000</td>\n",
       "      <td>23.120000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>11.45000</td>\n",
       "      <td>28.790000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-8.600000</td>\n",
       "      <td>-5.280000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>23.160000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.43000</td>\n",
       "      <td>28.830000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-8.620000</td>\n",
       "      <td>-5.260000</td>\n",
       "      <td>17.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.890000</td>\n",
       "      <td>23.180000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.42000</td>\n",
       "      <td>28.850000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-8.710000</td>\n",
       "      <td>-5.230000</td>\n",
       "      <td>17.150000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>3.990000</td>\n",
       "      <td>11.41000</td>\n",
       "      <td>28.880000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-8.800000</td>\n",
       "      <td>-5.200000</td>\n",
       "      <td>17.230000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.870000</td>\n",
       "      <td>23.230000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>11.41000</td>\n",
       "      <td>28.890000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>-9.050000</td>\n",
       "      <td>-5.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.860000</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>11.41000</td>\n",
       "      <td>28.940000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-9.050000</td>\n",
       "      <td>-5.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>-4.050000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-1.540000</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-10.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.850000</td>\n",
       "      <td>23.260000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>11.39000</td>\n",
       "      <td>28.920000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-9.120000</td>\n",
       "      <td>-5.220000</td>\n",
       "      <td>17.130000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.940000</td>\n",
       "      <td>-3.810000</td>\n",
       "      <td>-1.530000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>-7.540000</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>-10.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.830000</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>11.38000</td>\n",
       "      <td>28.940000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-9.190000</td>\n",
       "      <td>-5.210000</td>\n",
       "      <td>17.140000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.940000</td>\n",
       "      <td>-3.810000</td>\n",
       "      <td>-1.530000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>-7.540000</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>-10.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.820000</td>\n",
       "      <td>23.310000</td>\n",
       "      <td>3.910000</td>\n",
       "      <td>11.36000</td>\n",
       "      <td>28.970000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>-9.240000</td>\n",
       "      <td>-5.190000</td>\n",
       "      <td>17.220000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.940000</td>\n",
       "      <td>-3.810000</td>\n",
       "      <td>-1.530000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>-7.540000</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>-10.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>23.340000</td>\n",
       "      <td>3.910000</td>\n",
       "      <td>11.35000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>-9.280000</td>\n",
       "      <td>-5.170000</td>\n",
       "      <td>17.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.960000</td>\n",
       "      <td>-3.770000</td>\n",
       "      <td>-1.580000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>-7.620000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>-10.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.790000</td>\n",
       "      <td>23.360000</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>11.33000</td>\n",
       "      <td>29.030000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>-9.330000</td>\n",
       "      <td>-5.150000</td>\n",
       "      <td>17.450000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.960000</td>\n",
       "      <td>-3.770000</td>\n",
       "      <td>-1.580000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>-7.620000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>-10.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.770000</td>\n",
       "      <td>23.380000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>11.32000</td>\n",
       "      <td>29.050000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>-9.380000</td>\n",
       "      <td>-5.160000</td>\n",
       "      <td>17.570000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.960000</td>\n",
       "      <td>-3.770000</td>\n",
       "      <td>-1.580000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>-7.620000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>-10.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>23.410000</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>11.30000</td>\n",
       "      <td>29.070000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>-9.410000</td>\n",
       "      <td>-5.150000</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.960000</td>\n",
       "      <td>-3.770000</td>\n",
       "      <td>-1.580000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>-7.620000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>-10.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.730000</td>\n",
       "      <td>23.410000</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>11.28000</td>\n",
       "      <td>29.070000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>-9.440000</td>\n",
       "      <td>-5.130000</td>\n",
       "      <td>17.470000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.960000</td>\n",
       "      <td>-3.770000</td>\n",
       "      <td>-1.580000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>-7.620000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>-10.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.710000</td>\n",
       "      <td>23.410000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>11.27000</td>\n",
       "      <td>29.080000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>-9.460000</td>\n",
       "      <td>-5.100000</td>\n",
       "      <td>17.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>-3.960000</td>\n",
       "      <td>-3.770000</td>\n",
       "      <td>-1.580000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>-7.620000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>-10.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.690000</td>\n",
       "      <td>23.430000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>11.24000</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>-9.480000</td>\n",
       "      <td>-5.090000</td>\n",
       "      <td>17.360000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-4.660264</td>\n",
       "      <td>-9.319439</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>-7.790802</td>\n",
       "      <td>-4.645689</td>\n",
       "      <td>1.200071</td>\n",
       "      <td>-13.988221</td>\n",
       "      <td>-6.041995</td>\n",
       "      <td>2.242153</td>\n",
       "      <td>-8.823877</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.700616</td>\n",
       "      <td>-3.882828</td>\n",
       "      <td>6.034923</td>\n",
       "      <td>-17.24349</td>\n",
       "      <td>25.397566</td>\n",
       "      <td>34.451653</td>\n",
       "      <td>-1.123149</td>\n",
       "      <td>-2.130739</td>\n",
       "      <td>7.081838</td>\n",
       "      <td>-6.792709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "1           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "2           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "3           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "4           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "5           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "6           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "7           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "8           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "9           0.430000         -4.050000         -3.900000        -1.540000   \n",
       "10          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "11          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "12          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "13          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "14          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "15          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "16          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "17          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "18          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "19          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "20          0.430000         -4.050000         -3.900000        -1.540000   \n",
       "21          0.370000         -3.940000         -3.810000        -1.530000   \n",
       "22          0.370000         -3.940000         -3.810000        -1.530000   \n",
       "23          0.370000         -3.940000         -3.810000        -1.530000   \n",
       "24          0.370000         -3.960000         -3.770000        -1.580000   \n",
       "25          0.370000         -3.960000         -3.770000        -1.580000   \n",
       "26          0.370000         -3.960000         -3.770000        -1.580000   \n",
       "27          0.370000         -3.960000         -3.770000        -1.580000   \n",
       "28          0.370000         -3.960000         -3.770000        -1.580000   \n",
       "29          0.370000         -3.960000         -3.770000        -1.580000   \n",
       "30         -4.660264         -9.319439          0.008315        -7.790802   \n",
       "\n",
       "    m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0          5.440000         3.670000         -7.500000          5.400000   \n",
       "1          5.440000         3.670000         -7.500000          5.400000   \n",
       "2          5.440000         3.670000         -7.500000          5.400000   \n",
       "3          5.440000         3.670000         -7.500000          5.400000   \n",
       "4          5.440000         3.670000         -7.500000          5.400000   \n",
       "5          5.440000         3.670000         -7.500000          5.400000   \n",
       "6          5.440000         3.670000         -7.500000          5.400000   \n",
       "7          5.440000         3.670000         -7.500000          5.400000   \n",
       "8          5.440000         3.670000         -7.500000          5.400000   \n",
       "9          5.440000         3.670000         -7.500000          5.400000   \n",
       "10         5.440000         3.670000         -7.500000          5.400000   \n",
       "11         5.440000         3.670000         -7.500000          5.400000   \n",
       "12         5.440000         3.670000         -7.500000          5.400000   \n",
       "13         5.440000         3.670000         -7.500000          5.400000   \n",
       "14         5.440000         3.670000         -7.500000          5.400000   \n",
       "15         5.440000         3.670000         -7.500000          5.400000   \n",
       "16         5.440000         3.670000         -7.500000          5.400000   \n",
       "17         5.440000         3.670000         -7.500000          5.400000   \n",
       "18         5.440000         3.670000         -7.500000          5.400000   \n",
       "19         5.440000         3.670000         -7.500000          5.400000   \n",
       "20         5.440000         3.670000         -7.500000          5.400000   \n",
       "21         5.330000         3.640000         -7.540000          5.290000   \n",
       "22         5.330000         3.640000         -7.540000          5.290000   \n",
       "23         5.330000         3.640000         -7.540000          5.290000   \n",
       "24         5.320000         3.690000         -7.620000          5.280000   \n",
       "25         5.320000         3.690000         -7.620000          5.280000   \n",
       "26         5.320000         3.690000         -7.620000          5.280000   \n",
       "27         5.320000         3.690000         -7.620000          5.280000   \n",
       "28         5.320000         3.690000         -7.620000          5.280000   \n",
       "29         5.320000         3.690000         -7.620000          5.280000   \n",
       "30        -4.645689         1.200071        -13.988221         -6.041995   \n",
       "\n",
       "    m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_ShoulderRotX  \\\n",
       "0           2.810000         -10.070000  ...             11.940000   \n",
       "1           2.810000         -10.070000  ...             11.950000   \n",
       "2           2.810000         -10.070000  ...             11.950000   \n",
       "3           2.810000         -10.070000  ...             11.950000   \n",
       "4           2.810000         -10.070000  ...             11.950000   \n",
       "5           2.810000         -10.070000  ...             11.950000   \n",
       "6           2.810000         -10.070000  ...             11.960000   \n",
       "7           2.810000         -10.070000  ...             11.960000   \n",
       "8           2.810000         -10.070000  ...             11.970000   \n",
       "9           2.810000         -10.070000  ...             11.950000   \n",
       "10          2.810000         -10.070000  ...             11.950000   \n",
       "11          2.810000         -10.070000  ...             11.940000   \n",
       "12          2.810000         -10.070000  ...             11.930000   \n",
       "13          2.810000         -10.070000  ...             11.920000   \n",
       "14          2.810000         -10.070000  ...             11.910000   \n",
       "15          2.810000         -10.070000  ...             11.900000   \n",
       "16          2.810000         -10.070000  ...             11.890000   \n",
       "17          2.810000         -10.070000  ...             11.880000   \n",
       "18          2.810000         -10.070000  ...             11.870000   \n",
       "19          2.810000         -10.070000  ...             11.860000   \n",
       "20          2.810000         -10.070000  ...             11.850000   \n",
       "21          2.770000         -10.250000  ...             11.830000   \n",
       "22          2.770000         -10.250000  ...             11.820000   \n",
       "23          2.770000         -10.250000  ...             11.800000   \n",
       "24          2.820000         -10.380000  ...             11.790000   \n",
       "25          2.820000         -10.380000  ...             11.770000   \n",
       "26          2.820000         -10.380000  ...             11.750000   \n",
       "27          2.820000         -10.380000  ...             11.730000   \n",
       "28          2.820000         -10.380000  ...             11.710000   \n",
       "29          2.820000         -10.380000  ...             11.690000   \n",
       "30          2.242153          -8.823877  ...             -6.700616   \n",
       "\n",
       "    m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  m_avg_R_ElbowRotX  \\\n",
       "0              22.820000              3.970000           11.48000   \n",
       "1              22.840000              3.960000           11.49000   \n",
       "2              22.850000              3.970000           11.48000   \n",
       "3              22.870000              3.980000           11.48000   \n",
       "4              22.900000              3.960000           11.49000   \n",
       "5              22.940000              3.970000           11.49000   \n",
       "6              22.970000              3.960000           11.50000   \n",
       "7              22.980000              3.960000           11.50000   \n",
       "8              23.010000              3.950000           11.51000   \n",
       "9              23.030000              3.970000           11.49000   \n",
       "10             23.070000              3.980000           11.48000   \n",
       "11             23.090000              3.970000           11.48000   \n",
       "12             23.100000              3.980000           11.47000   \n",
       "13             23.110000              3.990000           11.46000   \n",
       "14             23.120000              3.990000           11.45000   \n",
       "15             23.160000              4.000000           11.43000   \n",
       "16             23.180000              4.000000           11.42000   \n",
       "17             23.220000              3.990000           11.41000   \n",
       "18             23.230000              3.960000           11.41000   \n",
       "19             23.270000              3.920000           11.41000   \n",
       "20             23.260000              3.920000           11.39000   \n",
       "21             23.270000              3.920000           11.38000   \n",
       "22             23.310000              3.910000           11.36000   \n",
       "23             23.340000              3.910000           11.35000   \n",
       "24             23.360000              3.890000           11.33000   \n",
       "25             23.380000              3.880000           11.32000   \n",
       "26             23.410000              3.870000           11.30000   \n",
       "27             23.410000              3.870000           11.28000   \n",
       "28             23.410000              3.850000           11.27000   \n",
       "29             23.430000              3.850000           11.24000   \n",
       "30             -3.882828              6.034923          -17.24349   \n",
       "\n",
       "    m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  \\\n",
       "0           28.490000           0.540000          -8.110000   \n",
       "1           28.510000           0.530000          -8.150000   \n",
       "2           28.520000           0.530000          -8.210000   \n",
       "3           28.540000           0.540000          -8.310000   \n",
       "4           28.570000           0.530000          -8.440000   \n",
       "5           28.610000           0.540000          -8.550000   \n",
       "6           28.640000           0.530000          -8.650000   \n",
       "7           28.650000           0.530000          -8.720000   \n",
       "8           28.680000           0.520000          -8.730000   \n",
       "9           28.700000           0.540000          -8.750000   \n",
       "10          28.740000           0.540000          -8.740000   \n",
       "11          28.760000           0.540000          -8.710000   \n",
       "12          28.770000           0.550000          -8.650000   \n",
       "13          28.780000           0.560000          -8.620000   \n",
       "14          28.790000           0.550000          -8.600000   \n",
       "15          28.830000           0.560000          -8.620000   \n",
       "16          28.850000           0.560000          -8.710000   \n",
       "17          28.880000           0.550000          -8.800000   \n",
       "18          28.890000           0.520000          -9.050000   \n",
       "19          28.940000           0.480000          -9.050000   \n",
       "20          28.920000           0.480000          -9.120000   \n",
       "21          28.940000           0.480000          -9.190000   \n",
       "22          28.970000           0.460000          -9.240000   \n",
       "23          29.000000           0.460000          -9.280000   \n",
       "24          29.030000           0.440000          -9.330000   \n",
       "25          29.050000           0.430000          -9.380000   \n",
       "26          29.070000           0.420000          -9.410000   \n",
       "27          29.070000           0.410000          -9.440000   \n",
       "28          29.080000           0.390000          -9.460000   \n",
       "29          29.100000           0.390000          -9.480000   \n",
       "30          25.397566          34.451653          -1.123149   \n",
       "\n",
       "    m_avg_R_WristRotY  m_avg_R_WristRotZ  Rot_diff_category  \n",
       "0           -5.270000          16.450000           0.000000  \n",
       "1           -5.250000          16.470000           0.000000  \n",
       "2           -5.230000          16.550000           0.000000  \n",
       "3           -5.240000          16.680000           0.000000  \n",
       "4           -5.260000          16.740000           0.000000  \n",
       "5           -5.280000          16.770000           0.000000  \n",
       "6           -5.310000          16.770000           0.000000  \n",
       "7           -5.320000          16.790000           0.000000  \n",
       "8           -5.310000          16.850000           0.000000  \n",
       "9           -5.290000          16.910000           0.000000  \n",
       "10          -5.290000          17.040000           0.000000  \n",
       "11          -5.300000          17.040000           0.000000  \n",
       "12          -5.300000          16.970000           0.000000  \n",
       "13          -5.300000          16.920000           0.000000  \n",
       "14          -5.280000          16.930000           0.000000  \n",
       "15          -5.260000          17.050000           0.000000  \n",
       "16          -5.230000          17.150000           0.000000  \n",
       "17          -5.200000          17.230000           0.000000  \n",
       "18          -5.210000          17.200000           0.000000  \n",
       "19          -5.210000          17.200000           0.000000  \n",
       "20          -5.220000          17.130000           0.000000  \n",
       "21          -5.210000          17.140000           0.000000  \n",
       "22          -5.190000          17.220000           0.000000  \n",
       "23          -5.170000          17.340000           0.000000  \n",
       "24          -5.150000          17.450000           0.000000  \n",
       "25          -5.160000          17.570000           0.000000  \n",
       "26          -5.150000          17.550000           0.000000  \n",
       "27          -5.130000          17.470000           0.000000  \n",
       "28          -5.100000          17.340000           0.000000  \n",
       "29          -5.090000          17.360000           0.000000  \n",
       "30          -2.130739           7.081838          -6.792709  \n",
       "\n",
       "[31 rows x 64 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined_df.to_csv('./test_combined_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 10개로 output 1개 예측 되는지 확인\n",
    "# 차원 수 확인\n",
    "# transformer모델 고도화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihsens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
