{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './csvFiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 목록을 랜덤하게 섞습니다.\n",
    "random.seed(42)  # 재현 가능한 결과를 위해 시드 설정\n",
    "random.shuffle(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1545687217.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.iloc[300:-100]\n",
    "    df = df.applymap(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Time</th>\n",
       "      <th>m_avg_PelvisPosX</th>\n",
       "      <th>m_avg_PelvisPosY</th>\n",
       "      <th>m_avg_PelvisPosZ</th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipPosX</th>\n",
       "      <th>m_avg_L_HipPosY</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristPosX</th>\n",
       "      <th>m_avg_R_WristPosY</th>\n",
       "      <th>m_avg_R_WristPosZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.0</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.26</td>\n",
       "      <td>352.22</td>\n",
       "      <td>350.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.20</td>\n",
       "      <td>359.56</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>352.27</td>\n",
       "      <td>350.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>352.29</td>\n",
       "      <td>350.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>359.53</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>352.28</td>\n",
       "      <td>350.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.24</td>\n",
       "      <td>359.54</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>358.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>359.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>8.26</td>\n",
       "      <td>352.23</td>\n",
       "      <td>350.85</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.39</td>\n",
       "      <td>359.57</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250226</th>\n",
       "      <td>4599.0</td>\n",
       "      <td>51.25</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.55</td>\n",
       "      <td>179.77</td>\n",
       "      <td>357.66</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.13</td>\n",
       "      <td>198.30</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>47.17</td>\n",
       "      <td>37.40</td>\n",
       "      <td>178.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250227</th>\n",
       "      <td>4600.0</td>\n",
       "      <td>51.26</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.36</td>\n",
       "      <td>179.61</td>\n",
       "      <td>357.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.13</td>\n",
       "      <td>198.37</td>\n",
       "      <td>3.79</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>47.21</td>\n",
       "      <td>37.33</td>\n",
       "      <td>178.62</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250228</th>\n",
       "      <td>4601.0</td>\n",
       "      <td>51.27</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.36</td>\n",
       "      <td>179.61</td>\n",
       "      <td>357.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.13</td>\n",
       "      <td>198.42</td>\n",
       "      <td>3.84</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>47.29</td>\n",
       "      <td>37.23</td>\n",
       "      <td>178.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250229</th>\n",
       "      <td>4602.0</td>\n",
       "      <td>51.28</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.36</td>\n",
       "      <td>179.61</td>\n",
       "      <td>357.62</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.14</td>\n",
       "      <td>198.47</td>\n",
       "      <td>3.87</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>47.36</td>\n",
       "      <td>37.14</td>\n",
       "      <td>178.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250230</th>\n",
       "      <td>4603.0</td>\n",
       "      <td>51.29</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>18.45</td>\n",
       "      <td>179.67</td>\n",
       "      <td>357.49</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.14</td>\n",
       "      <td>198.51</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>47.44</td>\n",
       "      <td>37.06</td>\n",
       "      <td>178.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250231 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Frame   Time  m_avg_PelvisPosX  m_avg_PelvisPosY  m_avg_PelvisPosZ  \\\n",
       "0         301.0   3.45              0.02              0.54              0.69   \n",
       "1         302.0   3.47              0.02              0.54              0.69   \n",
       "2         303.0   3.48              0.02              0.54              0.69   \n",
       "3         304.0   3.49              0.02              0.54              0.69   \n",
       "4         305.0   3.50              0.02              0.54              0.69   \n",
       "...         ...    ...               ...               ...               ...   \n",
       "1250226  4599.0  51.25             -0.67              0.46              0.82   \n",
       "1250227  4600.0  51.26             -0.67              0.46              0.82   \n",
       "1250228  4601.0  51.27             -0.67              0.46              0.82   \n",
       "1250229  4602.0  51.28             -0.67              0.46              0.82   \n",
       "1250230  4603.0  51.29             -0.67              0.46              0.82   \n",
       "\n",
       "         m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  \\\n",
       "0                  358.82              0.68            359.84   \n",
       "1                  358.82              0.68            359.84   \n",
       "2                  358.82              0.68            359.84   \n",
       "3                  358.82              0.68            359.84   \n",
       "4                  358.82              0.68            359.84   \n",
       "...                   ...               ...               ...   \n",
       "1250226             18.55            179.77            357.66   \n",
       "1250227             18.36            179.61            357.62   \n",
       "1250228             18.36            179.61            357.62   \n",
       "1250229             18.36            179.61            357.62   \n",
       "1250230             18.45            179.67            357.49   \n",
       "\n",
       "         m_avg_L_HipPosX  m_avg_L_HipPosY  ...  m_avg_R_ElbowRotX  \\\n",
       "0                  -0.04             0.46  ...               8.26   \n",
       "1                  -0.04             0.46  ...               8.27   \n",
       "2                  -0.04             0.46  ...               8.27   \n",
       "3                  -0.04             0.46  ...               8.27   \n",
       "4                  -0.04             0.46  ...               8.26   \n",
       "...                  ...              ...  ...                ...   \n",
       "1250226            -0.61             0.39  ...              11.13   \n",
       "1250227            -0.61             0.39  ...              11.13   \n",
       "1250228            -0.61             0.39  ...              11.13   \n",
       "1250229            -0.61             0.39  ...              11.14   \n",
       "1250230            -0.61             0.39  ...              11.14   \n",
       "\n",
       "         m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristPosX  \\\n",
       "0                   352.22             350.74               0.73   \n",
       "1                   352.27             350.77               0.73   \n",
       "2                   352.29             350.81               0.73   \n",
       "3                   352.28             350.81               0.73   \n",
       "4                   352.23             350.85               0.73   \n",
       "...                    ...                ...                ...   \n",
       "1250226             198.30               3.76              -1.32   \n",
       "1250227             198.37               3.79              -1.32   \n",
       "1250228             198.42               3.84              -1.32   \n",
       "1250229             198.47               3.87              -1.32   \n",
       "1250230             198.51               3.90              -1.32   \n",
       "\n",
       "         m_avg_R_WristPosY  m_avg_R_WristPosZ  m_avg_R_WristRotX  \\\n",
       "0                     0.94               0.63               0.20   \n",
       "1                     0.94               0.63               0.11   \n",
       "2                     0.94               0.63               0.15   \n",
       "3                     0.94               0.63               0.24   \n",
       "4                     0.94               0.63               0.39   \n",
       "...                    ...                ...                ...   \n",
       "1250226               1.04               0.93              47.17   \n",
       "1250227               1.04               0.92              47.21   \n",
       "1250228               1.04               0.92              47.29   \n",
       "1250229               1.04               0.92              47.36   \n",
       "1250230               1.04               0.93              47.44   \n",
       "\n",
       "         m_avg_R_WristRotY  m_avg_R_WristRotZ  Unnamed: 128  \n",
       "0                   359.56               0.85           NaN  \n",
       "1                   359.54               0.88           NaN  \n",
       "2                   359.53               0.92           NaN  \n",
       "3                   359.54               0.96           NaN  \n",
       "4                   359.57               0.96           NaN  \n",
       "...                    ...                ...           ...  \n",
       "1250226              37.40             178.72           NaN  \n",
       "1250227              37.33             178.62           NaN  \n",
       "1250228              37.23             178.46           NaN  \n",
       "1250229              37.14             178.29           NaN  \n",
       "1250230              37.06             178.13           NaN  \n",
       "\n",
       "[1250231 rows x 129 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250231"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_columns_pos = [col for col in combined_df.columns if 'Pos' in col]\n",
    "rotation_df_pos = combined_df[rotation_columns_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_df_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_columns = [col for col in combined_df.columns if 'Rot' in col]\n",
    "rotation_df = combined_df[rotation_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -180~180 사이로 정규화\n",
    "normalize_angle = lambda x: (x - 360) if x > 180 else (x + 360) if x < -180 else x\n",
    "rotation_df = rotation_df.apply(lambda col: col.apply(normalize_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.78</td>\n",
       "      <td>-9.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.63</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-6.61</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.72</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.77</td>\n",
       "      <td>-9.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0             -1.18              0.68             -0.16            -0.28   \n",
       "1             -1.18              0.68             -0.16            -0.28   \n",
       "2             -1.18              0.68             -0.16            -0.28   \n",
       "3             -1.18              0.68             -0.16            -0.28   \n",
       "4             -1.18              0.68             -0.16            -0.28   \n",
       "\n",
       "   m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0             0.11            -0.02             -0.93              0.18   \n",
       "1             0.11            -0.02             -0.93              0.18   \n",
       "2             0.11            -0.02             -0.93              0.18   \n",
       "3             0.11            -0.02             -0.93              0.18   \n",
       "4             0.11            -0.02             -0.93              0.18   \n",
       "\n",
       "   m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "0             -0.09               0.04  ...                 1.8   \n",
       "1             -0.09               0.04  ...                 1.8   \n",
       "2             -0.09               0.04  ...                 1.8   \n",
       "3             -0.09               0.04  ...                 1.8   \n",
       "4             -0.09               0.04  ...                 1.8   \n",
       "\n",
       "   m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "0                  9.14                 -0.34                 -6.66   \n",
       "1                  9.14                 -0.35                 -6.63   \n",
       "2                  9.13                 -0.37                 -6.61   \n",
       "3                  9.12                 -0.39                 -6.62   \n",
       "4                  9.12                 -0.35                 -6.60   \n",
       "\n",
       "   m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  \\\n",
       "0               8.26              -7.78              -9.26               0.20   \n",
       "1               8.27              -7.73              -9.23               0.11   \n",
       "2               8.27              -7.71              -9.19               0.15   \n",
       "3               8.27              -7.72              -9.19               0.24   \n",
       "4               8.26              -7.77              -9.15               0.39   \n",
       "\n",
       "   m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "0              -0.44               0.85  \n",
       "1              -0.46               0.88  \n",
       "2              -0.47               0.92  \n",
       "3              -0.46               0.96  \n",
       "4              -0.43               0.96  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 프레임과의 차이를 계산하여 변화량 DataFrame을 생성\n",
    "rotation_change_df = rotation_df.diff().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량을 계산하는 함수\n",
    "def calculate_average_change(rotation_df):\n",
    "    rotation_change_df = rotation_df.diff().abs()\n",
    "    # 첫 번째 행의 NaN 값을 0으로 채우기 (또는 다른 합리적인 값으로 채울 수 있음)\n",
    "    rotation_change_df.iloc[0] = rotation_change_df.iloc[0].fillna(0)\n",
    "    # 모든 joint의 변화량에 대한 평균을 계산\n",
    "    average_change = rotation_change_df.mean(axis=1)\n",
    "    return average_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량을 기준으로 데이터를 1, 2, 3단계로 나누는 함수\n",
    "def categorize_average_change(average_change, thresholds):\n",
    "    # 변화량에 따라 범주화\n",
    "    categories = np.digitize(average_change, thresholds)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame에 변화량 범주를 추가하는 함수\n",
    "def add_change_category_to_df(rotation_df, thresholds):\n",
    "    average_change = calculate_average_change(rotation_df)\n",
    "    change_categories = categorize_average_change(average_change, thresholds)\n",
    "    rotation_df['Rot_diff_category'] = change_categories\n",
    "    return rotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 설정 (예: [5, 10])\n",
    "thresholds = [5, 10]\n",
    "combined_df = add_change_category_to_df(rotation_df, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범위를 벗어나는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# -180 ~ 180 범위를 벗어나는 값이 있는지 확인\n",
    "num_values_out_of_range = (combined_df > 180).sum().sum() + (combined_df < -180).sum().sum()\n",
    "\n",
    "# 결과 확인\n",
    "if num_values_out_of_range > 0:\n",
    "    print(f\"범위를 벗어나는 값의 수: {num_values_out_of_range}\")\n",
    "else:\n",
    "    print(\"범위를 벗어나는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rot_diff_category\n",
      "0    1161534\n",
      "1      59415\n",
      "2      29282\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = combined_df['Rot_diff_category'].value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Rot_diff_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.78</td>\n",
       "      <td>-9.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.14</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.63</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-6.61</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.71</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-6.62</td>\n",
       "      <td>8.27</td>\n",
       "      <td>-7.72</td>\n",
       "      <td>-9.19</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.12</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-7.77</td>\n",
       "      <td>-9.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0             -1.18              0.68             -0.16            -0.28   \n",
       "1             -1.18              0.68             -0.16            -0.28   \n",
       "2             -1.18              0.68             -0.16            -0.28   \n",
       "3             -1.18              0.68             -0.16            -0.28   \n",
       "4             -1.18              0.68             -0.16            -0.28   \n",
       "\n",
       "   m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0             0.11            -0.02             -0.93              0.18   \n",
       "1             0.11            -0.02             -0.93              0.18   \n",
       "2             0.11            -0.02             -0.93              0.18   \n",
       "3             0.11            -0.02             -0.93              0.18   \n",
       "4             0.11            -0.02             -0.93              0.18   \n",
       "\n",
       "   m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_ShoulderRotX  \\\n",
       "0             -0.09               0.04  ...                  9.14   \n",
       "1             -0.09               0.04  ...                  9.14   \n",
       "2             -0.09               0.04  ...                  9.13   \n",
       "3             -0.09               0.04  ...                  9.12   \n",
       "4             -0.09               0.04  ...                  9.12   \n",
       "\n",
       "   m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  m_avg_R_ElbowRotX  \\\n",
       "0                 -0.34                 -6.66               8.26   \n",
       "1                 -0.35                 -6.63               8.27   \n",
       "2                 -0.37                 -6.61               8.27   \n",
       "3                 -0.39                 -6.62               8.27   \n",
       "4                 -0.35                 -6.60               8.26   \n",
       "\n",
       "   m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  m_avg_R_WristRotY  \\\n",
       "0              -7.78              -9.26               0.20              -0.44   \n",
       "1              -7.73              -9.23               0.11              -0.46   \n",
       "2              -7.71              -9.19               0.15              -0.47   \n",
       "3              -7.72              -9.19               0.24              -0.46   \n",
       "4              -7.77              -9.15               0.39              -0.43   \n",
       "\n",
       "   m_avg_R_WristRotZ  Rot_diff_category  \n",
       "0               0.85                  0  \n",
       "1               0.88                  0  \n",
       "2               0.92                  0  \n",
       "3               0.96                  0  \n",
       "4               0.96                  0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('./combined_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터를 DataFrame으로 변환\n",
    "combined_df = pd.DataFrame(combined_df, columns=combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined_df.iloc[:897757]\n",
    "test = combined_df.iloc[897757:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_input = 30  # Sequence length\n",
    "n_features = 64  # Number of features\n",
    "output_units = (21 * 3) + 1  # Output shape\n",
    "head_size = 320  # Size of attention head\n",
    "num_heads = 8  # Number of attention heads\n",
    "ff_dim = 512  # Hidden layer size in feed forward network inside transformer\n",
    "num_blocks = 4  # Number of transformer blocks\n",
    "mlp_units = [512, 256, 128]  # Size of the dense layers of the final classifier\n",
    "dropout_rate = 0.3 \n",
    "\n",
    "# TimeseriesGenerator 생성\n",
    "train_generator = TimeseriesGenerator(X_train.values, X_train.values, length=n_input, batch_size=batch_size)\n",
    "val_generator = TimeseriesGenerator(X_val.values, X_val.values, length=n_input, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 30, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0800e+00,  1.1200e+00,  1.0000e-02, ..., -8.1000e-01,\n",
       "         9.1000e-01,  0.0000e+00],\n",
       "       [-1.0800e+00,  1.1200e+00,  1.0000e-02, ..., -8.3000e-01,\n",
       "         9.0000e-01,  0.0000e+00],\n",
       "       [-1.0800e+00,  1.1200e+00,  1.0000e-02, ..., -8.7000e-01,\n",
       "         8.7000e-01,  0.0000e+00],\n",
       "       ...,\n",
       "       [-5.7600e+00, -1.1000e+00, -3.8900e+00, ..., -1.3011e+02,\n",
       "         4.3780e+01,  0.0000e+00],\n",
       "       [-5.7800e+00, -1.1600e+00, -3.8700e+00, ..., -1.3085e+02,\n",
       "         4.4590e+01,  0.0000e+00],\n",
       "       [-5.7800e+00, -1.1600e+00, -3.8700e+00, ..., -1.3135e+02,\n",
       "         4.5340e+01,  0.0000e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.initializers import HeNormal\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "def positional_encoding(input_shape):\n",
    "    n_steps, n_features = input_shape\n",
    "    pos_enc = np.zeros((n_steps, n_features))\n",
    "    for pos in range(n_steps):\n",
    "        for i in range(n_features):\n",
    "            if i % 2 == 0:\n",
    "                pos_enc[pos, i] = np.sin(pos / (10000 ** ((2 * i) / n_features)))\n",
    "            else:\n",
    "                pos_enc[pos, i] = np.cos(pos / (10000 ** ((2 * (i - 1)) / n_features)))\n",
    "    return pos_enc\n",
    "\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-Head Attention\n",
    "    attention_out =layers. MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    attention_out = Dropout(dropout)(attention_out)\n",
    "    attention_out = layers.LayerNormalization(epsilon=1e-6)(inputs + attention_out)\n",
    "\n",
    "    # Feed Forward\n",
    "    ff_out = Dense(ff_dim, activation=\"relu\", kernel_initializer=HeNormal())(attention_out)\n",
    "    ff_out = Dropout(dropout)(ff_out)\n",
    "    ff_out = Dense(inputs.shape[-1])(ff_out)\n",
    "    ff_out = layers.LayerNormalization(epsilon=1e-6)(attention_out + ff_out)\n",
    "    return ff_out\n",
    "\n",
    "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_blocks, output_units, dropout=0, mlp_units=[]):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Add positional encoding\n",
    "    pos_enc = positional_encoding(input_shape)\n",
    "    x = inputs + pos_enc\n",
    "\n",
    "    # Add one more transformer block\n",
    "    num_blocks += 1\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = transformer_block(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    for units in mlp_units:\n",
    "        x = Dense(units, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(output_units, activation=\"linear\")(x)  # Change to sigmoid if needed\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Building the model\n",
    "model = build_transformer_model(\n",
    "    input_shape=(n_input, n_features),\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_blocks=num_blocks,\n",
    "    dropout=dropout_rate,\n",
    "    mlp_units=mlp_units,\n",
    "    output_units=output_units\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  # patience를 7에서 15로 증가\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.00001)  # patience를 4에서 7로 증가, min_lr를 더 낮춤\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "csv_logger = CSVLogger('training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(Loss):\n",
    "    def __init__(self, weighted_columns_indices, weight_for_weighted_columns, weights_for_rot_diff_category, **kwargs):\n",
    "    # def __init__(self, weighted_columns_indices, weight_for_weighted_columns, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weighted_columns_indices = tf.constant(weighted_columns_indices, dtype=tf.int32)\n",
    "        self.weight_for_weighted_columns = weight_for_weighted_columns\n",
    "        self.weights_for_rot_diff_category = tf.constant(weights_for_rot_diff_category, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # y_pred의 마지막 feature를 rot_diff_category로 분리\n",
    "        y_pred_values = y_pred[:, :-1]\n",
    "        rot_diff_pred = y_pred[:, -1]\n",
    "\n",
    "        # 런타임에 형태 확인\n",
    "        # tf.print(\"y_true shape:\", tf.shape(y_true))\n",
    "        # tf.print(\"y_pred_values shape:\", tf.shape(y_pred_values))\n",
    "\n",
    "        # MSE 계산\n",
    "        mse = tf.reduce_mean(tf.square(y_true[:, :-1] - y_pred_values), axis=-1)\n",
    "\n",
    "        # 특정 joint rotation에 대한 가중치 적용\n",
    "        weighted_mse = tf.gather(y_pred_values, self.weighted_columns_indices, axis=1)\n",
    "        weighted_mse = tf.square(weighted_mse) * self.weight_for_weighted_columns\n",
    "        mse += tf.reduce_mean(weighted_mse, axis=-1)\n",
    "\n",
    "        # rot_diff_category에 따른 가중치 적용\n",
    "        for category in range(len(self.weights_for_rot_diff_category)):\n",
    "            category_mask = tf.cast(tf.equal(rot_diff_pred, category), tf.float32)\n",
    "            category_mask = tf.expand_dims(category_mask, -1)  \n",
    "            weighted_mse = tf.square(y_true[:, :-1] - y_pred_values) * category_mask\n",
    "            mse += self.weights_for_rot_diff_category[category] * tf.reduce_mean(weighted_mse, axis=-1)\n",
    "\n",
    "        return mse\n",
    "\n",
    "# 가중치를 적용할 열 인덱스와 가중치 값\n",
    "weighted_columns_indices = [42, 43, 44, 48, 49, 50, 60, 61, 62]  # 예시 인덱스\n",
    "weight_for_weighted_columns = 2.0\n",
    "weights_for_rot_diff_category = [1.0, 1.5, 2.0]  # 1단계, 2단계, 3단계에 대한 가중치\n",
    "\n",
    "# CustomLoss 인스턴스 생성\n",
    "custom_loss_instance = CustomLoss(\n",
    "    weighted_columns_indices=weighted_columns_indices,\n",
    "    weight_for_weighted_columns=weight_for_weighted_columns,\n",
    "    weights_for_rot_diff_category=weights_for_rot_diff_category\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss=custom_loss_instance)\n",
    "# model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30, 64)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 30, 64)      0           ['input_2[0][0]']                \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 30, 64)      663104      ['tf.__operators__.add_11[0][0]',\n",
      " eadAttention)                                                    'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 30, 64)       0           ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 30, 64)      0           ['tf.__operators__.add_11[0][0]',\n",
      " ambda)                                                           'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 30, 512)      33280       ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 30, 512)      0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 30, 64)       32832       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 30, 64)      0           ['layer_normalization_13[0][0]', \n",
      " ambda)                                                           'dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 30, 64)      663104      ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 30, 64)       0           ['multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 30, 64)      0           ['layer_normalization_14[0][0]', \n",
      " ambda)                                                           'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 30, 512)      33280       ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 30, 512)      0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 30, 64)       32832       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 30, 64)      0           ['layer_normalization_15[0][0]', \n",
      " ambda)                                                           'dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_15[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 30, 64)      663104      ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 30, 64)       0           ['multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 30, 64)      0           ['layer_normalization_16[0][0]', \n",
      " ambda)                                                           'dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 30, 512)      33280       ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 30, 512)      0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 30, 64)       32832       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 30, 64)      0           ['layer_normalization_17[0][0]', \n",
      " ambda)                                                           'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 30, 64)      663104      ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 30, 64)       0           ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 30, 64)      0           ['layer_normalization_18[0][0]', \n",
      " ambda)                                                           'dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 30, 512)      33280       ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 30, 512)      0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 30, 64)       32832       ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 30, 64)      0           ['layer_normalization_19[0][0]', \n",
      " ambda)                                                           'dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 30, 64)      663104      ['layer_normalization_20[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 30, 64)       0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 30, 64)      0           ['layer_normalization_20[0][0]', \n",
      " ambda)                                                           'dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 30, 512)      33280       ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 30, 512)      0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 30, 64)       32832       ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 30, 64)      0           ['layer_normalization_21[0][0]', \n",
      " ambda)                                                           'dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 30, 64)      128         ['tf.__operators__.add_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 30, 512)      33280       ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 30, 512)      0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 30, 512)     1024        ['dropout_23[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 30, 256)      131328      ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 30, 256)      0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 30, 256)     512         ['dropout_24[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 30, 128)      32896       ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 30, 128)      0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 30, 128)     256         ['dropout_25[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['layer_normalization_25[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 64)           8256        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,854,912\n",
      "Trainable params: 3,854,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Current device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# 사용 가능한 GPU 목록을 출력합니다.\n",
    "print(\"Available GPUs:\", tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "# 현재 장치를 출력합니다.\n",
    "print(\"Current device:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5611/5611 [==============================] - 222s 39ms/step - loss: 3598.1375 - val_loss: 3318.3064 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2966.6392 - val_loss: 2879.7239 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2657.4802 - val_loss: 2720.2737 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2505.9036 - val_loss: 2684.4893 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2421.9495 - val_loss: 2662.1707 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2365.4878 - val_loss: 2726.1731 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2316.9219 - val_loss: 2664.5337 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2272.6074 - val_loss: 2621.8491 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 2234.3958 - val_loss: 2586.4065 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2203.6758 - val_loss: 2631.1338 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2171.9622 - val_loss: 2479.8779 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2143.6821 - val_loss: 2489.8472 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2113.9060 - val_loss: 2469.8284 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 2088.4490 - val_loss: 2418.6931 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2064.4216 - val_loss: 2411.1841 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2040.4692 - val_loss: 2414.8342 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 2021.7306 - val_loss: 2378.5886 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 2000.0165 - val_loss: 2380.3567 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1978.6471 - val_loss: 2386.4507 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1957.8710 - val_loss: 2355.6990 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1941.0563 - val_loss: 2377.6936 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1921.4403 - val_loss: 2353.4653 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1902.2041 - val_loss: 2289.9209 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1884.8912 - val_loss: 2354.3589 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1870.7908 - val_loss: 2326.1606 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1855.8599 - val_loss: 2310.9072 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1838.5106 - val_loss: 2324.8728 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1822.6921 - val_loss: 2247.5649 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1806.7433 - val_loss: 2277.8342 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1788.2378 - val_loss: 2305.5347 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1770.0735 - val_loss: 2259.8701 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1751.7996 - val_loss: 2250.5691 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1729.9663 - val_loss: 2222.8528 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1707.6066 - val_loss: 2185.9871 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1684.5244 - val_loss: 2166.7185 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1663.4336 - val_loss: 2164.9771 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1645.6647 - val_loss: 2126.9990 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1626.6356 - val_loss: 2178.6714 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1611.6262 - val_loss: 2165.0840 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1598.1392 - val_loss: 2148.2695 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1588.6654 - val_loss: 2132.9128 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1575.2823 - val_loss: 2125.9746 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1566.1968 - val_loss: 2156.9185 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1555.7593 - val_loss: 2118.0225 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1544.7375 - val_loss: 2139.0813 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1534.3369 - val_loss: 2116.7139 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1522.7434 - val_loss: 2132.2134 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1516.0376 - val_loss: 2142.9722 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "5611/5611 [==============================] - 218s 39ms/step - loss: 1505.3130 - val_loss: 2134.0063 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "5611/5611 [==============================] - 219s 39ms/step - loss: 1494.1176 - val_loss: 2089.6528 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d871b5cdf0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=50, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint, csv_logger]\n",
    "    # callbacks=[reduce_lr, model_checkpoint, csv_logger]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model_Transformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1df047dfeb0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myloss = model.history.history['loss']\n",
    "myval_loss = model.history.history['val_loss']\n",
    "plt.plot(range(len(myloss)),myloss, label='Training Loss', color='blue')\n",
    "plt.plot(range(len(myval_loss)), myval_loss, label='Validation Loss', color = 'orange')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./B01_TransformData_FinalAvatar_20230922_171230.csv').iloc[300:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Time</th>\n",
       "      <th>m_avg_PelvisPosX</th>\n",
       "      <th>m_avg_PelvisPosY</th>\n",
       "      <th>m_avg_PelvisPosZ</th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipPosX</th>\n",
       "      <th>m_avg_L_HipPosY</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristPosX</th>\n",
       "      <th>m_avg_R_WristPosY</th>\n",
       "      <th>m_avg_R_WristPosZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301</td>\n",
       "      <td>3.516298</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>0.309281</td>\n",
       "      <td>1.707612</td>\n",
       "      <td>357.083</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>0.110527</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>...</td>\n",
       "      <td>351.9312</td>\n",
       "      <td>358.1726</td>\n",
       "      <td>282.4885</td>\n",
       "      <td>0.484731</td>\n",
       "      <td>0.254242</td>\n",
       "      <td>1.712456</td>\n",
       "      <td>339.4850</td>\n",
       "      <td>296.8258</td>\n",
       "      <td>305.4126</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>302</td>\n",
       "      <td>3.527282</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>0.309281</td>\n",
       "      <td>1.707612</td>\n",
       "      <td>357.083</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>0.110527</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>...</td>\n",
       "      <td>350.7178</td>\n",
       "      <td>357.2758</td>\n",
       "      <td>281.4112</td>\n",
       "      <td>0.473791</td>\n",
       "      <td>0.253382</td>\n",
       "      <td>1.724783</td>\n",
       "      <td>337.8150</td>\n",
       "      <td>292.9910</td>\n",
       "      <td>307.2033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>3.538654</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>0.309281</td>\n",
       "      <td>1.707612</td>\n",
       "      <td>357.083</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>0.110527</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>...</td>\n",
       "      <td>349.4878</td>\n",
       "      <td>356.3683</td>\n",
       "      <td>280.3726</td>\n",
       "      <td>0.462770</td>\n",
       "      <td>0.253029</td>\n",
       "      <td>1.736980</td>\n",
       "      <td>336.0336</td>\n",
       "      <td>289.2522</td>\n",
       "      <td>308.9090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>304</td>\n",
       "      <td>3.549650</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.316027</td>\n",
       "      <td>1.705714</td>\n",
       "      <td>357.288</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>0.112322</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>...</td>\n",
       "      <td>348.2825</td>\n",
       "      <td>355.5042</td>\n",
       "      <td>279.3825</td>\n",
       "      <td>0.452501</td>\n",
       "      <td>0.258765</td>\n",
       "      <td>1.747534</td>\n",
       "      <td>334.1286</td>\n",
       "      <td>285.3405</td>\n",
       "      <td>310.8063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>3.561161</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.316027</td>\n",
       "      <td>1.705714</td>\n",
       "      <td>357.288</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>0.112322</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>...</td>\n",
       "      <td>346.9774</td>\n",
       "      <td>354.4922</td>\n",
       "      <td>278.4650</td>\n",
       "      <td>0.441532</td>\n",
       "      <td>0.259532</td>\n",
       "      <td>1.759929</td>\n",
       "      <td>332.4753</td>\n",
       "      <td>281.4930</td>\n",
       "      <td>312.3235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frame      Time  m_avg_PelvisPosX  m_avg_PelvisPosY  m_avg_PelvisPosZ  \\\n",
       "300    301  3.516298          0.167637          0.309281          1.707612   \n",
       "301    302  3.527282          0.167637          0.309281          1.707612   \n",
       "302    303  3.538654          0.167637          0.309281          1.707612   \n",
       "303    304  3.549650          0.169145          0.316027          1.705714   \n",
       "304    305  3.561161          0.169145          0.316027          1.705714   \n",
       "\n",
       "     m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipPosX  \\\n",
       "300           357.083          356.5699          359.1780         0.110527   \n",
       "301           357.083          356.5699          359.1780         0.110527   \n",
       "302           357.083          356.5699          359.1780         0.110527   \n",
       "303           357.288          355.9712          359.2451         0.112322   \n",
       "304           357.288          355.9712          359.2451         0.112322   \n",
       "\n",
       "     m_avg_L_HipPosY  ...  m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  \\\n",
       "300         0.229474  ...           351.9312           358.1726   \n",
       "301         0.229474  ...           350.7178           357.2758   \n",
       "302         0.229474  ...           349.4878           356.3683   \n",
       "303         0.236200  ...           348.2825           355.5042   \n",
       "304         0.236200  ...           346.9774           354.4922   \n",
       "\n",
       "     m_avg_R_ElbowRotZ  m_avg_R_WristPosX  m_avg_R_WristPosY  \\\n",
       "300           282.4885           0.484731           0.254242   \n",
       "301           281.4112           0.473791           0.253382   \n",
       "302           280.3726           0.462770           0.253029   \n",
       "303           279.3825           0.452501           0.258765   \n",
       "304           278.4650           0.441532           0.259532   \n",
       "\n",
       "     m_avg_R_WristPosZ  m_avg_R_WristRotX  m_avg_R_WristRotY  \\\n",
       "300           1.712456           339.4850           296.8258   \n",
       "301           1.724783           337.8150           292.9910   \n",
       "302           1.736980           336.0336           289.2522   \n",
       "303           1.747534           334.1286           285.3405   \n",
       "304           1.759929           332.4753           281.4930   \n",
       "\n",
       "     m_avg_R_WristRotZ  Unnamed: 128  \n",
       "300           305.4126           NaN  \n",
       "301           307.2033           NaN  \n",
       "302           308.9090           NaN  \n",
       "303           310.8063           NaN  \n",
       "304           312.3235           NaN  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rotation_columns = [col for col in test_df.columns if 'Rot' in col]\n",
    "test_rotation_df = test_df[test_rotation_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>357.083000</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>3.120952</td>\n",
       "      <td>2.614980</td>\n",
       "      <td>1.605597</td>\n",
       "      <td>357.2850</td>\n",
       "      <td>2.783687</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>354.665700</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0468</td>\n",
       "      <td>346.61580</td>\n",
       "      <td>356.47380</td>\n",
       "      <td>287.389800</td>\n",
       "      <td>351.93120</td>\n",
       "      <td>358.17260</td>\n",
       "      <td>282.488500</td>\n",
       "      <td>339.4850</td>\n",
       "      <td>296.8258</td>\n",
       "      <td>305.41260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>357.083000</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>3.120952</td>\n",
       "      <td>2.614980</td>\n",
       "      <td>1.605597</td>\n",
       "      <td>357.2850</td>\n",
       "      <td>2.783687</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>354.665700</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0468</td>\n",
       "      <td>345.37230</td>\n",
       "      <td>355.67140</td>\n",
       "      <td>286.328600</td>\n",
       "      <td>350.71780</td>\n",
       "      <td>357.27580</td>\n",
       "      <td>281.411200</td>\n",
       "      <td>337.8150</td>\n",
       "      <td>292.9910</td>\n",
       "      <td>307.20330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>357.083000</td>\n",
       "      <td>356.5699</td>\n",
       "      <td>359.1780</td>\n",
       "      <td>3.120952</td>\n",
       "      <td>2.614980</td>\n",
       "      <td>1.605597</td>\n",
       "      <td>357.2850</td>\n",
       "      <td>2.783687</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>354.665700</td>\n",
       "      <td>...</td>\n",
       "      <td>350.0468</td>\n",
       "      <td>344.11480</td>\n",
       "      <td>354.85520</td>\n",
       "      <td>285.303200</td>\n",
       "      <td>349.48780</td>\n",
       "      <td>356.36830</td>\n",
       "      <td>280.372600</td>\n",
       "      <td>336.0336</td>\n",
       "      <td>289.2522</td>\n",
       "      <td>308.90900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>357.288000</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>1.685574</td>\n",
       "      <td>5.019152</td>\n",
       "      <td>2.186052</td>\n",
       "      <td>356.7885</td>\n",
       "      <td>5.105362</td>\n",
       "      <td>1.477256</td>\n",
       "      <td>4.062734</td>\n",
       "      <td>...</td>\n",
       "      <td>349.6448</td>\n",
       "      <td>342.88500</td>\n",
       "      <td>354.07880</td>\n",
       "      <td>284.322500</td>\n",
       "      <td>348.28250</td>\n",
       "      <td>355.50420</td>\n",
       "      <td>279.382500</td>\n",
       "      <td>334.1286</td>\n",
       "      <td>285.3405</td>\n",
       "      <td>310.80630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>357.288000</td>\n",
       "      <td>355.9712</td>\n",
       "      <td>359.2451</td>\n",
       "      <td>1.685574</td>\n",
       "      <td>5.019152</td>\n",
       "      <td>2.186052</td>\n",
       "      <td>356.7885</td>\n",
       "      <td>5.105362</td>\n",
       "      <td>1.477256</td>\n",
       "      <td>4.062734</td>\n",
       "      <td>...</td>\n",
       "      <td>349.6448</td>\n",
       "      <td>341.55870</td>\n",
       "      <td>353.14730</td>\n",
       "      <td>283.414800</td>\n",
       "      <td>346.97740</td>\n",
       "      <td>354.49220</td>\n",
       "      <td>278.465000</td>\n",
       "      <td>332.4753</td>\n",
       "      <td>281.4930</td>\n",
       "      <td>312.32350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>0.638496</td>\n",
       "      <td>355.0141</td>\n",
       "      <td>356.6961</td>\n",
       "      <td>357.393600</td>\n",
       "      <td>4.837928</td>\n",
       "      <td>3.512594</td>\n",
       "      <td>349.2009</td>\n",
       "      <td>4.826385</td>\n",
       "      <td>2.328943</td>\n",
       "      <td>349.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>353.4269</td>\n",
       "      <td>10.94913</td>\n",
       "      <td>21.90927</td>\n",
       "      <td>6.278744</td>\n",
       "      <td>10.26911</td>\n",
       "      <td>27.53492</td>\n",
       "      <td>2.730536</td>\n",
       "      <td>355.6536</td>\n",
       "      <td>355.0251</td>\n",
       "      <td>20.78619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0.638496</td>\n",
       "      <td>355.0141</td>\n",
       "      <td>356.6961</td>\n",
       "      <td>357.393600</td>\n",
       "      <td>4.837928</td>\n",
       "      <td>3.512594</td>\n",
       "      <td>349.2009</td>\n",
       "      <td>4.826385</td>\n",
       "      <td>2.328943</td>\n",
       "      <td>349.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>353.4269</td>\n",
       "      <td>10.96714</td>\n",
       "      <td>21.80633</td>\n",
       "      <td>6.167922</td>\n",
       "      <td>10.29771</td>\n",
       "      <td>27.43369</td>\n",
       "      <td>2.622310</td>\n",
       "      <td>355.6207</td>\n",
       "      <td>354.8966</td>\n",
       "      <td>20.48832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>0.638496</td>\n",
       "      <td>355.0141</td>\n",
       "      <td>356.6961</td>\n",
       "      <td>357.393600</td>\n",
       "      <td>4.837928</td>\n",
       "      <td>3.512594</td>\n",
       "      <td>349.2009</td>\n",
       "      <td>4.826385</td>\n",
       "      <td>2.328943</td>\n",
       "      <td>349.104800</td>\n",
       "      <td>...</td>\n",
       "      <td>353.4269</td>\n",
       "      <td>10.97428</td>\n",
       "      <td>21.70186</td>\n",
       "      <td>6.112121</td>\n",
       "      <td>10.31019</td>\n",
       "      <td>27.33001</td>\n",
       "      <td>2.567600</td>\n",
       "      <td>355.6002</td>\n",
       "      <td>354.7376</td>\n",
       "      <td>20.17733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>0.646919</td>\n",
       "      <td>355.0108</td>\n",
       "      <td>356.7127</td>\n",
       "      <td>357.546200</td>\n",
       "      <td>5.342571</td>\n",
       "      <td>3.862668</td>\n",
       "      <td>349.4238</td>\n",
       "      <td>5.280097</td>\n",
       "      <td>2.694932</td>\n",
       "      <td>349.240000</td>\n",
       "      <td>...</td>\n",
       "      <td>353.2370</td>\n",
       "      <td>10.99195</td>\n",
       "      <td>21.59484</td>\n",
       "      <td>6.029818</td>\n",
       "      <td>10.33570</td>\n",
       "      <td>27.22439</td>\n",
       "      <td>2.487622</td>\n",
       "      <td>355.6598</td>\n",
       "      <td>354.5097</td>\n",
       "      <td>19.92392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>0.646919</td>\n",
       "      <td>355.0108</td>\n",
       "      <td>356.7127</td>\n",
       "      <td>357.546200</td>\n",
       "      <td>5.342571</td>\n",
       "      <td>3.862668</td>\n",
       "      <td>349.4238</td>\n",
       "      <td>5.280097</td>\n",
       "      <td>2.694932</td>\n",
       "      <td>349.240000</td>\n",
       "      <td>...</td>\n",
       "      <td>353.2370</td>\n",
       "      <td>10.99784</td>\n",
       "      <td>21.51480</td>\n",
       "      <td>5.988278</td>\n",
       "      <td>10.34555</td>\n",
       "      <td>27.14502</td>\n",
       "      <td>2.446991</td>\n",
       "      <td>355.7557</td>\n",
       "      <td>354.3958</td>\n",
       "      <td>19.77342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4376 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "300         357.083000          356.5699          359.1780         3.120952   \n",
       "301         357.083000          356.5699          359.1780         3.120952   \n",
       "302         357.083000          356.5699          359.1780         3.120952   \n",
       "303         357.288000          355.9712          359.2451         1.685574   \n",
       "304         357.288000          355.9712          359.2451         1.685574   \n",
       "...                ...               ...               ...              ...   \n",
       "4671          0.638496          355.0141          356.6961       357.393600   \n",
       "4672          0.638496          355.0141          356.6961       357.393600   \n",
       "4673          0.638496          355.0141          356.6961       357.393600   \n",
       "4674          0.646919          355.0108          356.7127       357.546200   \n",
       "4675          0.646919          355.0108          356.7127       357.546200   \n",
       "\n",
       "      m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "300          2.614980         1.605597          357.2850          2.783687   \n",
       "301          2.614980         1.605597          357.2850          2.783687   \n",
       "302          2.614980         1.605597          357.2850          2.783687   \n",
       "303          5.019152         2.186052          356.7885          5.105362   \n",
       "304          5.019152         2.186052          356.7885          5.105362   \n",
       "...               ...              ...               ...               ...   \n",
       "4671         4.837928         3.512594          349.2009          4.826385   \n",
       "4672         4.837928         3.512594          349.2009          4.826385   \n",
       "4673         4.837928         3.512594          349.2009          4.826385   \n",
       "4674         5.342571         3.862668          349.4238          5.280097   \n",
       "4675         5.342571         3.862668          349.4238          5.280097   \n",
       "\n",
       "      m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "300           0.762435         354.665700  ...            350.0468   \n",
       "301           0.762435         354.665700  ...            350.0468   \n",
       "302           0.762435         354.665700  ...            350.0468   \n",
       "303           1.477256           4.062734  ...            349.6448   \n",
       "304           1.477256           4.062734  ...            349.6448   \n",
       "...                ...                ...  ...                 ...   \n",
       "4671          2.328943         349.104800  ...            353.4269   \n",
       "4672          2.328943         349.104800  ...            353.4269   \n",
       "4673          2.328943         349.104800  ...            353.4269   \n",
       "4674          2.694932         349.240000  ...            353.2370   \n",
       "4675          2.694932         349.240000  ...            353.2370   \n",
       "\n",
       "      m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "300              346.61580             356.47380            287.389800   \n",
       "301              345.37230             355.67140            286.328600   \n",
       "302              344.11480             354.85520            285.303200   \n",
       "303              342.88500             354.07880            284.322500   \n",
       "304              341.55870             353.14730            283.414800   \n",
       "...                    ...                   ...                   ...   \n",
       "4671              10.94913              21.90927              6.278744   \n",
       "4672              10.96714              21.80633              6.167922   \n",
       "4673              10.97428              21.70186              6.112121   \n",
       "4674              10.99195              21.59484              6.029818   \n",
       "4675              10.99784              21.51480              5.988278   \n",
       "\n",
       "      m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  \\\n",
       "300           351.93120          358.17260         282.488500   \n",
       "301           350.71780          357.27580         281.411200   \n",
       "302           349.48780          356.36830         280.372600   \n",
       "303           348.28250          355.50420         279.382500   \n",
       "304           346.97740          354.49220         278.465000   \n",
       "...                 ...                ...                ...   \n",
       "4671           10.26911           27.53492           2.730536   \n",
       "4672           10.29771           27.43369           2.622310   \n",
       "4673           10.31019           27.33001           2.567600   \n",
       "4674           10.33570           27.22439           2.487622   \n",
       "4675           10.34555           27.14502           2.446991   \n",
       "\n",
       "      m_avg_R_WristRotX  m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "300            339.4850           296.8258          305.41260  \n",
       "301            337.8150           292.9910          307.20330  \n",
       "302            336.0336           289.2522          308.90900  \n",
       "303            334.1286           285.3405          310.80630  \n",
       "304            332.4753           281.4930          312.32350  \n",
       "...                 ...                ...                ...  \n",
       "4671           355.6536           355.0251           20.78619  \n",
       "4672           355.6207           354.8966           20.48832  \n",
       "4673           355.6002           354.7376           20.17733  \n",
       "4674           355.6598           354.5097           19.92392  \n",
       "4675           355.7557           354.3958           19.77342  \n",
       "\n",
       "[4376 rows x 63 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_26396\\1565179903.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_df[test_rotation_columns] = test_df[test_rotation_columns].applymap(normalize_angle)\n"
     ]
    }
   ],
   "source": [
    "#-180~180 사이로 정규화\n",
    "def normalize_angle(x):\n",
    "    x = np.where(x > 180, x - 360, x)\n",
    "    x = np.where(x < -180, x + 360, x)\n",
    "    return x\n",
    "test_df[test_rotation_columns] = test_df[test_rotation_columns].applymap(normalize_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_rotation_columns].map(lambda x: float(f\"{x:.2f}\") if isinstance(x, (int, float)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_CollarRotZ</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>-13.38</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>-72.61</td>\n",
       "      <td>-8.07</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>-77.51</td>\n",
       "      <td>-20.51</td>\n",
       "      <td>-63.17</td>\n",
       "      <td>-54.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>-14.63</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>-73.67</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-78.59</td>\n",
       "      <td>-22.19</td>\n",
       "      <td>-67.01</td>\n",
       "      <td>-52.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.95</td>\n",
       "      <td>-15.89</td>\n",
       "      <td>-5.14</td>\n",
       "      <td>-74.70</td>\n",
       "      <td>-10.51</td>\n",
       "      <td>-3.63</td>\n",
       "      <td>-79.63</td>\n",
       "      <td>-23.97</td>\n",
       "      <td>-70.75</td>\n",
       "      <td>-51.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.69</td>\n",
       "      <td>5.02</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-3.21</td>\n",
       "      <td>5.11</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.06</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-17.12</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>-75.68</td>\n",
       "      <td>-11.72</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-80.62</td>\n",
       "      <td>-25.87</td>\n",
       "      <td>-74.66</td>\n",
       "      <td>-49.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.69</td>\n",
       "      <td>5.02</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-3.21</td>\n",
       "      <td>5.11</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.06</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>-18.44</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>-76.59</td>\n",
       "      <td>-13.02</td>\n",
       "      <td>-5.51</td>\n",
       "      <td>-81.54</td>\n",
       "      <td>-27.52</td>\n",
       "      <td>-78.51</td>\n",
       "      <td>-47.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>10.95</td>\n",
       "      <td>21.91</td>\n",
       "      <td>6.28</td>\n",
       "      <td>10.27</td>\n",
       "      <td>27.53</td>\n",
       "      <td>2.73</td>\n",
       "      <td>-4.35</td>\n",
       "      <td>-4.97</td>\n",
       "      <td>20.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>10.97</td>\n",
       "      <td>21.81</td>\n",
       "      <td>6.17</td>\n",
       "      <td>10.30</td>\n",
       "      <td>27.43</td>\n",
       "      <td>2.62</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>20.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-10.80</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-10.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>10.97</td>\n",
       "      <td>21.70</td>\n",
       "      <td>6.11</td>\n",
       "      <td>10.31</td>\n",
       "      <td>27.33</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-4.40</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>20.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-10.58</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-10.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.76</td>\n",
       "      <td>10.99</td>\n",
       "      <td>21.59</td>\n",
       "      <td>6.03</td>\n",
       "      <td>10.34</td>\n",
       "      <td>27.22</td>\n",
       "      <td>2.49</td>\n",
       "      <td>-4.34</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>19.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-10.58</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-10.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.76</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.51</td>\n",
       "      <td>5.99</td>\n",
       "      <td>10.35</td>\n",
       "      <td>27.15</td>\n",
       "      <td>2.45</td>\n",
       "      <td>-4.24</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>19.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4376 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "300              -2.92             -3.43             -0.82             3.12   \n",
       "301              -2.92             -3.43             -0.82             3.12   \n",
       "302              -2.92             -3.43             -0.82             3.12   \n",
       "303              -2.71             -4.03             -0.75             1.69   \n",
       "304              -2.71             -4.03             -0.75             1.69   \n",
       "...                ...               ...               ...              ...   \n",
       "4671              0.64             -4.99             -3.30            -2.61   \n",
       "4672              0.64             -4.99             -3.30            -2.61   \n",
       "4673              0.64             -4.99             -3.30            -2.61   \n",
       "4674              0.65             -4.99             -3.29            -2.45   \n",
       "4675              0.65             -4.99             -3.29            -2.45   \n",
       "\n",
       "      m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "300              2.61             1.61             -2.71              2.78   \n",
       "301              2.61             1.61             -2.71              2.78   \n",
       "302              2.61             1.61             -2.71              2.78   \n",
       "303              5.02             2.19             -3.21              5.11   \n",
       "304              5.02             2.19             -3.21              5.11   \n",
       "...               ...              ...               ...               ...   \n",
       "4671             4.84             3.51            -10.80              4.83   \n",
       "4672             4.84             3.51            -10.80              4.83   \n",
       "4673             4.84             3.51            -10.80              4.83   \n",
       "4674             5.34             3.86            -10.58              5.28   \n",
       "4675             5.34             3.86            -10.58              5.28   \n",
       "\n",
       "      m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_CollarRotZ  \\\n",
       "300               0.76              -5.33  ...               -9.95   \n",
       "301               0.76              -5.33  ...               -9.95   \n",
       "302               0.76              -5.33  ...               -9.95   \n",
       "303               1.48               4.06  ...              -10.36   \n",
       "304               1.48               4.06  ...              -10.36   \n",
       "...                ...                ...  ...                 ...   \n",
       "4671              2.33             -10.90  ...               -6.57   \n",
       "4672              2.33             -10.90  ...               -6.57   \n",
       "4673              2.33             -10.90  ...               -6.57   \n",
       "4674              2.69             -10.76  ...               -6.76   \n",
       "4675              2.69             -10.76  ...               -6.76   \n",
       "\n",
       "      m_avg_R_ShoulderRotX  m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  \\\n",
       "300                 -13.38                 -3.53                -72.61   \n",
       "301                 -14.63                 -4.33                -73.67   \n",
       "302                 -15.89                 -5.14                -74.70   \n",
       "303                 -17.12                 -5.92                -75.68   \n",
       "304                 -18.44                 -6.85                -76.59   \n",
       "...                    ...                   ...                   ...   \n",
       "4671                 10.95                 21.91                  6.28   \n",
       "4672                 10.97                 21.81                  6.17   \n",
       "4673                 10.97                 21.70                  6.11   \n",
       "4674                 10.99                 21.59                  6.03   \n",
       "4675                 11.00                 21.51                  5.99   \n",
       "\n",
       "      m_avg_R_ElbowRotX  m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  \\\n",
       "300               -8.07              -1.83             -77.51   \n",
       "301               -9.28              -2.72             -78.59   \n",
       "302              -10.51              -3.63             -79.63   \n",
       "303              -11.72              -4.50             -80.62   \n",
       "304              -13.02              -5.51             -81.54   \n",
       "...                 ...                ...                ...   \n",
       "4671              10.27              27.53               2.73   \n",
       "4672              10.30              27.43               2.62   \n",
       "4673              10.31              27.33               2.57   \n",
       "4674              10.34              27.22               2.49   \n",
       "4675              10.35              27.15               2.45   \n",
       "\n",
       "      m_avg_R_WristRotX  m_avg_R_WristRotY  m_avg_R_WristRotZ  \n",
       "300              -20.51             -63.17             -54.59  \n",
       "301              -22.19             -67.01             -52.80  \n",
       "302              -23.97             -70.75             -51.09  \n",
       "303              -25.87             -74.66             -49.19  \n",
       "304              -27.52             -78.51             -47.68  \n",
       "...                 ...                ...                ...  \n",
       "4671              -4.35              -4.97              20.79  \n",
       "4672              -4.38              -5.10              20.49  \n",
       "4673              -4.40              -5.26              20.18  \n",
       "4674              -4.34              -5.49              19.92  \n",
       "4675              -4.24              -5.60              19.77  \n",
       "\n",
       "[4376 rows x 63 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범위를 벗어나는 값이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# -180 ~ 180 범위를 벗어나는 값이 있는지 확인\n",
    "num_values_out_of_range = (test_df > 180).sum().sum() + (test_df < -180).sum().sum()\n",
    "\n",
    "# 결과 확인\n",
    "if num_values_out_of_range > 0:\n",
    "    print(f\"범위를 벗어나는 값의 수: {num_values_out_of_range}\")\n",
    "else:\n",
    "    print(\"범위를 벗어나는 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 변화량 계산 및 범주화\n",
    "def calculate_average_change(test_df):\n",
    "    rotation_change_df = test_df.diff().abs()\n",
    "    rotation_change_df.iloc[0] = rotation_change_df.iloc[0].fillna(0)\n",
    "    average_change = rotation_change_df.mean(axis=1)\n",
    "    return average_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_average_change(average_change, thresholds):\n",
    "    categories = np.digitize(average_change, thresholds)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 변화량 범주 추가\n",
    "def add_change_category_to_df(test_df, thresholds):\n",
    "    average_change = calculate_average_change(test_df)\n",
    "    change_categories = categorize_average_change(average_change, thresholds)\n",
    "    test_df['Rot_diff_category'] = change_categories\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [5, 10]\n",
    "test_df = add_change_category_to_df(test_df, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4376, 64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 새로운 CSV 파일로 저장합니다.\n",
    "test_df.to_csv('./test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 364ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측 값을 넣을 빈 리스트\n",
    "test_predictions = []\n",
    "\n",
    "# 훈련 데이터셋에서 마지막 입력 개수의 값을 가져온 후\n",
    "current_batch = test_df[-n_input:].to_numpy().reshape((1, n_input, n_features))\n",
    "\n",
    "# 예측 과정 반복\n",
    "for i in range(1):\n",
    "    # 현재 배치에서 다음 포인트를 예측\n",
    "    current_pred = model.predict(current_batch)[0]  # 마지막 시퀀스 포인트 예측\n",
    "    current_pred = np.array([normalize_angle(y) for y in current_pred])  # 예측값 정규화\n",
    "\n",
    "    # 예측된 마지막 프레임을 리스트에 추가\n",
    "    test_predictions.append(current_pred)\n",
    "\n",
    "    # 새로운 배치 생성: 마지막 시퀀스 제외하고 예측값 추가\n",
    "    current_batch = np.roll(current_batch, -1, axis=1)\n",
    "    current_batch[0, -1, :] = current_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ -19.15331459,  145.60191345,   -2.35373902,   -1.62554216,\n",
       "         -26.54080772,    1.95792103,   -8.20357037,   -7.25508785,\n",
       "           0.44423327,   -8.46181965,  -52.06181717,   -0.53491789,\n",
       "           1.39775658,  -20.15781403,   19.35151482,   -5.45479584,\n",
       "           6.85913086,    2.48807454,  -12.07250977,   11.74835205,\n",
       "           6.91235495,   -9.83826828, -153.98405457,    8.37948227,\n",
       "           7.4973979 ,   -1.04024446,   50.20867157,  -20.78359604,\n",
       "         143.92155457,   -1.24525404,   -9.37625122,  155.4203949 ,\n",
       "          -4.87517071,   -6.57583141, -166.26812744,   -3.08035827,\n",
       "           2.49294758,  -47.15938568,   44.55622101,    1.19511306,\n",
       "         -15.06562233,   17.14491463,   -0.43270645,    3.08082056,\n",
       "           2.32816601,   -7.95456505,  164.44294739,   -8.49555302,\n",
       "           0.29763013,    1.35612667,   -0.7104311 ,   -6.98550034,\n",
       "         -35.29873657,  -11.23464489,    4.46827316,   75.23217773,\n",
       "         -42.78692245,   -1.59817147,  117.30580139,  -39.17132568,\n",
       "           0.55053025,    4.40880203,   -3.30749941,    0.97665143])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_array = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions 리스트의 각 항목을 (64,) 모양의 배열로 변환합니다.\n",
    "# test_predictions_flat = [pred.flatten() for pred in test_predictions]\n",
    "\n",
    "# 변환된 리스트를 데이터프레임으로 변환합니다.\n",
    "test_predictions = pd.DataFrame(test_predictions_array)\n",
    "\n",
    "# test_predictions 데이터프레임을 CSV 파일로 저장합니다.\n",
    "test_predictions.to_csv('./test_predictions.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-19.153315</td>\n",
       "      <td>145.601913</td>\n",
       "      <td>-2.353739</td>\n",
       "      <td>-1.625542</td>\n",
       "      <td>-26.540808</td>\n",
       "      <td>1.957921</td>\n",
       "      <td>-8.20357</td>\n",
       "      <td>-7.255088</td>\n",
       "      <td>0.444233</td>\n",
       "      <td>-8.46182</td>\n",
       "      <td>...</td>\n",
       "      <td>4.468273</td>\n",
       "      <td>75.232178</td>\n",
       "      <td>-42.786922</td>\n",
       "      <td>-1.598171</td>\n",
       "      <td>117.305801</td>\n",
       "      <td>-39.171326</td>\n",
       "      <td>0.55053</td>\n",
       "      <td>4.408802</td>\n",
       "      <td>-3.307499</td>\n",
       "      <td>0.976651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1         2         3          4         5        6   \\\n",
       "0 -19.153315  145.601913 -2.353739 -1.625542 -26.540808  1.957921 -8.20357   \n",
       "\n",
       "         7         8        9   ...        54         55         56        57  \\\n",
       "0 -7.255088  0.444233 -8.46182  ...  4.468273  75.232178 -42.786922 -1.598171   \n",
       "\n",
       "           58         59       60        61        62        63  \n",
       "0  117.305801 -39.171326  0.55053  4.408802 -3.307499  0.976651  \n",
       "\n",
       "[1 rows x 64 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    'm_avg_PelvisRotX', 'm_avg_PelvisRotY', 'm_avg_PelvisRotZ',\n",
    "    'm_avg_L_HipRotX', 'm_avg_L_HipRotY', 'm_avg_L_HipRotZ',\n",
    "    'm_avg_L_KneeRotX', 'm_avg_L_KneeRotY', 'm_avg_L_KneeRotZ',\n",
    "    'm_avg_L_AnkleRotX', 'm_avg_L_AnkleRotY', 'm_avg_L_AnkleRotZ',\n",
    "    'm_avg_L_FootRotX', 'm_avg_L_FootRotY', 'm_avg_L_FootRotZ',\n",
    "    'm_avg_R_HipRotX', 'm_avg_R_HipRotY', 'm_avg_R_HipRotZ',\n",
    "    'm_avg_R_KneeRotX', 'm_avg_R_KneeRotY', 'm_avg_R_KneeRotZ',\n",
    "    'm_avg_R_AnkleRotX', 'm_avg_R_AnkleRotY', 'm_avg_R_AnkleRotZ',\n",
    "    'm_avg_R_FootRotX', 'm_avg_R_FootRotY', 'm_avg_R_FootRotZ',\n",
    "    'm_avg_Spine1RotX', 'm_avg_Spine1RotY', 'm_avg_Spine1RotZ',\n",
    "    'm_avg_Spine2RotX', 'm_avg_Spine2RotY', 'm_avg_Spine2RotZ',\n",
    "    'm_avg_L_CollarRotX', 'm_avg_L_CollarRotY', 'm_avg_L_CollarRotZ',\n",
    "    'm_avg_L_ShoulderRotX', 'm_avg_L_ShoulderRotY', 'm_avg_L_ShoulderRotZ',\n",
    "    'm_avg_L_ElbowRotX', 'm_avg_L_ElbowRotY', 'm_avg_L_ElbowRotZ',\n",
    "    'm_avg_L_WristRotX', 'm_avg_L_WristRotY', 'm_avg_L_WristRotZ',\n",
    "    'm_avg_NeckRotX', 'm_avg_NeckRotY', 'm_avg_NeckRotZ',\n",
    "    'm_avg_HeadRotX', 'm_avg_HeadRotY', 'm_avg_HeadRotZ',\n",
    "    'm_avg_R_CollarRotX', 'm_avg_R_CollarRotY', 'm_avg_R_CollarRotZ',\n",
    "    'm_avg_R_ShoulderRotX', 'm_avg_R_ShoulderRotY', 'm_avg_R_ShoulderRotZ',\n",
    "    'm_avg_R_ElbowRotX', 'm_avg_R_ElbowRotY', 'm_avg_R_ElbowRotZ',\n",
    "    'm_avg_R_WristRotX', 'm_avg_R_WristRotY', 'm_avg_R_WristRotZ',\n",
    "    'Rot_diff_category'\n",
    "]\n",
    "# input 데이터(test_df)의 마지막 5 프레임과 \n",
    "last_inputs_df = test_df.iloc[-30:][column_order].reset_index(drop=True)\n",
    "test_predictions_df = pd.DataFrame(test_predictions_array, columns=column_order)\n",
    "\n",
    "test_combined_df = pd.concat([last_inputs_df, test_predictions_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_avg_PelvisRotX</th>\n",
       "      <th>m_avg_PelvisRotY</th>\n",
       "      <th>m_avg_PelvisRotZ</th>\n",
       "      <th>m_avg_L_HipRotX</th>\n",
       "      <th>m_avg_L_HipRotY</th>\n",
       "      <th>m_avg_L_HipRotZ</th>\n",
       "      <th>m_avg_L_KneeRotX</th>\n",
       "      <th>m_avg_L_KneeRotY</th>\n",
       "      <th>m_avg_L_KneeRotZ</th>\n",
       "      <th>m_avg_L_AnkleRotX</th>\n",
       "      <th>...</th>\n",
       "      <th>m_avg_R_ShoulderRotX</th>\n",
       "      <th>m_avg_R_ShoulderRotY</th>\n",
       "      <th>m_avg_R_ShoulderRotZ</th>\n",
       "      <th>m_avg_R_ElbowRotX</th>\n",
       "      <th>m_avg_R_ElbowRotY</th>\n",
       "      <th>m_avg_R_ElbowRotZ</th>\n",
       "      <th>m_avg_R_WristRotX</th>\n",
       "      <th>m_avg_R_WristRotY</th>\n",
       "      <th>m_avg_R_WristRotZ</th>\n",
       "      <th>Rot_diff_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.290000</td>\n",
       "      <td>-2.860000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>-2.880000</td>\n",
       "      <td>9.890000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>-19.27000</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>-23.31000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>25.170000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>9.240000</td>\n",
       "      <td>30.740000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>-1.59000</td>\n",
       "      <td>-1.080000</td>\n",
       "      <td>28.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.840000</td>\n",
       "      <td>-133.450000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-10.590000</td>\n",
       "      <td>-83.650000</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>-38.96000</td>\n",
       "      <td>-92.770000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-37.73000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.190000</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>9.190000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>5.990000</td>\n",
       "      <td>-1.95000</td>\n",
       "      <td>-1.220000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.840000</td>\n",
       "      <td>-133.450000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-10.590000</td>\n",
       "      <td>-83.650000</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>-38.96000</td>\n",
       "      <td>-92.770000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-37.73000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>25.230000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>30.790000</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>-2.25000</td>\n",
       "      <td>-1.390000</td>\n",
       "      <td>28.470000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.840000</td>\n",
       "      <td>-133.450000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-10.590000</td>\n",
       "      <td>-83.650000</td>\n",
       "      <td>19.510000</td>\n",
       "      <td>-38.96000</td>\n",
       "      <td>-92.770000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>-37.73000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.220000</td>\n",
       "      <td>25.190000</td>\n",
       "      <td>9.740000</td>\n",
       "      <td>9.210000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>-2.55000</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>28.440000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.070000</td>\n",
       "      <td>-4.730000</td>\n",
       "      <td>-2.910000</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>-20.96000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-21.27000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>25.120000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>9.240000</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>6.060000</td>\n",
       "      <td>-2.90000</td>\n",
       "      <td>-1.710000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.070000</td>\n",
       "      <td>-4.730000</td>\n",
       "      <td>-2.910000</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>-20.96000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-21.27000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.270000</td>\n",
       "      <td>25.040000</td>\n",
       "      <td>9.660000</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>6.020000</td>\n",
       "      <td>-3.26000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.070000</td>\n",
       "      <td>-4.730000</td>\n",
       "      <td>-2.910000</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>-20.96000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-21.27000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>24.950000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>9.310000</td>\n",
       "      <td>30.510000</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>-3.59000</td>\n",
       "      <td>-2.080000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>-4.650000</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-17.18000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-13.93000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>24.770000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>9.370000</td>\n",
       "      <td>30.330000</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>-3.91000</td>\n",
       "      <td>-2.330000</td>\n",
       "      <td>28.320000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>-4.650000</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-17.18000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-13.93000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>24.610000</td>\n",
       "      <td>9.230000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>30.180000</td>\n",
       "      <td>5.610000</td>\n",
       "      <td>-4.22000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>-4.650000</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-17.18000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-13.93000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.440000</td>\n",
       "      <td>24.460000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>30.030000</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>-4.47000</td>\n",
       "      <td>-2.940000</td>\n",
       "      <td>27.070000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>-14.32000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-11.22000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.510000</td>\n",
       "      <td>24.260000</td>\n",
       "      <td>8.810000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>29.840000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>-4.78000</td>\n",
       "      <td>-3.220000</td>\n",
       "      <td>26.340000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>-14.32000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-11.22000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.560000</td>\n",
       "      <td>24.080000</td>\n",
       "      <td>8.630000</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>-5.04000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>25.640000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.790000</td>\n",
       "      <td>-1.870000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>-14.32000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>-11.22000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.610000</td>\n",
       "      <td>23.890000</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>9.730000</td>\n",
       "      <td>29.480000</td>\n",
       "      <td>4.790000</td>\n",
       "      <td>-5.26000</td>\n",
       "      <td>-3.680000</td>\n",
       "      <td>25.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.590000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.260000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-13.00000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>-9.72000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>8.160000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>-5.22000</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.590000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.260000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-13.00000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>-9.72000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>23.520000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>9.860000</td>\n",
       "      <td>29.110000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>-5.23000</td>\n",
       "      <td>-3.910000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.590000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.260000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-13.00000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>-9.72000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>23.330000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>28.930000</td>\n",
       "      <td>4.140000</td>\n",
       "      <td>-5.03000</td>\n",
       "      <td>-4.060000</td>\n",
       "      <td>23.690000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.280000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-12.88000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>-9.58000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.770000</td>\n",
       "      <td>23.140000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>9.970000</td>\n",
       "      <td>28.740000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>-4.81000</td>\n",
       "      <td>-4.180000</td>\n",
       "      <td>23.170000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.280000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-12.88000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>-9.58000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.960000</td>\n",
       "      <td>7.330000</td>\n",
       "      <td>10.020000</td>\n",
       "      <td>28.570000</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>-4.67000</td>\n",
       "      <td>-4.340000</td>\n",
       "      <td>22.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.280000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>-12.88000</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>-9.58000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830000</td>\n",
       "      <td>22.780000</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>10.070000</td>\n",
       "      <td>28.390000</td>\n",
       "      <td>3.590000</td>\n",
       "      <td>-4.52000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>22.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.290000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>-12.85000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>-9.55000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.860000</td>\n",
       "      <td>22.620000</td>\n",
       "      <td>6.990000</td>\n",
       "      <td>10.110000</td>\n",
       "      <td>28.230000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>-4.45000</td>\n",
       "      <td>-4.620000</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.290000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>-12.85000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>-9.55000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.880000</td>\n",
       "      <td>22.460000</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>10.150000</td>\n",
       "      <td>28.080000</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>-4.40000</td>\n",
       "      <td>-4.690000</td>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>-4.610000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.290000</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>-12.85000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>-9.55000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>22.330000</td>\n",
       "      <td>6.710000</td>\n",
       "      <td>10.180000</td>\n",
       "      <td>27.940000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>-4.33000</td>\n",
       "      <td>-4.750000</td>\n",
       "      <td>21.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>-11.41000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>-10.60000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.910000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>27.820000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>-4.29000</td>\n",
       "      <td>-4.810000</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>-11.41000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>-10.60000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>6.460000</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>27.730000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>-4.30000</td>\n",
       "      <td>-4.870000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>-5.080000</td>\n",
       "      <td>-3.150000</td>\n",
       "      <td>-2.550000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>-11.41000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>-10.60000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.940000</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>27.640000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>-4.32000</td>\n",
       "      <td>-4.910000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>-10.80000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>-10.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>10.270000</td>\n",
       "      <td>27.530000</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>-4.35000</td>\n",
       "      <td>-4.970000</td>\n",
       "      <td>20.790000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>-10.80000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>-10.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>21.810000</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>27.430000</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>-4.38000</td>\n",
       "      <td>-5.100000</td>\n",
       "      <td>20.490000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>-10.80000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>-10.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>10.310000</td>\n",
       "      <td>27.330000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>-4.40000</td>\n",
       "      <td>-5.260000</td>\n",
       "      <td>20.180000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.290000</td>\n",
       "      <td>-2.450000</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>-10.58000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>-10.76000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>21.590000</td>\n",
       "      <td>6.030000</td>\n",
       "      <td>10.340000</td>\n",
       "      <td>27.220000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>-4.34000</td>\n",
       "      <td>-5.490000</td>\n",
       "      <td>19.920000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>-4.990000</td>\n",
       "      <td>-3.290000</td>\n",
       "      <td>-2.450000</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>-10.58000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>-10.76000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.510000</td>\n",
       "      <td>5.990000</td>\n",
       "      <td>10.350000</td>\n",
       "      <td>27.150000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>-4.24000</td>\n",
       "      <td>-5.600000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-19.153315</td>\n",
       "      <td>145.601913</td>\n",
       "      <td>-2.353739</td>\n",
       "      <td>-1.625542</td>\n",
       "      <td>-26.540808</td>\n",
       "      <td>1.957921</td>\n",
       "      <td>-8.20357</td>\n",
       "      <td>-7.255088</td>\n",
       "      <td>0.444233</td>\n",
       "      <td>-8.46182</td>\n",
       "      <td>...</td>\n",
       "      <td>4.468273</td>\n",
       "      <td>75.232178</td>\n",
       "      <td>-42.786922</td>\n",
       "      <td>-1.598171</td>\n",
       "      <td>117.305801</td>\n",
       "      <td>-39.171326</td>\n",
       "      <td>0.55053</td>\n",
       "      <td>4.408802</td>\n",
       "      <td>-3.307499</td>\n",
       "      <td>0.976651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    m_avg_PelvisRotX  m_avg_PelvisRotY  m_avg_PelvisRotZ  m_avg_L_HipRotX  \\\n",
       "0           1.290000         -2.860000         -1.520000        -2.880000   \n",
       "1         -10.840000       -133.450000         -3.480000       -10.590000   \n",
       "2         -10.840000       -133.450000         -3.480000       -10.590000   \n",
       "3         -10.840000       -133.450000         -3.480000       -10.590000   \n",
       "4           1.070000         -4.730000         -2.910000        -1.370000   \n",
       "5           1.070000         -4.730000         -2.910000        -1.370000   \n",
       "6           1.070000         -4.730000         -2.910000        -1.370000   \n",
       "7           0.830000         -4.650000         -3.010000        -1.520000   \n",
       "8           0.830000         -4.650000         -3.010000        -1.520000   \n",
       "9           0.830000         -4.650000         -3.010000        -1.520000   \n",
       "10          0.770000         -4.600000         -2.790000        -1.870000   \n",
       "11          0.770000         -4.600000         -2.790000        -1.870000   \n",
       "12          0.770000         -4.600000         -2.790000        -1.870000   \n",
       "13          0.720000         -4.590000         -2.690000        -2.260000   \n",
       "14          0.720000         -4.590000         -2.690000        -2.260000   \n",
       "15          0.720000         -4.590000         -2.690000        -2.260000   \n",
       "16          0.720000         -4.600000         -2.690000        -2.280000   \n",
       "17          0.720000         -4.600000         -2.690000        -2.280000   \n",
       "18          0.720000         -4.600000         -2.690000        -2.280000   \n",
       "19          0.710000         -4.610000         -2.690000        -2.290000   \n",
       "20          0.710000         -4.610000         -2.690000        -2.290000   \n",
       "21          0.710000         -4.610000         -2.690000        -2.290000   \n",
       "22          0.670000         -5.080000         -3.150000        -2.550000   \n",
       "23          0.670000         -5.080000         -3.150000        -2.550000   \n",
       "24          0.670000         -5.080000         -3.150000        -2.550000   \n",
       "25          0.640000         -4.990000         -3.300000        -2.610000   \n",
       "26          0.640000         -4.990000         -3.300000        -2.610000   \n",
       "27          0.640000         -4.990000         -3.300000        -2.610000   \n",
       "28          0.650000         -4.990000         -3.290000        -2.450000   \n",
       "29          0.650000         -4.990000         -3.290000        -2.450000   \n",
       "30        -19.153315        145.601913         -2.353739        -1.625542   \n",
       "\n",
       "    m_avg_L_HipRotY  m_avg_L_HipRotZ  m_avg_L_KneeRotX  m_avg_L_KneeRotY  \\\n",
       "0          9.890000         4.190000         -19.27000          9.840000   \n",
       "1        -83.650000        19.510000         -38.96000        -92.770000   \n",
       "2        -83.650000        19.510000         -38.96000        -92.770000   \n",
       "3        -83.650000        19.510000         -38.96000        -92.770000   \n",
       "4          2.790000         3.020000         -20.96000          3.240000   \n",
       "5          2.790000         3.020000         -20.96000          3.240000   \n",
       "6          2.790000         3.020000         -20.96000          3.240000   \n",
       "7          3.960000         2.810000         -17.18000          4.290000   \n",
       "8          3.960000         2.810000         -17.18000          4.290000   \n",
       "9          3.960000         2.810000         -17.18000          4.290000   \n",
       "10         4.040000         2.920000         -14.32000          4.220000   \n",
       "11         4.040000         2.920000         -14.32000          4.220000   \n",
       "12         4.040000         2.920000         -14.32000          4.220000   \n",
       "13         4.020000         2.960000         -13.00000          4.140000   \n",
       "14         4.020000         2.960000         -13.00000          4.140000   \n",
       "15         4.020000         2.960000         -13.00000          4.140000   \n",
       "16         4.010000         2.960000         -12.88000          4.130000   \n",
       "17         4.010000         2.960000         -12.88000          4.130000   \n",
       "18         4.010000         2.960000         -12.88000          4.130000   \n",
       "19         4.030000         2.970000         -12.85000          4.150000   \n",
       "20         4.030000         2.970000         -12.85000          4.150000   \n",
       "21         4.030000         2.970000         -12.85000          4.150000   \n",
       "22         4.250000         3.190000         -11.41000          4.290000   \n",
       "23         4.250000         3.190000         -11.41000          4.290000   \n",
       "24         4.250000         3.190000         -11.41000          4.290000   \n",
       "25         4.840000         3.510000         -10.80000          4.830000   \n",
       "26         4.840000         3.510000         -10.80000          4.830000   \n",
       "27         4.840000         3.510000         -10.80000          4.830000   \n",
       "28         5.340000         3.860000         -10.58000          5.280000   \n",
       "29         5.340000         3.860000         -10.58000          5.280000   \n",
       "30       -26.540808         1.957921          -8.20357         -7.255088   \n",
       "\n",
       "    m_avg_L_KneeRotZ  m_avg_L_AnkleRotX  ...  m_avg_R_ShoulderRotX  \\\n",
       "0           1.820000          -23.31000  ...             10.220000   \n",
       "1          19.100000          -37.73000  ...             10.190000   \n",
       "2          19.100000          -37.73000  ...             10.210000   \n",
       "3          19.100000          -37.73000  ...             10.220000   \n",
       "4           0.080000          -21.27000  ...             10.250000   \n",
       "5           0.080000          -21.27000  ...             10.270000   \n",
       "6           0.080000          -21.27000  ...             10.300000   \n",
       "7           0.480000          -13.93000  ...             10.350000   \n",
       "8           0.480000          -13.93000  ...             10.400000   \n",
       "9           0.480000          -13.93000  ...             10.440000   \n",
       "10          1.090000          -11.22000  ...             10.510000   \n",
       "11          1.090000          -11.22000  ...             10.560000   \n",
       "12          1.090000          -11.22000  ...             10.610000   \n",
       "13          1.390000           -9.72000  ...             10.660000   \n",
       "14          1.390000           -9.72000  ...             10.700000   \n",
       "15          1.390000           -9.72000  ...             10.740000   \n",
       "16          1.410000           -9.58000  ...             10.770000   \n",
       "17          1.410000           -9.58000  ...             10.800000   \n",
       "18          1.410000           -9.58000  ...             10.830000   \n",
       "19          1.420000           -9.55000  ...             10.860000   \n",
       "20          1.420000           -9.55000  ...             10.880000   \n",
       "21          1.420000           -9.55000  ...             10.900000   \n",
       "22          1.910000          -10.60000  ...             10.910000   \n",
       "23          1.910000          -10.60000  ...             10.930000   \n",
       "24          1.910000          -10.60000  ...             10.940000   \n",
       "25          2.330000          -10.90000  ...             10.950000   \n",
       "26          2.330000          -10.90000  ...             10.970000   \n",
       "27          2.330000          -10.90000  ...             10.970000   \n",
       "28          2.690000          -10.76000  ...             10.990000   \n",
       "29          2.690000          -10.76000  ...             11.000000   \n",
       "30          0.444233           -8.46182  ...              4.468273   \n",
       "\n",
       "    m_avg_R_ShoulderRotY  m_avg_R_ShoulderRotZ  m_avg_R_ElbowRotX  \\\n",
       "0              25.170000              9.440000           9.240000   \n",
       "1              25.240000              9.640000           9.190000   \n",
       "2              25.230000              9.700000           9.200000   \n",
       "3              25.190000              9.740000           9.210000   \n",
       "4              25.120000              9.710000           9.240000   \n",
       "5              25.040000              9.660000           9.270000   \n",
       "6              24.950000              9.570000           9.310000   \n",
       "7              24.770000              9.400000           9.370000   \n",
       "8              24.610000              9.230000           9.440000   \n",
       "9              24.460000              9.050000           9.500000   \n",
       "10             24.260000              8.810000           9.590000   \n",
       "11             24.080000              8.630000           9.650000   \n",
       "12             23.890000              8.380000           9.730000   \n",
       "13             23.700000              8.160000           9.800000   \n",
       "14             23.520000              7.930000           9.860000   \n",
       "15             23.330000              7.720000           9.920000   \n",
       "16             23.140000              7.520000           9.970000   \n",
       "17             22.960000              7.330000          10.020000   \n",
       "18             22.780000              7.150000          10.070000   \n",
       "19             22.620000              6.990000          10.110000   \n",
       "20             22.460000              6.840000          10.150000   \n",
       "21             22.330000              6.710000          10.180000   \n",
       "22             22.200000              6.580000          10.200000   \n",
       "23             22.100000              6.460000          10.230000   \n",
       "24             22.020000              6.360000          10.250000   \n",
       "25             21.910000              6.280000          10.270000   \n",
       "26             21.810000              6.170000          10.300000   \n",
       "27             21.700000              6.110000          10.310000   \n",
       "28             21.590000              6.030000          10.340000   \n",
       "29             21.510000              5.990000          10.350000   \n",
       "30             75.232178            -42.786922          -1.598171   \n",
       "\n",
       "    m_avg_R_ElbowRotY  m_avg_R_ElbowRotZ  m_avg_R_WristRotX  \\\n",
       "0           30.740000           5.800000           -1.59000   \n",
       "1           30.800000           5.990000           -1.95000   \n",
       "2           30.790000           6.050000           -2.25000   \n",
       "3           30.750000           6.090000           -2.55000   \n",
       "4           30.680000           6.060000           -2.90000   \n",
       "5           30.600000           6.020000           -3.26000   \n",
       "6           30.510000           5.940000           -3.59000   \n",
       "7           30.330000           5.770000           -3.91000   \n",
       "8           30.180000           5.610000           -4.22000   \n",
       "9           30.030000           5.430000           -4.47000   \n",
       "10          29.840000           5.200000           -4.78000   \n",
       "11          29.670000           5.020000           -5.04000   \n",
       "12          29.480000           4.790000           -5.26000   \n",
       "13          29.300000           4.570000           -5.22000   \n",
       "14          29.110000           4.350000           -5.23000   \n",
       "15          28.930000           4.140000           -5.03000   \n",
       "16          28.740000           3.940000           -4.81000   \n",
       "17          28.570000           3.760000           -4.67000   \n",
       "18          28.390000           3.590000           -4.52000   \n",
       "19          28.230000           3.430000           -4.45000   \n",
       "20          28.080000           3.280000           -4.40000   \n",
       "21          27.940000           3.150000           -4.33000   \n",
       "22          27.820000           3.030000           -4.29000   \n",
       "23          27.730000           2.910000           -4.30000   \n",
       "24          27.640000           2.810000           -4.32000   \n",
       "25          27.530000           2.730000           -4.35000   \n",
       "26          27.430000           2.620000           -4.38000   \n",
       "27          27.330000           2.570000           -4.40000   \n",
       "28          27.220000           2.490000           -4.34000   \n",
       "29          27.150000           2.450000           -4.24000   \n",
       "30         117.305801         -39.171326            0.55053   \n",
       "\n",
       "    m_avg_R_WristRotY  m_avg_R_WristRotZ  Rot_diff_category  \n",
       "0           -1.080000          28.350000           0.000000  \n",
       "1           -1.220000          28.450000           2.000000  \n",
       "2           -1.390000          28.470000           0.000000  \n",
       "3           -1.550000          28.440000           0.000000  \n",
       "4           -1.710000          28.450000           2.000000  \n",
       "5           -1.870000          28.500000           0.000000  \n",
       "6           -2.080000          28.500000           0.000000  \n",
       "7           -2.330000          28.320000           0.000000  \n",
       "8           -2.600000          27.990000           0.000000  \n",
       "9           -2.940000          27.070000           0.000000  \n",
       "10          -3.220000          26.340000           0.000000  \n",
       "11          -3.480000          25.640000           0.000000  \n",
       "12          -3.680000          25.050000           0.000000  \n",
       "13          -3.750000          24.580000           0.000000  \n",
       "14          -3.910000          24.100000           0.000000  \n",
       "15          -4.060000          23.690000           0.000000  \n",
       "16          -4.180000          23.170000           0.000000  \n",
       "17          -4.340000          22.580000           0.000000  \n",
       "18          -4.500000          22.040000           0.000000  \n",
       "19          -4.620000          21.660000           0.000000  \n",
       "20          -4.690000          21.350000           0.000000  \n",
       "21          -4.750000          21.050000           0.000000  \n",
       "22          -4.810000          20.760000           0.000000  \n",
       "23          -4.870000          20.830000           0.000000  \n",
       "24          -4.910000          20.900000           0.000000  \n",
       "25          -4.970000          20.790000           0.000000  \n",
       "26          -5.100000          20.490000           0.000000  \n",
       "27          -5.260000          20.180000           0.000000  \n",
       "28          -5.490000          19.920000           0.000000  \n",
       "29          -5.600000          19.770000           0.000000  \n",
       "30           4.408802          -3.307499           0.976651  \n",
       "\n",
       "[31 rows x 64 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined_df.to_csv('./test_combined_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추후 확인\n",
    "1. Input 데이터 (combined_df)가 파일 한개 데이터 씩 순서 상관 없이 잘 섞였는지 확인\n",
    "2. 학습 데이터를 IHSens 데이터로 하는게 맞는지? (다른 더 정확한 motion capture 데이터) 혹은 학습 시킬 때 position도 학습 시켜야 할지\n",
    "3. 학습시킬 때, Transfromer에 넣기 전에 21개 skeletal 구조를 먼저 학습 시킨 후에 (어떤 모델로?) sequential한 motion 데이터를 학습 시켜야 하는지\n",
    "    - .bvh 파일 뷰어: https://www.creators3d.com/online-viewer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihsens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
